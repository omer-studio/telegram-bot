#!/usr/bin/env python3
"""
ğŸ  ××¢×¨×›×ª ×’×™×‘×•×™ ×¤× ×™××™×ª ×‘××¡×“ ×”× ×ª×•× ×™×
×™×•×¦×¨×ª "×ª×™×§×™×•×ª" (schemas) ×‘×ª×•×š ××•×ª×• ××¡×“ × ×ª×•× ×™×
×›×œ ×™×•× = ×ª×™×§×™×” ×—×“×©×” ×¢× ×›×œ ×”×˜×‘×œ××•×ª ×”×—×©×•×‘×•×ª
"""

import psycopg2
from datetime import datetime, timedelta
from config import config
from simple_logger import logger
from admin_notifications import send_admin_notification

DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")

# ğŸ”’ ×˜×‘×œ××•×ª ×§×¨×™×˜×™×•×ª ×œ×’×™×‘×•×™
CRITICAL_TABLES = [
    "user_profiles",     # ×”×œ×‘ ×©×œ ×”××¢×¨×›×ª
    "chat_messages",     # ×›×œ ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×•×ª  
    "interactions_log"   # ×›×œ ×”×§×¨×™××•×ª ×•×”×¢×œ×•×™×•×ª (×”×—×œ×™×¤×” ××ª gpt_calls_log)
]

def create_backup_schema(backup_date):
    """×™×•×¦×¨ schema ×—×“×© ×œ×’×™×‘×•×™ (×›××• ×ª×™×§×™×”)"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        schema_name = f"backup_{backup_date}"
        
        # ×™×¦×™×¨×ª schema ×—×“×©
        cur.execute(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
        
        # ×”×•×¡×¤×ª ×”×¢×¨×” ×œschema
        cur.execute(f"""
            COMMENT ON SCHEMA {schema_name} IS 
            '×’×™×‘×•×™ ××•×˜×•××˜×™ ××ª××¨×™×š {backup_date} - × ×•×¦×¨ ×‘×©×¢×” {datetime.now().strftime("%H:%M:%S")}'
        """)
        
        conn.commit()
        cur.close()
        conn.close()
        
        logger.info(f"ğŸ“ × ×•×¦×¨ schema ×’×™×‘×•×™: {schema_name}")
        return schema_name
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª schema ×’×™×‘×•×™: {e}")
        return None

def backup_table_to_schema(table_name, schema_name):
    """××’×‘×” ×˜×‘×œ×” ×œschema ×”×’×™×‘×•×™"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×©×œ×™×¤×ª ××‘× ×” ×”×˜×‘×œ×” ×”××§×•×¨×™×ª
        cur.execute(f"""
            SELECT column_name, data_type, is_nullable, column_default
            FROM information_schema.columns 
            WHERE table_name = '{table_name}' AND table_schema = 'public'
            ORDER BY ordinal_position
        """)
        
        columns_info = cur.fetchall()
        
        if not columns_info:
            logger.warning(f"âš ï¸ ×˜×‘×œ×” {table_name} ×œ× × ××¦××”")
            return False
        
        # ×‘× ×™×™×ª CREATE TABLE statement
        create_columns = []
        for col_name, data_type, is_nullable, col_default in columns_info:
            col_def = f"{col_name} {data_type}"
            
            if is_nullable == 'NO':
                col_def += " NOT NULL"
            
            if col_default:
                col_def += f" DEFAULT {col_default}"
            
            create_columns.append(col_def)
        
        create_table_sql = f"""
            CREATE TABLE {schema_name}.{table_name} (
                {', '.join(create_columns)}
            )
        """
        
        # ×™×¦×™×¨×ª ×˜×‘×œ×ª ×’×™×‘×•×™
        cur.execute(create_table_sql)
        
        # ×”×¢×ª×§×ª ×”× ×ª×•× ×™×
        cur.execute(f"""
            INSERT INTO {schema_name}.{table_name} 
            SELECT * FROM public.{table_name}
        """)
        
        rows_copied = cur.rowcount
        
        # ×”×•×¡×¤×ª ×”×¢×¨×” ×œ×˜×‘×œ×”
        cur.execute(f"""
            COMMENT ON TABLE {schema_name}.{table_name} IS 
            '×’×™×‘×•×™ ×©×œ {table_name} - {rows_copied} ×¨×©×•××•×ª ××ª××¨×™×š {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        """)
        
        conn.commit()
        cur.close()
        conn.close()
        
        logger.info(f"âœ… ×’×™×‘×•×™ {table_name}: {rows_copied} ×¨×©×•××•×ª ×œ-{schema_name}")
        return rows_copied
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ {table_name}: {e}")
        return False

def run_internal_backup():
    """××¨×™×¥ ×’×™×‘×•×™ ×¤× ×™××™ ××œ×"""
    try:
        backup_date = datetime.now().strftime("%Y%m%d")
        logger.info(f"ğŸ  ××ª×—×™×œ ×’×™×‘×•×™ ×¤× ×™××™ ×œ×ª××¨×™×š {backup_date}")
        
        # ×™×¦×™×¨×ª schema ×œ×’×™×‘×•×™ ×”×™×•×
        schema_name = create_backup_schema(backup_date)
        if not schema_name:
            return False
        
        # ×’×™×‘×•×™ ×›×œ ×˜×‘×œ×” ×§×¨×™×˜×™×ª
        backup_results = {}
        total_rows = 0
        
        for table in CRITICAL_TABLES:
            rows_backed_up = backup_table_to_schema(table, schema_name)
            backup_results[table] = rows_backed_up
            
            if rows_backed_up:
                total_rows += rows_backed_up
        
        # ×¡×™×›×•×
        successful_tables = len([t for t in backup_results.values() if t])
        
        if successful_tables == len(CRITICAL_TABLES):
            logger.info(f"ğŸ‰ ×’×™×‘×•×™ ×¤× ×™××™ ×”×•×©×œ×: {total_rows} ×¨×©×•××•×ª ×‘-{successful_tables} ×˜×‘×œ××•×ª")
            
            # ×”×•×¡×¤×ª ××˜×-××™×“×¢ ×œschema
            add_backup_metadata(schema_name, backup_results, total_rows)
            
            # ×”×ª×¨××” ×œ××“××™×Ÿ
            send_admin_notification(
                f"ğŸ  **×’×™×‘×•×™ ×¤× ×™××™ ×”×•×©×œ×**\n\n" +
                f"ğŸ“ **Schema:** `{schema_name}`\n" +
                f"ğŸ“Š **×¡×”\"×› ×¨×©×•××•×ª:** {total_rows:,}\n" +
                f"ğŸ“‹ **×˜×‘×œ××•×ª:** {successful_tables}/{len(CRITICAL_TABLES)}\n\n" +
                f"ğŸ” **×¤×™×¨×•×˜:**\n" +
                f"ğŸ‘¥ user_profiles: {backup_results.get('user_profiles', 0):,}\n" +
                f"ğŸ’¬ chat_messages: {backup_results.get('chat_messages', 0):,}\n" +
                f"ğŸ”„ interactions_log: {backup_results.get('interactions_log', 0):,}\n\n" +
                f"ğŸ”’ **×”× ×ª×•× ×™× ××•×’× ×™× ×‘××•×ª×• ××¡×“ × ×ª×•× ×™×**"
            )
            
            return True
        else:
            logger.error(f"âŒ ×’×™×‘×•×™ ×¤× ×™××™ × ×›×©×œ: {successful_tables}/{len(CRITICAL_TABLES)} ×˜×‘×œ××•×ª")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™: {e}")
        return False

def add_backup_metadata(schema_name, backup_results, total_rows):
    """××•×¡×™×£ ×˜×‘×œ×ª ××˜×-××™×“×¢ ×œ×’×™×‘×•×™"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×™×¦×™×¨×ª ×˜×‘×œ×ª ××˜×-××™×“×¢
        cur.execute(f"""
            CREATE TABLE {schema_name}.backup_metadata (
                backup_date DATE NOT NULL,
                backup_time TIMESTAMP NOT NULL,
                table_name TEXT NOT NULL,
                rows_count INTEGER NOT NULL,
                backup_size_estimate TEXT,
                created_by TEXT DEFAULT 'internal_backup_system'
            )
        """)
        
        # ×”×•×¡×¤×ª × ×ª×•× ×™ ××˜× ×œ×›×œ ×˜×‘×œ×”
        backup_time = datetime.now()
        backup_date = backup_time.date()
        
        for table_name, rows_count in backup_results.items():
            if rows_count:
                # ××•××“×Ÿ ×’×•×“×œ
                if table_name == "chat_messages":
                    size_estimate = f"~{rows_count * 0.5:.1f}KB"
                elif table_name == "interactions_log":
                    size_estimate = f"~{rows_count * 5:.1f}KB"  # ×˜×‘×œ×” ×™×•×ª×¨ ××¤×•×¨×˜×ª
                else:
                    size_estimate = f"~{rows_count * 0.1:.1f}KB"
                
                cur.execute(f"""
                    INSERT INTO {schema_name}.backup_metadata 
                    (backup_date, backup_time, table_name, rows_count, backup_size_estimate)
                    VALUES (%s, %s, %s, %s, %s)
                """, (backup_date, backup_time, table_name, rows_count, size_estimate))
        
        # ×”×•×¡×¤×ª ×¨×©×•××ª ×¡×™×›×•×
        cur.execute(f"""
            INSERT INTO {schema_name}.backup_metadata 
            (backup_date, backup_time, table_name, rows_count, backup_size_estimate)
            VALUES (%s, %s, %s, %s, %s)
        """, (backup_date, backup_time, "TOTAL_SUMMARY", total_rows, f"~{total_rows * 0.8:.1f}KB"))
        
        conn.commit()
        cur.close()
        conn.close()
        
        logger.info(f"ğŸ“‹ × ×•×¡×£ ××˜×-××™×“×¢ ×œ×’×™×‘×•×™ {schema_name}")
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×”×•×¡×¤×ª ××˜×-××™×“×¢: {e}")

def list_internal_backups():
    """××¦×™×’ ×¨×©×™××ª ×’×™×‘×•×™×™× ×¤× ×™××™×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×—×™×¤×•×© schemas ×©×œ ×’×™×‘×•×™
        cur.execute("""
            SELECT schema_name, 
                   obj_description(oid, 'pg_namespace') as description
            FROM information_schema.schemata s
            JOIN pg_namespace n ON n.nspname = s.schema_name
            WHERE schema_name LIKE 'backup_%'
            ORDER BY schema_name DESC
        """)
        
        backups = cur.fetchall()
        
        if not backups:
            print("ğŸ“ ×œ× × ××¦××• ×’×™×‘×•×™×™× ×¤× ×™××™×™×")
            return
        
        print("ğŸ  ×’×™×‘×•×™×™× ×¤× ×™××™×™× ×–××™× ×™×:")
        print("=" * 60)
        
        for schema_name, description in backups:
            backup_date = schema_name.replace("backup_", "")
            
            # ×¤×™×¨××•×˜ ×ª××¨×™×š
            try:
                date_obj = datetime.strptime(backup_date, "%Y%m%d")
                formatted_date = date_obj.strftime("%d/%m/%Y")
            except:
                formatted_date = backup_date
            
            print(f"\nğŸ“… {formatted_date} (Schema: {schema_name})")
            
            if description:
                print(f"   ğŸ“ {description}")
            
            # ×”×¦×’×ª ×¤×¨×˜×™ ×˜×‘×œ××•×ª
            try:
                cur.execute(f"""
                    SELECT table_name, 
                           obj_description(oid, 'pg_class') as table_comment
                    FROM information_schema.tables t
                    LEFT JOIN pg_class c ON c.relname = t.table_name
                    WHERE table_schema = '{schema_name}' 
                      AND table_name != 'backup_metadata'
                    ORDER BY table_name
                """)
                
                tables = cur.fetchall()
                for table_name, table_comment in tables:
                    if table_comment:
                        rows_count = table_comment.split(" - ")[1].split(" ×¨×©×•××•×ª")[0] if " - " in table_comment else "?"
                        print(f"   ğŸ“Š {table_name}: {rows_count} ×¨×©×•××•×ª")
                    else:
                        print(f"   ğŸ“Š {table_name}")
            except:
                pass
        
        cur.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")

def restore_from_internal_backup(backup_date, table_name=None):
    """×©×—×–×•×¨ ××’×™×‘×•×™ ×¤× ×™××™"""
    try:
        schema_name = f"backup_{backup_date}"
        
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×‘×“×™×§×” ×©×”schema ×§×™×™×
        cur.execute("""
            SELECT schema_name FROM information_schema.schemata 
            WHERE schema_name = %s
        """, (schema_name,))
        
        if not cur.fetchone():
            print(f"âŒ ×’×™×‘×•×™ ××ª××¨×™×š {backup_date} ×œ× × ××¦×")
            return False
        
        # ×¨×©×™××ª ×˜×‘×œ××•×ª ×œ×©×—×–×•×¨
        tables_to_restore = [table_name] if table_name else CRITICAL_TABLES
        
        print(f"ğŸ”„ ×©×—×–×•×¨ ××’×™×‘×•×™ {backup_date}")
        print(f"ğŸ“Š ×˜×‘×œ××•×ª ×œ×©×—×–×•×¨: {', '.join(tables_to_restore)}")
        
        # ××™×©×•×¨ ××—×¨×•×Ÿ
        confirm = input("\nâš ï¸ ×”×× ××ª×” ×‘×˜×•×—? ×–×” ×™××—×§ ××ª ×”× ×ª×•× ×™× ×”× ×•×›×—×™×™×! (YES/no): ")
        if confirm != "YES":
            print("âŒ ×©×—×–×•×¨ ×‘×•×˜×œ")
            return False
        
        restored_tables = 0
        for table in tables_to_restore:
            try:
                # ×‘×“×™×§×” ×©×”×˜×‘×œ×” ×§×™×™××ª ×‘×’×™×‘×•×™
                cur.execute(f"""
                    SELECT COUNT(*) FROM {schema_name}.{table}
                """)
                backup_rows = cur.fetchone()[0]
                
                # ××—×™×§×ª × ×ª×•× ×™× × ×•×›×—×™×™×
                cur.execute(f"DELETE FROM public.{table}")
                
                # ×©×—×–×•×¨ ×”× ×ª×•× ×™×
                cur.execute(f"""
                    INSERT INTO public.{table} 
                    SELECT * FROM {schema_name}.{table}
                """)
                
                restored_rows = cur.rowcount
                restored_tables += 1
                
                print(f"âœ… {table}: {restored_rows} ×¨×©×•××•×ª ×©×•×—×–×¨×•")
                
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ {table}: {e}")
        
        conn.commit()
        cur.close()
        conn.close()
        
        if restored_tables > 0:
            print(f"\nğŸ‰ ×©×—×–×•×¨ ×”×•×©×œ×: {restored_tables} ×˜×‘×œ××•×ª")
            
            # ×”×ª×¨××” ×œ××“××™×Ÿ
            send_admin_notification(
                f"ğŸ”„ **×©×—×–×•×¨ ××’×™×‘×•×™ ×¤× ×™××™**\n\n" +
                f"ğŸ“… **×ª××¨×™×š ×’×™×‘×•×™:** {backup_date}\n" +
                f"ğŸ“Š **×˜×‘×œ××•×ª ×©×•×—×–×¨×•:** {restored_tables}\n" +
                f"ğŸ”’ **××§×•×¨:** Schema {schema_name}"
            )
            
            return True
        else:
            print("âŒ ×©×—×–×•×¨ × ×›×©×œ")
            return False
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨: {e}")
        return False

def cleanup_old_internal_backups(days_to_keep=30):
    """××—×™×§×ª ×’×™×‘×•×™×™× ×¤× ×™××™×™× ×™×©× ×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        cutoff_str = cutoff_date.strftime("%Y%m%d")
        
        # ×—×™×¤×•×© schemas ×™×©× ×™×
        cur.execute("""
            SELECT schema_name FROM information_schema.schemata 
            WHERE schema_name LIKE 'backup_%' 
              AND schema_name < %s
            ORDER BY schema_name
        """, (f"backup_{cutoff_str}",))
        
        old_schemas = [row[0] for row in cur.fetchall()]
        
        if not old_schemas:
            logger.info("ğŸ§¹ ××™×Ÿ ×’×™×‘×•×™×™× ×™×©× ×™× ×œ××—×™×§×”")
            return
        
        deleted_schemas = 0
        for schema in old_schemas:
            try:
                cur.execute(f"DROP SCHEMA {schema} CASCADE")
                deleted_schemas += 1
                logger.info(f"ğŸ—‘ï¸ × ××—×§ ×’×™×‘×•×™ ×™×©×Ÿ: {schema}")
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘××—×™×§×ª {schema}: {e}")
        
        conn.commit()
        cur.close()
        conn.close()
        
        if deleted_schemas > 0:
            logger.info(f"ğŸ§¹ × ××—×§×• {deleted_schemas} ×’×™×‘×•×™×™× ×™×©× ×™×")
            
            send_admin_notification(
                f"ğŸ§¹ **× ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×**\n\n" +
                f"ğŸ—‘ï¸ **× ××—×§×•:** {deleted_schemas} ×’×™×‘×•×™×™×\n" +
                f"ğŸ“… **×™×©× ×™× ×:** {cutoff_date.strftime('%d/%m/%Y')}\n" +
                f"ğŸ’¾ **×©××™×¨×ª:** {days_to_keep} ×™××™× ××—×¨×•× ×™×"
            )
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "backup":
            run_internal_backup()
        elif command == "list":
            list_internal_backups()
        elif command == "restore":
            if len(sys.argv) < 3:
                print("×©×™××•×©: python internal_backup_system.py restore <backup_date> [table_name]")
                print("×“×•×’××”: python internal_backup_system.py restore 20250109")
                print("×“×•×’××”: python internal_backup_system.py restore 20250109 user_profiles")
            else:
                backup_date = sys.argv[2]
                table_name = sys.argv[3] if len(sys.argv) > 3 else None
                restore_from_internal_backup(backup_date, table_name)
        elif command == "cleanup":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            cleanup_old_internal_backups(days)
        else:
            print("×©×™××•×©: python internal_backup_system.py [backup|list|restore|cleanup]")
    else:
        # ×’×™×‘×•×™ ×¨×’×™×œ
        run_internal_backup() 