#!/usr/bin/env python3
"""
ğŸ”’ backup_system.py
==================
××¢×¨×›×ª ×’×™×‘×•×™ ×××•×—×“×ª - ××—×œ×™×¤×” 12 ×§×‘×¦×™ ×’×™×‘×•×™ ×©×•× ×™×!

ğŸ¯ ××—×œ×§×•×ª:
- LocalBackup: ×’×™×‘×•×™ ×™×•××™ ×œ×§×‘×¦×™ JSON
- CloudBackup: ×’×™×‘×•×™ ×¢× ×Ÿ ×œ××¡×“ × ×ª×•× ×™× × ×¤×¨×“  
- InternalBackup: ×’×™×‘×•×™ ×¤× ×™××™ ×‘××¡×“ ×”× ×ª×•× ×™×
- S3Backup: ×’×™×‘×•×™ ×œ-AWS S3
- DualBackup: ×’×™×‘×•×™ ×›×¤×•×œ ×œ-Dropbox + OneDrive
- RestoreManager: ×©×—×–×•×¨ ××›×œ ×”××§×•×¨×•×ª
- BackupScheduler: ×ª×–××•×Ÿ ×’×™×‘×•×™×™×
- BackupManager: × ×™×”×•×œ ××¨×›×–×™ ×©×œ ×›×œ ×”×’×™×‘×•×™×™×

ğŸ”„ ××—×œ×™×£:
- daily_backup.py, cloud_backup.py, organized_internal_backup.py
- aws_s3_backup.py, simple_dual_backup.py, enhanced_backup_system.py
- comprehensive_chat_restore.py, emergency_full_restore.py
- schedule_internal_backup.py, internal_backup_system.py
- organized_backup_system.py, backup_unused_tables.py
"""

import os
import json
import psycopg2
import shutil
import hashlib
import boto3
import threading
import schedule
import atexit
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from contextlib import contextmanager

from config import config
from simple_logger import logger
from admin_notifications import send_admin_notification
from database_operations import get_safe_db_connection

# ğŸ”’ ×˜×‘×œ××•×ª ×§×¨×™×˜×™×•×ª ×œ×’×™×‘×•×™
CRITICAL_TABLES = [
    "user_profiles",     # ×”×œ×‘ ×©×œ ×”××¢×¨×›×ª - ×§×•×“×™ ××™×©×•×¨ ×•××©×ª××©×™×
    "chat_messages",     # ×›×œ ×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×•×ª
    "interactions_log"   # ×›×œ ×”×§×¨×™××•×ª ×•×”×¢×œ×•×™×•×ª
]

# ğŸ¯ ×”×’×“×¨×•×ª ×’×œ×•×‘×œ×™×•×ª
DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")
BACKUP_DB_URL = os.getenv("BACKUP_DATABASE_URL")
BACKUP_DIR = "backups/daily_db_backups"
BACKUP_SCHEMA = "backup"
BACKUP_RETENTION_DAYS = 30

class LocalBackup:
    """ğŸ”’ ×’×™×‘×•×™ ×™×•××™ ×œ×§×‘×¦×™ JSON ×œ×•×§×œ×™×™×"""
    
    def __init__(self, backup_dir: str = BACKUP_DIR):
        self.backup_dir = backup_dir
        self.ensure_backup_dir()
    
    def ensure_backup_dir(self):
        """×™×•×¦×¨ ×ª×™×§×™×™×ª ×’×™×‘×•×™×™× ×× ×œ× ×§×™×™××ª"""
        os.makedirs(self.backup_dir, exist_ok=True)
    
    def backup_table_to_json(self, table_name: str, backup_date: str) -> int:
        """××’×‘×” ×˜×‘×œ×” ×™×—×™×“×” ×œ×§×•×‘×¥ JSON"""
        try:
            with get_safe_db_connection() as conn:
                cur = conn.cursor()
                
                # ×©×œ×™×¤×ª ×›×œ ×”× ×ª×•× ×™× ××”×˜×‘×œ×”
                cur.execute(f"SELECT * FROM {table_name}")
                rows = cur.fetchall()
                
                # ×©×œ×™×¤×ª ×©××•×ª ×”×¢××•×“×•×ª
                cur.execute(f"""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = '{table_name}' 
                    ORDER BY ordinal_position
                """)
                columns = [row[0] for row in cur.fetchall()]
                
                # ×”××¨×” ×œ-JSON
                data = []
                for row in rows:
                    row_dict = {}
                    for i, col in enumerate(columns):
                        value = row[i]
                        if isinstance(value, datetime):
                            value = value.isoformat()
                        row_dict[col] = value
                    data.append(row_dict)
                
                # ×©××™×¨×ª ×”×’×™×‘×•×™
                backup_file = f"{self.backup_dir}/{table_name}_{backup_date}.json"
                with open(backup_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2, default=str)
                
                logger.info(f"âœ… ×’×™×‘×•×™ {table_name}: {len(data)} ×©×•×¨×•×ª × ×©××¨×• ×œ-{backup_file}")
                return len(data)
                
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ {table_name}: {e}")
            return 0
    
    def create_backup_summary(self, backup_date: str, results: Dict[str, int]) -> Dict[str, Any]:
        """×™×•×¦×¨ ×§×•×‘×¥ ×¡×™×›×•× ×œ×’×™×‘×•×™"""
        summary = {
            "backup_date": backup_date,
            "backup_time": datetime.now().isoformat(),
            "tables_backed_up": len(results),
            "total_rows": sum(results.values()),
            "results": results,
            "backup_location": self.backup_dir
        }
        
        summary_file = f"{self.backup_dir}/backup_summary_{backup_date}.json"
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        return summary
    
    def cleanup_old_backups(self, days_to_keep: int = 30):
        """××—×™×§×ª ×’×™×‘×•×™×™× ×™×©× ×™×"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)
            
            for filename in os.listdir(self.backup_dir):
                file_path = os.path.join(self.backup_dir, filename)
                if os.path.isfile(file_path):
                    file_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                    if file_time < cutoff_date:
                        os.remove(file_path)
                        logger.info(f"ğŸ—‘ï¸ × ××—×§ ×’×™×‘×•×™ ×™×©×Ÿ: {filename}")
                        
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×: {e}")
    
    def run_backup(self) -> Optional[Dict[str, Any]]:
        """××¨×™×¥ ×’×™×‘×•×™ ×™×•××™ ××œ×"""
        try:
            logger.info("ğŸ”’ ××ª×—×™×œ ×’×™×‘×•×™ ×™×•××™ ×©×œ ×˜×‘×œ××•×ª ×§×¨×™×˜×™×•×ª")
            
            backup_date = datetime.now().strftime("%Y%m%d")
            backup_results = {}
            
            for table in CRITICAL_TABLES:
                rows_backed_up = self.backup_table_to_json(table, backup_date)
                backup_results[table] = rows_backed_up
            
            summary = self.create_backup_summary(backup_date, backup_results)
            self.cleanup_old_backups()
            
            logger.info(f"âœ… ×’×™×‘×•×™ ×™×•××™ ×”×•×©×œ×: {summary['total_rows']} ×©×•×¨×•×ª × ×©××¨×•")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×™×•××™: {e}")
            return None
    
    def restore_table_from_backup(self, table_name: str, backup_date: str) -> bool:
        """×©×—×–×•×¨ ×˜×‘×œ×” ××’×™×‘×•×™ JSON"""
        try:
            backup_file = f"{self.backup_dir}/{table_name}_{backup_date}.json"
            
            if not os.path.exists(backup_file):
                print(f"âŒ ×§×•×‘×¥ ×’×™×‘×•×™ ×œ× × ××¦×: {backup_file}")
                return False
            
            with open(backup_file, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)
            
            print(f"âš ï¸  ×©×—×–×•×¨ {table_name} ×-{backup_date}?")
            print(f"ğŸ“Š ×’×™×‘×•×™ ××›×™×œ: {len(backup_data)} ×©×•×¨×•×ª")
            
            confirm = input("×”×§×œ×“ 'YES' ×›×“×™ ×œ××©×¨: ")
            if confirm != "YES":
                print("âŒ ×©×—×–×•×¨ ×‘×•×˜×œ")
                return False
            
            with get_safe_db_connection() as conn:
                cur = conn.cursor()
                
                # ××—×™×§×ª × ×ª×•× ×™× × ×•×›×—×™×™×
                cur.execute(f"DELETE FROM {table_name}")
                
                # ×©×—×–×•×¨ ×”× ×ª×•× ×™×
                if backup_data:
                    columns = list(backup_data[0].keys())
                    placeholders = ', '.join(['%s'] * len(columns))
                    insert_sql = f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})"
                    
                    for row in backup_data:
                        values = [row[col] for col in columns]
                        cur.execute(insert_sql, values)
                
                conn.commit()
            
            print(f"âœ… ×©×—×–×•×¨ ×”×•×©×œ×: {len(backup_data)} ×©×•×¨×•×ª")
            logger.info(f"âœ… ×©×—×–×•×¨ {table_name} ×-{backup_date}: {len(backup_data)} ×©×•×¨×•×ª")
            return True
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨: {e}")
            return False


class CloudBackup:
    """â˜ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ ×œ××¡×“ × ×ª×•× ×™× × ×¤×¨×“"""
    
    def __init__(self, backup_db_url: str = BACKUP_DB_URL):
        self.backup_db_url = backup_db_url or DB_URL
        
    def setup_backup_database(self) -> str:
        """×™×•×¦×¨ ××¡×“ × ×ª×•× ×™× ×œ×’×™×‘×•×™×™× ×‘××¡×“ × ×¤×¨×“"""
        if not BACKUP_DB_URL:
            logger.warning("âš ï¸ BACKUP_DATABASE_URL ×œ× ××•×’×“×¨ - ××©×ª××© ×‘××¡×“ ×”×¨××©×™")
            return DB_URL
        
        try:
            conn = psycopg2.connect(self.backup_db_url)
            cur = conn.cursor()
            
            # ×™×¦×™×¨×ª ×˜×‘×œ×ª ×’×™×‘×•×™×™×
            cur.execute("""
                CREATE TABLE IF NOT EXISTS database_backups (
                    id SERIAL PRIMARY KEY,
                    backup_date DATE NOT NULL,
                    table_name TEXT NOT NULL,
                    backup_data JSONB NOT NULL,
                    backup_size_mb DECIMAL(10,2),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    checksum TEXT,
                    UNIQUE(backup_date, table_name)
                )
            """)
            
            # ×™×¦×™×¨×ª ××™× ×“×§×¡×™×
            cur.execute("""
                CREATE INDEX IF NOT EXISTS idx_backups_date_table 
                ON database_backups(backup_date, table_name)
            """)
            
            conn.commit()
            cur.close()
            conn.close()
            
            logger.info("âœ… ××¡×“ ×’×™×‘×•×™×™× ××•×›×Ÿ")
            return self.backup_db_url
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×”×›× ×ª ××¡×“ ×’×™×‘×•×™×™×: {e}")
            return DB_URL
    
    def calculate_checksum(self, data: List[Dict]) -> str:
        """××—×©×‘ checksum ×œ× ×ª×•× ×™×"""
        json_str = json.dumps(data, sort_keys=True, default=str)
        return hashlib.md5(json_str.encode()).hexdigest()
    
    def backup_table_to_cloud(self, table_name: str, backup_date: str, data: List[Dict]) -> bool:
        """××’×‘×” ×˜×‘×œ×” ×œ××¡×“ ×¢× ×Ÿ × ×¤×¨×“"""
        try:
            backup_db = self.setup_backup_database()
            conn = psycopg2.connect(backup_db)
            cur = conn.cursor()
            
            data_size_mb = len(json.dumps(data, default=str)) / (1024 * 1024)
            checksum = self.calculate_checksum(data)
            
            # ×©××™×¨×ª ×”×’×™×‘×•×™ (UPSERT)
            cur.execute("""
                INSERT INTO database_backups 
                (backup_date, table_name, backup_data, backup_size_mb, checksum)
                VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (backup_date, table_name)
                DO UPDATE SET 
                    backup_data = EXCLUDED.backup_data,
                    backup_size_mb = EXCLUDED.backup_size_mb,
                    checksum = EXCLUDED.checksum,
                    created_at = CURRENT_TIMESTAMP
            """, (backup_date, table_name, json.dumps(data, default=str), data_size_mb, checksum))
            
            conn.commit()
            cur.close()
            conn.close()
            
            logger.info(f"â˜ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ {table_name}: {len(data)} ×¨×©×•××•×ª ({data_size_mb:.2f}MB)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ {table_name}: {e}")
            return False
    
    def run_backup(self) -> bool:
        """××¨×™×¥ ×’×™×‘×•×™ ×¢× ×Ÿ ××œ×"""
        try:
            logger.info("â˜ï¸ ××ª×—×™×œ ×’×™×‘×•×™ ×¢× ×Ÿ")
            
            backup_date = datetime.now().strftime("%Y-%m-%d")
            successful_backups = 0
            
            for table in CRITICAL_TABLES:
                try:
                    with get_safe_db_connection() as conn:
                        cur = conn.cursor()
                        
                        cur.execute(f"SELECT * FROM {table}")
                        rows = cur.fetchall()
                        
                        cur.execute(f"""
                            SELECT column_name 
                            FROM information_schema.columns 
                            WHERE table_name = '{table}' 
                            ORDER BY ordinal_position
                        """)
                        columns = [row[0] for row in cur.fetchall()]
                        
                        data = []
                        for row in rows:
                            row_dict = {}
                            for i, col in enumerate(columns):
                                value = row[i]
                                if isinstance(value, datetime):
                                    value = value.isoformat()
                                row_dict[col] = value
                            data.append(row_dict)
                    
                    if self.backup_table_to_cloud(table, backup_date, data):
                        successful_backups += 1
                    
                except Exception as e:
                    logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ {table}: {e}")
            
            success = successful_backups == len(CRITICAL_TABLES)
            if success:
                logger.info(f"â˜ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ ×”×•×©×œ×: {successful_backups}/{len(CRITICAL_TABLES)} ×˜×‘×œ××•×ª")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ: {e}")
            return False


class InternalBackup:
    """ğŸ—„ï¸ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×‘××¡×“ ×”× ×ª×•× ×™×"""
    
    def __init__(self, schema_name: str = BACKUP_SCHEMA):
        self.schema_name = schema_name
        self.create_backup_schema()
    
    def create_backup_schema(self) -> bool:
        """×™×•×¦×¨ ××ª ×”-schema ×œ×’×™×‘×•×™ ×× ×œ× ×§×™×™×"""
        try:
            with get_safe_db_connection() as conn:
                cur = conn.cursor()
                cur.execute(f"CREATE SCHEMA IF NOT EXISTS {self.schema_name}")
                conn.commit()
            
            logger.info(f"âœ… Schema {self.schema_name} ××•×›×Ÿ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª backup schema: {e}")
            return False
    
    def backup_table_to_internal(self, table_name: str, backup_date: str) -> Optional[Dict[str, Any]]:
        """××’×‘×” ×˜×‘×œ×” ×œ×˜×‘×œ×ª ×’×™×‘×•×™ ×¤× ×™××™×ª"""
        try:
            with get_safe_db_connection() as conn:
                cur = conn.cursor()
                
                backup_table_name = f"{table_name}_backup_{backup_date}"
                full_backup_table = f"{self.schema_name}.{backup_table_name}"
                
                # ××—×™×§×ª ×”×˜×‘×œ×” ×× ×§×™×™××ª
                cur.execute(f"DROP TABLE IF EXISTS {full_backup_table}")
                
                # ×™×¦×™×¨×ª ×”×˜×‘×œ×” ×”×—×“×©×” ×¢× × ×ª×•× ×™ ×”×’×™×‘×•×™
                cur.execute(f"""
                    CREATE TABLE {full_backup_table} AS 
                    SELECT *, 
                           '{backup_date}' as backup_date,
                           '{datetime.now().isoformat()}' as backup_timestamp
                    FROM {table_name}
                """)
                
                # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª ×•×’×•×“×œ
                cur.execute(f"SELECT COUNT(*) FROM {full_backup_table}")
                records_count = cur.fetchone()[0]
                
                cur.execute(f"""
                    SELECT pg_size_pretty(pg_total_relation_size('{full_backup_table}'))
                """)
                table_size = cur.fetchone()[0]
                
                conn.commit()
            
            backup_info = {
                "table_name": table_name,
                "backup_table_name": backup_table_name,
                "full_backup_table": full_backup_table,
                "records_count": records_count,
                "table_size": table_size,
                "backup_date": backup_date,
                "confirmation_code": f"IB-{table_name.upper()[:3]}-{backup_date}-{records_count:04d}",
                "backup_timestamp": datetime.now()
            }
            
            logger.info(f"âœ… {table_name} â†’ {backup_table_name}: {records_count} ×¨×©×•××•×ª ({table_size})")
            return backup_info
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™ {table_name}: {e}")
            return None
    
    def run_backup(self) -> bool:
        """××¨×™×¥ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ××œ×"""
        try:
            backup_date = datetime.now().strftime("%d_%m_%Y")
            logger.info(f"ğŸ—„ï¸ ××ª×—×™×œ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×œ×ª××¨×™×š {backup_date}")
            
            backup_results = {}
            total_records = 0
            
            for table_name in CRITICAL_TABLES:
                backup_info = self.backup_table_to_internal(table_name, backup_date)
                if backup_info:
                    backup_results[table_name] = backup_info
                    total_records += backup_info["records_count"]
            
            success = len(backup_results) == len(CRITICAL_TABLES)
            if success:
                logger.info(f"ğŸ‰ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×”×•×©×œ×: {total_records} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨: {e}")
            return False


class S3Backup:
    """ğŸª£ ×’×™×‘×•×™ ×œ-AWS S3"""
    
    def __init__(self):
        self.aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
        self.aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
        self.bucket_name = os.getenv("AWS_S3_BUCKET_NAME", "telegram-bot-backups")
        self.region = os.getenv("AWS_REGION", "us-east-1")
    
    def is_configured(self) -> bool:
        """×‘×•×“×§ ×× AWS ××•×’×“×¨"""
        return bool(self.aws_access_key and self.aws_secret_key)
    
    def upload_to_s3(self, file_path: str, s3_key: str) -> bool:
        """××¢×œ×” ×§×•×‘×¥ ×œ-S3"""
        try:
            s3_client = boto3.client(
                's3',
                aws_access_key_id=self.aws_access_key,
                aws_secret_access_key=self.aws_secret_key,
                region_name=self.region
            )
            
            s3_client.upload_file(file_path, self.bucket_name, s3_key)
            logger.info(f"â˜ï¸ ×”×•×¢×œ×” ×œ-S3: {s3_key}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×”×¢×œ××” ×œ-S3: {e}")
            return False
    
    def run_backup(self, backup_dir: str = BACKUP_DIR) -> bool:
        """××’×‘×” ××ª ×›×œ ×§×‘×¦×™ ×”×’×™×‘×•×™ ×œ-S3"""
        if not self.is_configured():
            logger.warning("âš ï¸ AWS ×œ× ××•×’×“×¨ - ×“×•×œ×’ ×¢×œ ×’×™×‘×•×™ S3")
            return False
        
        try:
            backup_date = datetime.now().strftime("%Y%m%d")
            
            if not os.path.exists(backup_dir):
                logger.error("âŒ ×ª×™×§×™×™×ª ×’×™×‘×•×™×™× ×œ× ×§×™×™××ª")
                return False
            
            uploaded_files = 0
            for filename in os.listdir(backup_dir):
                if filename.endswith('.json'):
                    file_path = os.path.join(backup_dir, filename)
                    s3_key = f"daily_backups/{backup_date}/{filename}"
                    
                    if self.upload_to_s3(file_path, s3_key):
                        uploaded_files += 1
            
            logger.info(f"â˜ï¸ ×’×™×‘×•×™ S3 ×”×•×©×œ×: {uploaded_files} ×§×‘×¦×™×")
            return uploaded_files > 0
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ S3: {e}")
            return False


class DualBackup:
    """ğŸ“ ×’×™×‘×•×™ ×›×¤×•×œ - Dropbox + OneDrive"""
    
    def __init__(self, local_backup: LocalBackup):
        self.local_backup = local_backup
        self.onedrive_path = "C:/Users/ASUS/OneDrive"
    
    def copy_to_onedrive(self) -> bool:
        """××¢×ª×™×§ ××ª ×”×’×™×‘×•×™×™× ×œ-OneDrive"""
        try:
            source_dir = self.local_backup.backup_dir
            backup_date = datetime.now().strftime("%Y%m%d")
            target_dir = os.path.join(self.onedrive_path, "TelegramBot_Backups", backup_date)
            
            if not os.path.exists(source_dir):
                logger.error("âŒ ×ª×™×§×™×™×ª ×’×™×‘×•×™ ××§×•×¨ ×œ× ×§×™×™××ª")
                return False
            
            if not os.path.exists(self.onedrive_path):
                logger.error("âŒ OneDrive ×œ× × ××¦×")
                return False
            
            os.makedirs(target_dir, exist_ok=True)
            
            copied_files = 0
            total_size = 0
            
            for filename in os.listdir(source_dir):
                if filename.endswith('.json'):
                    source_file = os.path.join(source_dir, filename)
                    target_file = os.path.join(target_dir, filename)
                    
                    shutil.copy2(source_file, target_file)
                    
                    file_size = os.path.getsize(target_file)
                    total_size += file_size
                    copied_files += 1
                    
                    logger.info(f"ğŸ“„ ×”×•×¢×ª×§: {filename} ({file_size/1024/1024:.2f}MB)")
            
            if copied_files > 0:
                logger.info(f"ğŸ“ OneDrive: {copied_files} ×§×‘×¦×™× ({total_size/1024/1024:.2f}MB ×›×•×œ×œ)")
                return True
            else:
                logger.warning("âš ï¸ ×œ× × ××¦××• ×§×‘×¦×™× ×œ×”×¢×ª×§×”")
                return False
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×”×¢×ª×§×” ×œ-OneDrive: {e}")
            return False
    
    def run_backup(self) -> bool:
        """××¨×™×¥ ×’×™×‘×•×™ ×›×¤×•×œ - Dropbox + OneDrive"""
        try:
            logger.info("ğŸ“ ××ª×—×™×œ ×’×™×‘×•×™ ×›×¤×•×œ (Dropbox + OneDrive)")
            
            # 1. ×’×™×‘×•×™ ×¨×’×™×œ ×œ-Dropbox
            dropbox_success = self.local_backup.run_backup() is not None
            
            # 2. ×”×¢×ª×§×” × ×•×¡×¤×ª ×œ-OneDrive
            onedrive_success = self.copy_to_onedrive()
            
            return dropbox_success or onedrive_success
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×›×¤×•×œ: {e}")
            return False


class RestoreManager:
    """ğŸ”„ ×× ×”×œ ×©×—×–×•×¨ ××›×œ ×”××§×•×¨×•×ª"""
    
    def __init__(self, local_backup: LocalBackup, cloud_backup: CloudBackup):
        self.local_backup = local_backup
        self.cloud_backup = cloud_backup
    
    def restore_from_json_file(self, file_path: str, source_name: str) -> int:
        """×©×—×–×•×¨ ××§×•×‘×¥ JSON"""
        try:
            if not os.path.exists(file_path):
                print(f"âŒ ×§×•×‘×¥ ×œ× × ××¦×: {file_path}")
                return 0
            
            with open(file_path, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)
            
            print(f"ğŸ“„ {source_name}: {len(backup_data)} ×”×•×“×¢×•×ª")
            
            if not backup_data:
                return 0
            
            # ×©×—×–×•×¨ ×”×•×“×¢×•×ª ×œ××¡×“
            restored_count = 0
            with get_safe_db_connection() as conn:
                cur = conn.cursor()
                
                for message in backup_data:
                    try:
                        # ×‘×“×™×§×” ×× ×”×”×•×“×¢×” ×›×‘×¨ ×§×™×™××ª
                        if 'message_id' in message and 'chat_id' in message:
                            cur.execute("""
                                SELECT 1 FROM chat_messages 
                                WHERE message_id = %s AND chat_id = %s
                            """, (message['message_id'], message['chat_id']))
                            
                            if not cur.fetchone():
                                # ×”×•×¡×¤×ª ×”×”×•×“×¢×”
                                columns = list(message.keys())
                                placeholders = ', '.join(['%s'] * len(columns))
                                insert_sql = f"INSERT INTO chat_messages ({', '.join(columns)}) VALUES ({placeholders})"
                                values = [message[col] for col in columns]
                                cur.execute(insert_sql, values)
                                restored_count += 1
                    
                    except Exception as e:
                        logger.warning(f"âš ï¸ ×©×’×™××” ×‘×©×—×–×•×¨ ×”×•×“×¢×”: {e}")
                        continue
                
                conn.commit()
            
            print(f"âœ… {source_name}: ×©×•×—×–×¨×• {restored_count:,} ×”×•×“×¢×•×ª")
            return restored_count
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ {source_name}: {e}")
            return 0
    
    def comprehensive_restore(self) -> bool:
        """×©×—×–×•×¨ ××§×™×£ ××›×œ ×”××§×•×¨×•×ª"""
        try:
            print("ğŸš¨ ××ª×—×™×œ ×©×—×–×•×¨ ××§×™×£ ××›×œ ×”××§×•×¨×•×ª...")
            print("=" * 60)
            
            total_restored = 0
            
            # ××§×•×¨×•×ª ×©×—×–×•×¨
            restoration_sources = [
                ("backups/daily_db_backups/chat_messages_20250709.json", "daily_backup_09_07"),
                ("backups/data_backup_20250706_141212/chat_history.json", "old_backup_06_07"),
                ("extracted_chat_data_20250706_155957.json", "extracted_data_06_07")
            ]
            
            for file_path, source_name in restoration_sources:
                restored = self.restore_from_json_file(file_path, source_name)
                total_restored += restored
            
            print(f"\nğŸ‰ ×¡×™×›×•× ×©×—×–×•×¨ ××§×™×£:")
            print(f"   ğŸ“Š ×¡×”\"×› ×”×•×“×¢×•×ª ×©×©×•×—×–×¨×•: {total_restored:,}")
            
            return total_restored > 0
            
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ ××§×™×£: {e}")
            return False


class BackupScheduler:
    """â° ××ª×–××Ÿ ×’×™×‘×•×™×™× ××•×˜×•××˜×™×™×"""
    
    def __init__(self, backup_manager: 'BackupManager'):
        self.backup_manager = backup_manager
        self.is_running = False
    
    def start_scheduler(self) -> bool:
        """××ª×—×™×œ ××ª ××ª×–××Ÿ ×”×’×™×‘×•×™×™×"""
        try:
            schedule.every().day.at("03:00").do(self.backup_manager.run_all_backups)
            schedule.every().sunday.at("02:00").do(self.backup_manager.cleanup_old_backups)
            
            self.is_running = True
            logger.info("â° ××ª×–××Ÿ ×’×™×‘×•×™×™× ×”×•×¤×¢×œ")
            
            # ×”×¨×¦×” ×‘×¨×§×¢
            def run_scheduler():
                while self.is_running:
                    schedule.run_pending()
                    import time
                    time.sleep(60)
            
            scheduler_thread = threading.Thread(target=run_scheduler)
            scheduler_thread.daemon = True
            scheduler_thread.start()
            
            atexit.register(self.stop_scheduler)
            return True
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×”×¤×¢×œ×ª ××ª×–××Ÿ: {e}")
            return False
    
    def stop_scheduler(self):
        """×¢×•×¦×¨ ××ª ×”××ª×–××Ÿ"""
        self.is_running = False
        schedule.clear()
        logger.info("â° ××ª×–××Ÿ ×’×™×‘×•×™×™× × ×¢×¦×¨")
    
    def run_backup_now(self) -> bool:
        """××¨×™×¥ ×’×™×‘×•×™ ××™×™×“×™"""
        return self.backup_manager.run_all_backups()


class BackupManager:
    """ğŸ¯ ×× ×”×œ ××¨×›×–×™ ×©×œ ×›×œ ××¢×¨×›×ª ×”×’×™×‘×•×™"""
    
    def __init__(self):
        self.local_backup = LocalBackup()
        self.cloud_backup = CloudBackup()
        self.internal_backup = InternalBackup()
        self.s3_backup = S3Backup()
        self.dual_backup = DualBackup(self.local_backup)
        self.restore_manager = RestoreManager(self.local_backup, self.cloud_backup)
        self.scheduler = BackupScheduler(self)
    
    def run_all_backups(self) -> bool:
        """××¨×™×¥ ××ª ×›×œ ×¡×•×’×™ ×”×’×™×‘×•×™"""
        try:
            logger.info("ğŸš€ ××ª×—×™×œ ×’×™×‘×•×™ ××œ× ×©×œ ×›×œ ×”××¢×¨×›×ª")
            
            backup_results = {
                "local": False,
                "cloud": False,
                "internal": False,
                "s3": False,
                "dual": False
            }
            
            # 1. ×’×™×‘×•×™ ××§×•××™
            try:
                backup_results["local"] = self.local_backup.run_backup() is not None
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ××§×•××™: {e}")
            
            # 2. ×’×™×‘×•×™ ×¢× ×Ÿ
            try:
                backup_results["cloud"] = self.cloud_backup.run_backup()
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ: {e}")
            
            # 3. ×’×™×‘×•×™ ×¤× ×™××™
            try:
                backup_results["internal"] = self.internal_backup.run_backup()
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™: {e}")
            
            # 4. ×’×™×‘×•×™ S3 (×× ××•×’×“×¨)
            try:
                if self.s3_backup.is_configured():
                    backup_results["s3"] = self.s3_backup.run_backup()
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ S3: {e}")
            
            # 5. ×’×™×‘×•×™ ×›×¤×•×œ
            try:
                backup_results["dual"] = self.dual_backup.run_backup()
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×›×¤×•×œ: {e}")
            
            # ×¡×™×›×•×
            successful_backups = sum(backup_results.values())
            total_attempted = len([k for k, v in backup_results.items() if k != "s3" or self.s3_backup.is_configured()])
            
            logger.info(f"ğŸ¯ ×’×™×‘×•×™ ×”×•×©×œ×: {successful_backups}/{total_attempted} ×¡×•×’×™ ×’×™×‘×•×™")
            
            # ×”×ª×¨××” ×œ××“××™×Ÿ
            self.send_backup_notification(backup_results, successful_backups, total_attempted)
            
            return successful_backups > 0
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ××œ×: {e}")
            return False
    
    def send_backup_notification(self, results: Dict[str, bool], successful: int, total: int):
        """×©×•×œ×— ×”×ª×¨××” ×¢×œ ×¡×˜×˜×•×¡ ×”×’×™×‘×•×™"""
        try:
            status_icons = {True: "âœ…", False: "âŒ"}
            message = f"ğŸš€ **×’×™×‘×•×™ ××œ× ×”×•×©×œ×**\n\n"
            
            backup_names = {
                "local": "×’×™×‘×•×™ ××§×•××™ (JSON)",
                "cloud": "×’×™×‘×•×™ ×¢× ×Ÿ (××¡×“ × ×¤×¨×“)",
                "internal": "×’×™×‘×•×™ ×¤× ×™××™ (schema)",
                "s3": "×’×™×‘×•×™ AWS S3",
                "dual": "×’×™×‘×•×™ ×›×¤×•×œ (OneDrive)"
            }
            
            for backup_type, success in results.items():
                if backup_type == "s3" and not self.s3_backup.is_configured():
                    continue
                icon = status_icons[success]
                name = backup_names[backup_type]
                message += f"{icon} **{name}**\n"
            
            message += f"\nğŸ“Š **×ª×•×¦××•×ª:** {successful}/{total} ×’×™×‘×•×™×™× ×”×¦×œ×™×—×•"
            
            if successful == 0:
                message += "\nğŸš¨ **××–×”×¨×”:** ×›×œ ×”×’×™×‘×•×™×™× × ×›×©×œ×•!"
                urgent = True
            elif successful < total:
                message += "\nâš ï¸ **××–×”×¨×”:** ×—×œ×§ ××”×’×™×‘×•×™×™× × ×›×©×œ×•"
                urgent = False
            else:
                message += "\nğŸ‰ **××¢×•×œ×”:** ×›×œ ×”×’×™×‘×•×™×™× ×”×¦×œ×™×—×•!"
                urgent = False
            
            send_admin_notification(message, urgent=urgent)
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”×ª×¨××ª ×’×™×‘×•×™: {e}")
    
    def cleanup_old_backups(self):
        """×× ×§×” ×’×™×‘×•×™×™× ×™×©× ×™× ×‘×›×œ ×”××¢×¨×›×•×ª"""
        try:
            logger.info("ğŸ§¹ ××ª×—×™×œ × ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×")
            
            # × ×™×§×•×™ ×’×™×‘×•×™×™× ××§×•××™×™×
            self.local_backup.cleanup_old_backups()
            
            logger.info("âœ… × ×™×§×•×™ ×’×™×‘×•×™×™× ×”×•×©×œ×")
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™×: {e}")
    
    def get_backup_status(self) -> Dict[str, Any]:
        """××—×–×™×¨ ×¡×˜×˜×•×¡ ××¤×•×¨×˜ ×©×œ ×›×œ ××¢×¨×›×•×ª ×”×’×™×‘×•×™"""
        try:
            status = {
                "local_backup_dir": os.path.exists(self.local_backup.backup_dir),
                "cloud_backup_configured": bool(BACKUP_DB_URL),
                "s3_configured": self.s3_backup.is_configured(),
                "onedrive_available": os.path.exists(self.dual_backup.onedrive_path),
                "scheduler_running": self.scheduler.is_running,
                "last_backup_time": None
            }
            
            # ×‘×“×™×§×ª ×–××Ÿ ×’×™×‘×•×™ ××—×¨×•×Ÿ
            if os.path.exists(self.local_backup.backup_dir):
                backup_files = [f for f in os.listdir(self.local_backup.backup_dir) if f.endswith('.json')]
                if backup_files:
                    latest_file = max(backup_files, key=lambda x: os.path.getmtime(os.path.join(self.local_backup.backup_dir, x)))
                    status["last_backup_time"] = datetime.fromtimestamp(
                        os.path.getmtime(os.path.join(self.local_backup.backup_dir, latest_file))
                    ).isoformat()
            
            return status
            
        except Exception as e:
            logger.error(f"âŒ ×©×’×™××” ×‘×§×‘×œ×ª ×¡×˜×˜×•×¡ ×’×™×‘×•×™: {e}")
            return {}


# ğŸ¯ ×¤×•× ×§×¦×™×•×ª × ×•×—×•×ª ×œ×©×™××•×© ××”×™×¨×•×”×©×ª××©
def run_daily_backup() -> bool:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×’×™×‘×•×™ ×™×•××™"""
    manager = BackupManager()
    return manager.local_backup.run_backup() is not None

def run_cloud_backup() -> bool:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×’×™×‘×•×™ ×¢× ×Ÿ"""
    manager = BackupManager()
    return manager.cloud_backup.run_backup()

def run_full_backup() -> bool:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×’×™×‘×•×™ ××œ×"""
    manager = BackupManager()
    return manager.run_all_backups()

def comprehensive_restore() -> bool:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×©×—×–×•×¨ ××§×™×£"""
    manager = BackupManager()
    return manager.restore_manager.comprehensive_restore()

def start_backup_scheduler() -> bool:
    """×¤×•× ×§×¦×™×” × ×•×—×” ×œ×”×¤×¢×œ×ª ××ª×–××Ÿ"""
    manager = BackupManager()
    return manager.scheduler.start_scheduler()


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ğŸ”’ ××¢×¨×›×ª ×’×™×‘×•×™ ×××•×—×“×ª")
        print("========================")
        print("×©×™××•×©: python backup_system.py [command] [options]")
        print()
        print("×¤×§×•×“×•×ª ×–××™× ×•×ª:")
        print("  backup          - ×’×™×‘×•×™ ×™×•××™ ××§×•××™")
        print("  cloud           - ×’×™×‘×•×™ ×¢× ×Ÿ")
        print("  internal        - ×’×™×‘×•×™ ×¤× ×™××™")
        print("  s3              - ×’×™×‘×•×™ AWS S3")
        print("  dual            - ×’×™×‘×•×™ ×›×¤×•×œ")
        print("  full            - ×’×™×‘×•×™ ××œ× (×›×œ ×”×¡×•×’×™×)")
        print("  restore         - ×©×—×–×•×¨ ××§×™×£")
        print("  schedule start  - ×”×¤×¢×œ×ª ××ª×–××Ÿ")
        print("  schedule stop   - ×¢×¦×™×¨×ª ××ª×–××Ÿ")
        print("  status          - ×¡×˜×˜×•×¡ ××¢×¨×›×ª")
        print("  cleanup         - × ×™×§×•×™ ×’×™×‘×•×™×™× ×™×©× ×™×")
        sys.exit(1)
    
    command = sys.argv[1]
    manager = BackupManager()
    
    if command == "backup":
        success = manager.local_backup.run_backup()
        print("âœ… ×’×™×‘×•×™ ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ × ×›×©×œ")
    
    elif command == "cloud":
        success = manager.cloud_backup.run_backup()
        print("âœ… ×’×™×‘×•×™ ×¢× ×Ÿ ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ ×¢× ×Ÿ × ×›×©×œ")
    
    elif command == "internal":
        success = manager.internal_backup.run_backup()
        print("âœ… ×’×™×‘×•×™ ×¤× ×™××™ ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ ×¤× ×™××™ × ×›×©×œ")
    
    elif command == "s3":
        success = manager.s3_backup.run_backup()
        print("âœ… ×’×™×‘×•×™ S3 ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ S3 × ×›×©×œ")
    
    elif command == "dual":
        success = manager.dual_backup.run_backup()
        print("âœ… ×’×™×‘×•×™ ×›×¤×•×œ ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ ×›×¤×•×œ × ×›×©×œ")
    
    elif command == "full":
        success = manager.run_all_backups()
        print("âœ… ×’×™×‘×•×™ ××œ× ×”×•×©×œ×" if success else "âŒ ×’×™×‘×•×™ ××œ× × ×›×©×œ")
    
    elif command == "restore":
        success = manager.restore_manager.comprehensive_restore()
        print("âœ… ×©×—×–×•×¨ ×”×•×©×œ×" if success else "âŒ ×©×—×–×•×¨ × ×›×©×œ")
    
    elif command == "schedule":
        if len(sys.argv) > 2:
            if sys.argv[2] == "start":
                success = manager.scheduler.start_scheduler()
                print("âœ… ××ª×–××Ÿ ×”×•×¤×¢×œ" if success else "âŒ ×”×¤×¢×œ×ª ××ª×–××Ÿ × ×›×©×œ×”")
            elif sys.argv[2] == "stop":
                manager.scheduler.stop_scheduler()
                print("âœ… ××ª×–××Ÿ × ×¢×¦×¨")
        else:
            print("×©×™××•×©: python backup_system.py schedule [start|stop]")
    
    elif command == "status":
        status = manager.get_backup_status()
        print("ğŸ“Š ×¡×˜×˜×•×¡ ××¢×¨×›×ª ×”×’×™×‘×•×™:")
        print("=" * 30)
        for key, value in status.items():
            icon = "âœ…" if value else "âŒ"
            print(f"{icon} {key}: {value}")
    
    elif command == "cleanup":
        manager.cleanup_old_backups()
        print("âœ… × ×™×§×•×™ ×”×•×©×œ×")
    
    else:
        print(f"âŒ ×¤×§×•×“×” ×œ× ××•×›×¨×ª: {command}")
        sys.exit(1) 