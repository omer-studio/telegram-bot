"""
================================================================================
ğŸš¨ ×—×©×•×‘ ×××•×“ - ×©×ª×™ ×¡×‘×™×‘×•×ª × ×¤×¨×“×•×ª! ğŸš¨
================================================================================

×¡×‘×™×‘×” 1 - ×¨× ×“×¨ (×™×™×¦×•×¨):
   - ×”×§×•×‘×¥ ×”×–×” ×¨×¥ ×™×©×™×¨×•×ª: python main.py
   - ×œ× ××©×ª××© ×‘-ngrok
   - ×œ× ××©×ª××© ×‘-sandbox.py
   - ×¨×¥ ×¢×œ ×¤×•×¨×˜ 8000 ×¢× HTTP server ×¤×©×•×˜

×¡×‘×™×‘×” 2 - ×œ×•×§××œ×™×ª (×¤×™×ª×•×—):
   - ×”×§×•×‘×¥ ×”×–×” ×¨×¥ ×“×¨×š sandbox.py: python sandbox.py
   - ××©×ª××© ×‘-ngrok
   - ×¨×¥ ×¢×œ ×¤×•×¨×˜ 10000 ×¢× uvicorn

âš ï¸  ××œ ×ª×©× ×” ××ª ×”×§×•×‘×¥ ×”×–×” ×›×“×™ ×©×™×ª××™× ×œ×¡×‘×™×‘×” ×œ×•×§××œ×™×ª!
   ×”×¡×‘×™×‘×” ×‘×¨× ×“×¨ ×œ× ×××•×¨×” ×œ×“×¢×ª ×‘×›×œ×œ ×¢×œ sandbox.py!
   ×›×œ ×©×™× ×•×™ ×›××Ÿ ×™×©×¤×™×¢ ×¢×œ ×”×¡×‘×™×‘×” ×‘×¨× ×“×¨!

ğŸš¨ ×”×¤×¢×œ×” ×‘×¡×‘×™×‘×” ×œ×•×§××œ×™×ª:
   python sandbox.py  âœ…
   
   ××œ ×ª×¤×¢×™×œ ×™×©×™×¨×•×ª:
   python main.py  âŒ

================================================================================

bot_setup.py
------------
×§×•×‘×¥ ×–×” ×¢×•×¡×§ ×¨×§ ×‘×”×’×“×¨×•×ª ×•×”×›× ×•×ª ×›×œ×œ×™×•×ª ×©×œ ×”×‘×•×˜ (×©××™× ×Ÿ ×ª×œ×•×™×•×ª ×¡×‘×™×‘×”).
×”×¨×¦×™×•× ×œ: ××ª×—×•×œ ×¡×‘×™×‘×ª×™, ×—×™×‘×•×¨ ×œ-Google Sheets, ×ª×–××•×Ÿ ×“×•×—×•×ª, ×•×”×•×¡×¤×ª handlers.
"""

# =============================================
# bot_setup.py â€” ×¡×˜××¤ ×›×œ×œ×™ ×©×œ ×”×‘×•×˜ (×œ× ×ª×œ×•×™ ×¡×‘×™×‘×”)
# -------------------------------------------------------------
# ××™×Ÿ ×œ×”×¤×¢×™×œ ×›××Ÿ ngrok ××• ×”×’×“×¨×ª webhook ×œ-local!
# ×›×œ ×§×•×“ ×¡×‘×™×‘×ª ×¤×™×ª×•×— ×œ×•×§××œ×™×ª (×›×•×œ×œ ngrok/webhook) × ××¦× ××š ×•×¨×§ ×‘-sandbox.py
# =============================================

import os
import subprocess
import sys
import time
import requests
import logging
from telegram.ext import ApplicationBuilder, MessageHandler, filters, CommandHandler
from config import TELEGRAM_BOT_TOKEN, config
from sheets_handler import increment_code_try, get_user_summary, update_user_profile, log_to_sheets, check_user_access, register_user, approve_user
from notifications import send_startup_notification
from messages import get_welcome_messages
from utils import log_event_to_file, update_chat_history, get_chat_history_messages, send_error_stats_report, send_usage_report
from gpt_a_handler import get_main_response
from gpt_b_handler import get_summary
from apscheduler.schedulers.background import BackgroundScheduler
# from daily_summary import send_daily_summary  # ×–×× ×™×ª ××•×©×‘×ª - ×”×§×•×‘×¥ ×œ× ×§×™×™×

async def send_daily_summary(days_back=1):
    """×¤×•× ×§×¦×™×” ×–×× ×™×ª - ×™×© ×œ×™×¦×•×¨ ××ª daily_summary.py ×‘×¢×ª×™×“"""
    print(f"ğŸ“Š [DAILY_SUMMARY] ×–×× ×™×ª ××•×©×‘×ª - ×¦×¨×™×š ×œ×™×¦×•×¨ daily_summary.py")
    return True
import pytz
from message_handler import handle_message
from notifications import gentle_reminder_background_task
from db_manager import create_tables, save_chat_message, save_user_profile, save_gpt_usage_log, save_gpt_call_log, save_critical_user_data, save_reminder_state, save_billing_usage_data, save_errors_stats_data, save_bot_error_log, save_bot_trace_log, save_sync_queue_data, save_rollback_data, save_free_model_limits_data, save_temp_critical_user_data
import json
import psycopg2
import datetime
import asyncio

# ×”×’×“×¨×ª DB_URL
DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")

# ×¨×©×™××” ×œ×©××™×¨×ª ×–×× ×™ ×‘×™×¦×•×¢
execution_times = {}

def time_operation(operation_name):
    """××§×™×©×˜ ×¤×•× ×§×¦×™×” ×œ××“×™×“×ª ×–××Ÿ ×‘×™×¦×•×¢"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            print(f"â±ï¸  ××ª×—×™×œ {operation_name}...")
            result = func(*args, **kwargs)
            elapsed_time = time.time() - start_time
            execution_times[operation_name] = elapsed_time
            print(f"âœ… {operation_name} ×”×•×©×œ× ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª")
            return result
        return wrapper
    return decorator

def print_execution_summary():
    """××“×¤×™×¡ ×˜×‘×œ×” ××¡×›××ª ×©×œ ×–×× ×™ ×”×‘×™×¦×•×¢"""
    print("\n" + "="*70)
    print("ğŸ“Š ×¡×™×›×•× ××¤×•×¨×˜ ×©×œ ×–×× ×™ ×‘×™×¦×•×¢ ×”×”×ª×§× ×”")
    print("="*70)
    print(f"{'×¤×¢×•×œ×”':<45} {'×–××Ÿ (×©× ×™×•×ª)':<12} {'×–××Ÿ (×“×§×•×ª)':<8}")
    print("-" * 70)
    
    # ××™×•×Ÿ ×œ×¤×™ ×¡×“×¨ ×‘×™×¦×•×¢ - ×§×˜×’×•×¨×™×•×ª ×¢×™×§×¨×™×•×ª ×•××—×¨ ×›×š ×¤×¨×˜×™×
    main_operations = []
    sub_operations = []
    
    for operation, duration in execution_times.items():
        if "×¡×”×´×›" in operation:
            main_operations.append((operation, duration))
        else:
            sub_operations.append((operation, duration))
    
    total_time = 0
    
    # ×”×“×¤×¡×ª ×§×˜×’×•×¨×™×•×ª ×¢×™×§×¨×™×•×ª
    print("ğŸ—ï¸ ×©×œ×‘×™× ×¢×™×§×¨×™×™×:")
    for operation, duration in main_operations:
        total_time += duration
        minutes = duration / 60
        print(f"  {operation:<43} {duration:>8.2f}      {minutes:>6.2f}")
    
    print()
    print("ğŸ” ×¤×™×¨×•×˜ ×©×œ×‘×™ ××©× ×”:")
    
    # ×”×“×¤×¡×ª ×¤×¨×˜×™× ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª
    categories = {
        "×§×‘×¦×™×": [op for op in sub_operations if "×§×•×‘×¥" in op[0]],
        "×ª×œ×•×™×•×ª": [op for op in sub_operations if any(x in op[0] for x in ["×¢×“×›×•×Ÿ", "requirements", "uvicorn", "requests"])],
        "×˜×œ×’×¨×": [op for op in sub_operations if any(x in op[0] for x in ["××¤×œ×™×§×¦×™×”", "concurrent", "×‘×¡×™×¡×™×ª", "××™× ×™××œ×™×ª"])],
        "Google Sheets": [op for op in sub_operations if any(x in op[0] for x in ["×¡×¤×¨×™×•×ª", "×”×¨×©××•×ª", "API", "×’×™×œ×™×•×Ÿ", "××©×ª××©×™×", "××¦×‘×™×"])],
        "×ª×–××•×Ÿ": [op for op in sub_operations if any(x in op[0] for x in ["××–×•×¨ ×–××Ÿ", "××ª×–××Ÿ", "×“×•×—", "×¡×™×›×•×", "×”×¤×¢×œ×ª"])],
        "××—×¨": [op for op in sub_operations if not any(cat in op[0] for cat in ["×§×•×‘×¥", "×¢×“×›×•×Ÿ", "requirements", "uvicorn", "requests", "××¤×œ×™×§×¦×™×”", "concurrent", "×‘×¡×™×¡×™×ª", "××™× ×™××œ×™×ª", "×¡×¤×¨×™×•×ª", "×”×¨×©××•×ª", "API", "×’×™×œ×™×•×Ÿ", "××©×ª××©×™×", "××¦×‘×™×", "××–×•×¨ ×–××Ÿ", "××ª×–××Ÿ", "×“×•×—", "×¡×™×›×•×", "×”×¤×¢×œ×ª"])]
    }
    
    for category, operations in categories.items():
        if operations:
            print(f"\n  ğŸ“ {category}:")
            for operation, duration in operations:
                minutes = duration / 60
                if duration < 0.01:  # ×¤×—×•×ª ×-0.01 ×©× ×™×”
                    print(f"    {operation:<39} {duration:>8.3f}      {minutes:>6.3f}")
                else:
                    print(f"    {operation:<39} {duration:>8.2f}      {minutes:>6.2f}")
    
    print("\n" + "-" * 70)
    total_minutes = total_time / 60
    print(f"{'ğŸ¯ ×¡×”×´×› ×–××Ÿ ×”×ª×§× ×” ×›×•×œ×œ':<45} {total_time:>8.2f}      {total_minutes:>6.2f}")
    print("="*70)

def setup_single_critical_file(file_path):
    """×™×•×¦×¨ ×§×•×‘×¥ ×§×¨×™×˜×™ ×™×—×™×“ ×¢× ××“×™×“×ª ×–××Ÿ"""
    start_time = time.time()
    file_name = os.path.basename(file_path)
    
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    if not os.path.exists(file_path):
        with open(file_path, 'w', encoding='utf-8') as f:
            if file_path.endswith('.json'):
                f.write('{}')
            else:
                f.write('')
        status = "× ×•×¦×¨"
    else:
        status = "×§×™×™×"
    
    elapsed_time = time.time() - start_time
    execution_times[f"×§×•×‘×¥ {file_name}"] = elapsed_time
    return status

@time_operation("×‘×“×™×§×ª ×§×™×•× ×§×‘×¦×™× ×§×¨×™×˜×™×™× - ×¡×”×´×›")
def setup_critical_files():
    """×™×•×¦×¨ ×§×‘×¦×™× ×§×¨×™×˜×™×™× ×”× ×“×¨×©×™× ×œ×¤×¢×•×œ×ª ×”×‘×•×˜"""
    critical_files = [
        "data/gpt_usage_log.jsonl",
        "data/chat_history.json", 
        "data/bot_errors.jsonl"
    ]
    
    print(f"[SETUP] ğŸ” ×‘×•×“×§ {len(critical_files)} ×§×‘×¦×™× ×§×¨×™×˜×™×™×...")
    
    # ××™×—×•×“ ×”×“×¤×¡×•×ª ×©×œ ×§×‘×¦×™× ×§×¨×™×˜×™×™×
    file_statuses = []
    for file_path in critical_files:
        status = setup_single_critical_file(file_path)
        file_statuses.append(f"{os.path.basename(file_path)} ({status})")
    
    print(f"[SETUP] ğŸ“ ×§×‘×¦×™× ×§×¨×™×˜×™×™×: {', '.join(file_statuses)}")

@time_operation("×‘×“×™×§×ª ×•×”×›× ×ª ×¡×‘×™×‘×” ×•×™×¨×˜×•××œ×™×ª")
def setup_virtual_environment():
    """×‘×•×“×§ ×•×™×•×¦×¨ venv ×‘××™×“×ª ×”×¦×•×¨×š (Windows ×‘×œ×‘×“)"""
    # ğŸ”§ ×ª×™×§×•×Ÿ: ×‘×¡×‘×™×‘×ª production ×œ× ×¦×¨×™×š venv
    if os.getenv("RENDER"):  # ×× ×¨×¥ ×‘×¨× ×“×¨
        print("[SETUP] â„¹ï¸  ×¨×¥ ×‘×¡×‘×™×‘×ª production - ××“×œ×’ ×¢×œ ×™×¦×™×¨×ª venv")
        return
        
    if os.name == 'nt':
        venv_path = os.path.join(os.getcwd(), 'venv')
        if not os.path.exists(venv_path):
            print('[SETUP] ğŸ”§ ×™×•×¦×¨ venv ×—×“×©...')
            subprocess.run([sys.executable, '-m', 'venv', 'venv'])
        else:
            print('[SETUP] âœ… venv ×§×™×™×')

def install_single_dependency(pip_command, description):
    """××ª×§×™×Ÿ dependency ×™×—×™×“ ×¢× ××“×™×“×ª ×–××Ÿ"""
    start_time = time.time()
    print(f"â±ï¸  ××ª×§×™×Ÿ {description}...")
    
    # ğŸ”§ ×ª×™×§×•×Ÿ: ×‘×¡×‘×™×‘×ª production ×œ× ××ª×§×™×Ÿ
    if os.getenv("RENDER"):  # ×× ×¨×¥ ×‘×¨× ×“×¨
        elapsed_time = time.time() - start_time
        execution_times[description] = elapsed_time
        print(f"â„¹ï¸  {description} - ××“×œ×’ (production) ×ª×•×š {elapsed_time:.3f} ×©× ×™×•×ª")
        return type('Result', (), {'returncode': 0})()  # mock result
    
    result = subprocess.run(pip_command, capture_output=True, text=True)
    elapsed_time = time.time() - start_time
    execution_times[description] = elapsed_time
    if result.returncode == 0:
        print(f"âœ… {description} ×”×•×ª×§×Ÿ ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª")
    else:
        print(f"âš ï¸ {description} - ×™×© ×‘×¢×™×” (××š ×××©×™×š): {elapsed_time:.2f} ×©× ×™×•×ª")
    return result

@time_operation("×”×ª×§× ×ª ×ª×œ×•×™×•×ª - ×¡×”×´×›")
def install_dependencies():
    """
    ××ª×§×™×Ÿ ×ª×œ×•×™×•×ª Python (×¨×§ ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— ××§×•××™)
    ×‘×¡×‘×™×‘×ª production (×¨× ×“×¨) ××• ×‘sandbox mode - ××“×œ×’ ×¢×œ ×”×ª×§× ×”
    """
    print("[SETUP] ğŸ“¦ ×‘×•×“×§ ×”×ª×§× ×ª ×ª×œ×•×™×•×ª...")
    
    # ğŸ”§ ×ª×™×§×•×Ÿ ×—×©×•×‘: ×× ×™×¢×ª ×”×ª×§× ×•×ª ×‘sandbox ×•×‘production
    if os.getenv("RENDER"):
        print("[SETUP] â„¹ï¸  ×¨×¥ ×‘×¡×‘×™×‘×ª production (×¨× ×“×¨) - ××“×œ×’ ×¢×œ ×”×ª×§× ×ª ×ª×œ×•×™×•×ª")
        print("[SETUP]    (×”×ª×œ×•×™×•×ª ×›×‘×¨ ×××•×¨×•×ª ×œ×”×™×•×ª ××•×ª×§× ×•×ª ××”-requirements.txt)")
        return
    
    # ×‘×“×™×§×” × ×•×¡×¤×ª: ×× ×–×” sandbox mode
    if any(arg in sys.argv[0].lower() for arg in ["sandbox", "uvicorn"]):
        print("[SETUP] â„¹ï¸  ×¨×¥ ×‘××¦×‘ sandbox - ××“×œ×’ ×¢×œ ×”×ª×§× ×ª ×ª×œ×•×™×•×ª")
        return
    
    # ×¨×§ ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— ××§×•××™ (Windows ×‘×“×¨×š ×›×œ×œ)
    print("[SETUP] ğŸ”§ ×¡×‘×™×‘×ª ×¤×™×ª×•×— ××§×•××™ - ×‘×•×“×§ ×ª×œ×•×™×•×ª...")
    
    pip_commands = [
        ([sys.executable, "-m", "pip", "install", "--upgrade", "pip"], "×¢×“×›×•×Ÿ pip"),
        ([sys.executable, "-m", "pip", "install", "python-telegram-bot[webhooks]"], "python-telegram-bot"),
        ([sys.executable, "-m", "pip", "install", "gspread", "oauth2client"], "Google Sheets"),
        ([sys.executable, "-m", "pip", "install", "fastapi", "uvicorn[standard]"], "FastAPI & Uvicorn"),
        ([sys.executable, "-m", "pip", "install", "litellm"], "LiteLLM"),
        ([sys.executable, "-m", "pip", "install", "openai"], "OpenAI"),
        ([sys.executable, "-m", "pip", "install", "anthropic"], "Anthropic"),
        ([sys.executable, "-m", "pip", "install", "google-generativeai"], "Google Generative AI"),
        ([sys.executable, "-m", "pip", "install", "apscheduler", "pytz"], "×ª×–××•×Ÿ"),
        ([sys.executable, "-m", "pip", "install", "requests"], "Requests")
        # ğŸ”§ ×ª×™×§×•×Ÿ ×–×× ×™: ×”×¡×¨×ª whisper ×¢×“ ×¤×ª×¨×•×Ÿ ×‘×¢×™×™×ª ×”×–×™×›×¨×•×Ÿ
        # ([sys.executable, "-m", "pip", "install", "openai-whisper"], "Whisper")
    ]
    
    for pip_command, description in pip_commands:
        install_single_dependency(pip_command, description)

def time_telegram_step(step_name, func):
    """××•×“×“ ×–××Ÿ ×œ×©×œ×‘ ×‘×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×™×ª ×˜×œ×’×¨×"""
    start_time = time.time()
    print(f"â±ï¸  {step_name}...")
    try:
        result = func()
        elapsed_time = time.time() - start_time
        execution_times[step_name] = elapsed_time
        print(f"âœ… {step_name} ×”×•×©×œ× ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª")
        return result
    except Exception as e:
        elapsed_time = time.time() - start_time
        execution_times[step_name] = elapsed_time
        print(f"âš ï¸ {step_name} × ×›×©×œ ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª: {e}")
        raise

@time_operation("×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×™×ª ×˜×œ×’×¨× - ×¡×”×´×›")
def create_telegram_app():
    """×™×•×¦×¨ ××¤×œ×™×§×¦×™×™×ª ×˜×œ×’×¨× ×¢× ×”×’×“×¨×•×ª ××ª×§×“××•×ª"""
    global app
    
    # × ×™×¡×™×•×Ÿ 1: ×”×’×“×¨×•×ª ××œ××•×ª
    try:
        def build_full_featured_app():
            return ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).concurrent_updates(True).read_timeout(30).job_queue(None).build()
        
        app = time_telegram_step("×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×” ×¢× concurrent_updates", build_full_featured_app)
        return
    except Exception as e:
        print(f"âš ï¸ ×‘×¢×™×” ×¢× ApplicationBuilder (× ×™×¡×™×•×Ÿ 1): {e}")
        
        # × ×™×¡×™×•×Ÿ 2: ×”×’×“×¨×•×ª ×‘×¡×™×¡×™×•×ª
        try:
            def build_basic_app():
                return ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).read_timeout(30).job_queue(None).build()
            
            app = time_telegram_step("×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×” ×‘×¡×™×¡×™×ª", build_basic_app)
            return
        except Exception as e2:
            print(f"âš ï¸ ×‘×¢×™×” ×¢× ApplicationBuilder (× ×™×¡×™×•×Ÿ 2): {e2}")
        
        # × ×™×¡×™×•×Ÿ 3: ××™× ×™××œ×™×¡×˜×™
        try:
            def build_minimal_app():
                return ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
            
            app = time_telegram_step("×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×” ××™× ×™××œ×™×ª", build_minimal_app)
        except Exception as e3:
            print(f"âŒ ×›×©×œ ×‘×›×œ × ×™×¡×™×•× ×•×ª ×™×¦×™×¨×ª ××¤×œ×™×§×¦×™×™×ª ×˜×œ×’×¨×: {e3}")
            raise

def time_google_sheets_step(step_name, func):
    """××•×“×“ ×–××Ÿ ×œ×©×œ×‘ ×‘×—×™×‘×•×¨ Google Sheets"""
    start_time = time.time()
    print(f"â±ï¸  {step_name}...")
    result = func()
    elapsed_time = time.time() - start_time
    execution_times[step_name] = elapsed_time
    print(f"âœ… {step_name} ×”×•×©×œ× ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª")
    return result

# ×—×™×‘×•×¨ ×œ-Google Sheets
@time_operation("×—×™×‘×•×¨ ×œ-Google Sheets - ×¡×”×´×›")
def connect_google_sheets(): # ××ª×—×‘×¨ ×œ-Google Sheets, ×˜×•×¢×Ÿ ×’×™×œ×™×•× ×•×ª ×¢×™×§×¨×™×™×, ×•×©×•××¨ ××•×ª× ×‘-bot_data
    """
    ××ª×—×‘×¨ ×œ-Google Sheets, ×˜×•×¢×Ÿ ×’×™×œ×™×•× ×•×ª ×¢×™×§×¨×™×™×, ×•×©×•××¨ ××•×ª× ×‘-bot_data.
    ×¤×œ×˜: ××™×Ÿ (××¢×“×›×Ÿ app.bot_data)
    """
    try:
        logging.info("ğŸ”— ××ª×—×‘×¨ ×œ-Google Sheets...")
        
        # ×©×œ×‘ 1: ×˜×¢×™× ×ª ×¡×¤×¨×™×•×ª
        def load_libraries():
            try:
                import gspread
                from oauth2client.service_account import ServiceAccountCredentials
                return gspread, ServiceAccountCredentials
            except ImportError as e:
                print(f"âš ï¸ Warning: Failed to import Google Sheets libraries: {e}")
                # ×™×¦×™×¨×ª dummy classes
                class DummyGspread:
                    def authorize(self, creds):
                        return self
                    def open_by_key(self, key):
                        return self
                    def worksheet(self, name):
                        return self
                    def get_all_values(self):
                        return []
                
                class DummyServiceAccountCredentials:
                    @staticmethod
                    def from_json_keyfile_dict(data, scope):
                        return DummyServiceAccountCredentials()
                
                return DummyGspread(), DummyServiceAccountCredentials
        
        gspread, ServiceAccountCredentials = time_google_sheets_step("×˜×¢×™× ×ª ×¡×¤×¨×™×•×ª Google Sheets", load_libraries)
        
        # ×©×œ×‘ 2: ×”×’×“×¨×ª ×”×¨×©××•×ª
        def setup_credentials():
            scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
            return ServiceAccountCredentials.from_json_keyfile_dict(config["SERVICE_ACCOUNT_DICT"], scope)
        
        creds = time_google_sheets_step("×”×’×“×¨×ª ×”×¨×©××•×ª Google", setup_credentials)
        
        # ×©×œ×‘ 3: ×”×ª×—×‘×¨×•×ª ×œ-API
        def authorize_client():
            return gspread.authorize(creds)
        
        client = time_google_sheets_step("×”×ª×—×‘×¨×•×ª ×œ-Google Sheets API", authorize_client)
        
        # ×©×œ×‘ 4: ×¤×ª×™×—×ª ×”×’×™×œ×™×•×Ÿ ×”×¨××©×™
        def open_main_sheet():
            return client.open_by_key(config["GOOGLE_SHEET_ID"])
        
        spreadsheet = time_google_sheets_step("×¤×ª×™×—×ª ×”×’×™×œ×™×•×Ÿ ×”×¨××©×™", open_main_sheet)
        
        # ×©×œ×‘ 5: ×˜×¢×™× ×ª ×’×™×œ×™×•×Ÿ ××©×ª××©×™×
        def load_users_sheet():
            return spreadsheet.worksheet(config["SHEET_USER_TAB"])
        
        sheet = time_google_sheets_step("×˜×¢×™× ×ª ×’×™×œ×™×•×Ÿ ××©×ª××©×™×", load_users_sheet)
        
        # ×©×œ×‘ 6: ×˜×¢×™× ×ª ×’×™×œ×™×•×Ÿ ××¦×‘×™×
        def load_states_sheet():
            return spreadsheet.worksheet(config["SHEET_STATES_TAB"])
        
        sheet_states = time_google_sheets_step("×˜×¢×™× ×ª ×’×™×œ×™×•×Ÿ ××¦×‘×™×", load_states_sheet)
        
        # ×©××™×¨×” ×‘××¤×œ×™×§×¦×™×”
        app.bot_data["sheet"] = sheet
        app.bot_data["sheet_states"] = sheet_states
        
        logging.info("âœ… ×—×™×‘×•×¨ ×œ-Google Sheets ×‘×•×¦×¢ ×‘×”×¦×œ×—×”")
        print("âœ… ×—×™×‘×•×¨ ×œ-Google Sheets ×‘×•×¦×¢ ×‘×”×¦×œ×—×”")
    except Exception as ex:
        logging.critical(f"âŒ ×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-Google Sheets: {ex}")
        print(f"âŒ ×©×’×™××” ×‘×”×ª×—×‘×¨×•×ª ×œ-Google Sheets: {ex}")
        raise

# === ×ª×–××•×Ÿ ×“×•×—×•×ª ××•×˜×•××˜×™×™× ×œ××“××™×Ÿ ===
def time_scheduler_step(step_name, func):
    """××•×“×“ ×–××Ÿ ×œ×©×œ×‘ ×‘×”×’×“×¨×ª ×ª×–××•×Ÿ"""
    start_time = time.time()
    print(f"â±ï¸  {step_name}...")
    result = func()
    elapsed_time = time.time() - start_time
    execution_times[step_name] = elapsed_time
    print(f"âœ… {step_name} ×”×•×©×œ× ×ª×•×š {elapsed_time:.2f} ×©× ×™×•×ª")
    return result

# ××ª×–××Ÿ ×’×œ×•×‘×œ×™ ×œ×©××™×¨×”
_admin_scheduler = None

@time_operation("×”×’×“×¨×ª ×ª×–××•×Ÿ ×“×•×—×•×ª ××•×˜×•××˜×™×™× - ×¡×”×´×›")
def setup_admin_reports(): # ××ª×–××Ÿ ×“×•×—×•×ª ××•×˜×•××˜×™×™× ×œ××“××™×Ÿ (×©×’×™××•×ª ×•-usage) ×œ×©×¢×” 8:00 ×‘×‘×•×§×¨
    """
    ××ª×–××Ÿ ×“×•×—×•×ª ××•×˜×•××˜×™×™× ×œ××“××™×Ÿ (×©×’×™××•×ª ×•-usage) ×œ×©×¢×” 8:00 ×‘×‘×•×§×¨.
    ×¤×œ×˜: ××™×Ÿ (××ª×–××Ÿ ×“×•×—×•×ª)
    """
    global _admin_scheduler
    
    # ×”×’×“×¨×ª ××–×•×¨ ×–××Ÿ
    def setup_timezone():
        return pytz.timezone("Asia/Jerusalem")
    
    tz = time_scheduler_step("×”×’×“×¨×ª ××–×•×¨ ×–××Ÿ ×™×©×¨××œ", setup_timezone)
    
    # ×™×¦×™×¨×ª ××ª×–××Ÿ
    def create_scheduler():
        global _admin_scheduler
        scheduler = BackgroundScheduler(timezone=tz)
        _admin_scheduler = scheduler  # ×©××™×¨×” ×’×œ×•×‘×œ×™×ª
        return scheduler
    
    scheduler = time_scheduler_step("×™×¦×™×¨×ª ××ª×–××Ÿ ×¨×§×¢", create_scheduler)
    
    # ×”×•×¡×¤×ª ×ª×–××•×Ÿ ×“×•×— ×©×’×™××•×ª
    def add_error_report_job():
        scheduler.add_job(send_error_stats_report, 'cron', hour=8, minute=0)
        return "×ª×–××•×Ÿ ×“×•×— ×©×’×™××•×ª × ×•×¡×£"
    
    time_scheduler_step("×”×•×¡×¤×ª ×ª×–××•×Ÿ ×“×•×— ×©×’×™××•×ª", add_error_report_job)
    
    # ×”×•×¡×¤×ª ×ª×–××•×Ÿ ×“×•×— ×©×™××•×©
    def add_usage_report_job():
        scheduler.add_job(lambda: send_usage_report(1), 'cron', hour=8, minute=0)
        return "×ª×–××•×Ÿ ×“×•×— ×©×™××•×© × ×•×¡×£"
    
    time_scheduler_step("×”×•×¡×¤×ª ×ª×–××•×Ÿ ×“×•×— ×©×™××•×©", add_usage_report_job)

    # ×”×•×¡×¤×ª ×ª×–××•×Ÿ ×¡×™×›×•× ×™×•××™
    def add_daily_summary_job():
        def run_daily_summary():
            """Wrapper ×¤×•× ×§×¦×™×” ×©××¨×™×¦×” ××ª ×”×¤×•× ×§×¦×™×” async ×‘×¦×•×¨×” × ×›×•× ×”"""
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(send_daily_summary(days_back=1))
            loop.close()
        
        scheduler.add_job(run_daily_summary, 'cron', hour=8, minute=0)  #×œ× ×œ××—×•×§!! ×“×•×— ×›×¡×¤×™× ×™×•××™ ×¢×œ ××ª××•×œ ×œ× ×œ××—×•×§ ×œ×¢×•×œ× ×œ× ××©× ×” ××”
        return "×ª×–××•×Ÿ ×¡×™×›×•× ×™×•××™ × ×•×¡×£"
    
    time_scheduler_step("×”×•×¡×¤×ª ×ª×–××•×Ÿ ×¡×™×›×•× ×™×•××™", add_daily_summary_job)

    # ×”×¤×¢×œ×ª ×”××ª×–××Ÿ
    def start_scheduler():
        scheduler.start()
        return "××ª×–××Ÿ ×”×•×¤×¢×œ"
    
    time_scheduler_step("×”×¤×¢×œ×ª ×”××ª×–××Ÿ", start_scheduler)
    
    print("âœ… ×ª×–××•×Ÿ ×“×•×—×•×ª ××“××™×Ÿ ×”×•×¤×¢×œ (8:00 ×™×•××™)")
    
    # ×”×“×¤×¡×ª ×¡×˜×˜×•×¡ ×”××ª×–××Ÿ
    if _admin_scheduler:
        print(f"ğŸ“… ××ª×–××Ÿ ×¤×¢×™×œ: {_admin_scheduler.running}")
        print(f"ğŸ“‹ ××©×™××•×ª ××ª×•×–×× ×•×ª: {len(_admin_scheduler.get_jobs())}")
        for job in _admin_scheduler.get_jobs():
            print(f"   - {job.name}: {job.next_run_time}")
    else:
        print("âš ï¸ ××ª×–××Ÿ ×œ× × ×•×¦×¨!")

@time_operation("×”×’×“×¨×ª ××¢×¨×›×ª ×ª×–×›×•×¨×•×ª ×¢×“×™× ×•×ª")
def setup_gentle_reminders():
    """××ª×—×™×œ ××ª ××©×™××ª ×”×¨×§×¢ ×œ×ª×–×›×•×¨×•×ª ×¢×“×™× ×•×ª"""
    try:
        # ×”×ª×—×œ×ª background task ×œ×ª×–×›×•×¨×•×ª
        import asyncio
        import threading
        
        def reminder_task():
            """××©×™××ª ×¨×§×¢ ×‘thread × ×¤×¨×“ ×œ×ª×–×›×•×¨×•×ª"""
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(gentle_reminder_background_task())
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘××©×™××ª ×ª×–×›×•×¨×•×ª ×¨×§×¢: {e}")
                logging.error(f"Error in reminder background task: {e}")
        
        # ×”×¤×¢×œ×” ×‘-thread × ×¤×¨×“ ×›×“×™ ×œ× ×œ×—×¡×•× ××ª ×”×‘×•×˜
        reminder_thread = threading.Thread(target=reminder_task, daemon=True)
        reminder_thread.start()
        
        print("âœ… ××¢×¨×›×ª ×ª×–×›×•×¨×•×ª ×¢×“×™× ×•×ª ×”×•×¤×¢×œ×” (×‘×“×™×§×” ×›×œ ×©×¢×”)")
        logging.info("Gentle reminder system started")
        
    except Exception as e:
        print(f"âš ï¸ ×‘×¢×™×” ×‘×”×ª×—×œ×ª ××¢×¨×›×ª ×ª×–×›×•×¨×•×ª: {e}")
        logging.error(f"Failed to start gentle reminder system: {e}")

@time_operation("×”×•×¡×¤×ª handlers ×œ×”×•×“×¢×•×ª")
def setup_message_handlers():
    """××•×¡×™×£ handlers ×œ×˜×™×¤×•×œ ×‘×”×•×“×¢×•×ª ×˜×§×¡×˜ ×•×¤×§×•×“×•×ª"""
    start_time = time.time()
    print(f"â±ï¸  ××•×¡×™×£ handlers ×œ×”×•×“×¢×•×ª...")
    
    # ×”×•×¡×¤×ª handler ×œ×”×•×“×¢×•×ª ×˜×§×¡×˜
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    # ×”×•×¡×¤×ª handler ×œ×¤×§×•×“×ª ××™×’×¨×¦×™×”
    app.add_handler(CommandHandler("migrate_all_data", handle_migrate_command))
    
    # ×”×•×¡×¤×ª handler ×œ×¤×§×•×“×ª ×œ×•×’×™×
    app.add_handler(CommandHandler("show_logs", handle_show_logs_command))
    
    # ×”×•×¡×¤×ª handler ×œ×¤×§×•×“×ª ×—×™×¤×•×© ×œ×•×’×™×
    app.add_handler(CommandHandler("search_logs", handle_search_logs_command))
    
    elapsed_time = time.time() - start_time
    execution_times["×”×•×¡×¤×ª message handlers"] = elapsed_time
    print(f"âœ… Message handlers × ×•×¡×¤×• ×ª×•×š {elapsed_time:.3f} ×©× ×™×•×ª")

@time_operation("×©×œ×™×—×ª ×”×ª×¨××ª ×”×¤×¢×œ×”")
def send_startup_notification_timed():
    """×©×•×œ×— ×”×ª×¨××” ×¢×œ ×”×¤×¢×œ×ª ×”×‘×•×˜"""
    # ğŸ”§ ×ª×™×§×•×Ÿ: ×¨×§ ×× ×œ× ×‘sandbox mode ×•×œ× ×‘setup ×›×¤×•×œ
    if not os.getenv("RENDER") and not _setup_completed:
        print("â„¹ï¸  ×¨×¥ ×‘×¡×‘×™×‘×ª ×¤×™×ª×•×— - ××“×œ×’ ×¢×œ ×”×ª×¨××ª startup")
        return
    elif _setup_completed:
        print("â„¹ï¸  ×”×ª×¨××ª startup ×›×‘×¨ × ×©×œ×—×” - ××“×œ×’")
        return
    send_startup_notification()

# ×ª×–××•×Ÿ ×“×•×—×•×ª ×™×ª×‘×¦×¢ ×›×—×œ×§ ××”×ª×§× ×ª ×”×‘×•×˜

# ğŸ”§ ×ª×™×§×•×Ÿ: ×× ×™×¢×ª setup ×›×¤×•×œ
_setup_completed = False

# ×¤×•× ×§×¦×™×” ×©××‘×¦×¢×ª ××ª ×›×œ ×”×”×ª×§× ×”
def setup_bot(): # ××‘×¦×¢ ××ª ×›×œ ×”×”×ª×§× ×” ×”×¨××©×•× ×™×ª ×©×œ ×”×‘×•×˜: ×—×™×‘×•×¨ Sheets, ×©×œ×™×—×ª ×”×ª×¨××”, ×”×—×–×¨×ª app
    """
    ××‘×¦×¢ ××ª ×›×œ ×”×”×ª×§× ×” ×”×¨××©×•× ×™×ª ×©×œ ×”×‘×•×˜: ×—×™×‘×•×¨ Sheets, ×©×œ×™×—×ª ×”×ª×¨××”, ×”×—×–×¨×ª app.
    ×¤×œ×˜: app (××¤×œ×™×§×¦×™×™×ª ×˜×œ×’×¨×)
    """
    global _setup_completed, app
    
    if _setup_completed and app:
        print("â„¹ï¸  ×”×‘×•×˜ ×›×‘×¨ ×”×•×’×“×¨, ××—×–×™×¨ instance ×§×™×™×")
        return app
    
    print("ğŸš€ ××ª×—×™×œ ×”×ª×§× ×” ×©×œ ×”×‘×•×˜...")
    
    # ×‘×™×¦×•×¢ ×›×œ ×©×œ×‘×™ ×”×”×ª×§× ×” ×¢× ××“×™×“×ª ×–××Ÿ
    setup_critical_files()
    setup_virtual_environment()
    install_dependencies()
    create_telegram_app()
    connect_google_sheets()
    setup_admin_reports()
    setup_gentle_reminders()
    setup_message_handlers()
    send_startup_notification_timed()
    
    # ×©×œ×™×—×ª ×“×•×— ×›×¡×¤×™ ×™×•××™ ×‘××ª×—×•×œ (×‘-thread × ×¤×¨×“, ×œ× ××¢×›×‘ ××ª ×”×‘×•×˜)
    def _send_daily_summary_startup():
        import asyncio
        print("ğŸ”¥ [STARTUP] ×©×•×œ×— ×“×•×— ×›×¡×¤×™ ×™×•××™ ×‘××ª×—×•×œ...")
        try:
            # ×™×¦×™×¨×ª event loop ×—×“×© ×‘×ª×•×š ×”-thread
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            loop.run_until_complete(send_daily_summary(days_back=1))
            loop.close()
            print("âœ… [STARTUP] ×“×•×— ×›×¡×¤×™ ×™×•××™ × ×©×œ×— ×‘×”×¦×œ×—×” ×‘××ª×—×•×œ!")
        except Exception as e:
            print(f"âŒ [STARTUP] ×©×’×™××” ×‘×©×œ×™×—×ª ×“×•×— ×›×¡×¤×™ ×‘××ª×—×•×œ: {e}")
    import threading
    threading.Thread(target=_send_daily_summary_startup, daemon=True).start()
    
    # ×”×“×¤×¡×ª ×¡×™×›×•× ×–×× ×™ ×”×‘×™×¦×•×¢
    print_execution_summary()
    
    print("ğŸ‰ ×”×”×ª×§× ×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!")
    
    _setup_completed = True
    return app

def get_scheduler_status():
    """××—×–×™×¨ ×¡×˜×˜×•×¡ ×”××ª×–××Ÿ ×”× ×•×›×—×™"""
    global _admin_scheduler
    if not _admin_scheduler:
        return {"status": "×œ× × ×•×¦×¨", "running": False, "jobs": 0}
    
    return {
        "status": "×¤×¢×™×œ" if _admin_scheduler.running else "×œ× ×¤×¢×™×œ",
        "running": _admin_scheduler.running,
        "jobs": len(_admin_scheduler.get_jobs()),
        "job_details": [
            {
                "name": job.name or "×œ×œ× ×©×",
                "next_run": str(job.next_run_time) if job.next_run_time else "×œ× ××ª×•×–××Ÿ"
            }
            for job in _admin_scheduler.get_jobs()
        ]
    }

def backup_data_to_drive():
    """××‘×¦×¢ ×’×™×‘×•×™ ×©×œ ×›×œ ×§×‘×¦×™ data/ ×œ-Google Drive"""
    try:
        print("ğŸ“ ××ª×—×™×œ ×’×™×‘×•×™ ×œ-Google Drive...")
        
        # âš ï¸ ×–×× ×™×ª: ××“×œ×’ ×¢×œ ×’×™×‘×•×™ ×›×“×™ ×œ× ×œ×¢×›×‘ ××ª ×”××™×’×¨×¦×™×”
        print("â„¹ï¸ ××“×œ×’ ×¢×œ ×’×™×‘×•×™ Google Drive ×›×“×™ ×œ× ×œ×¢×›×‘ ××ª ×”××™×’×¨×¦×™×”")
        print("âœ… ×”××©×š ××™×’×¨×¦×™×” ×œ×œ× ×’×™×‘×•×™ (×§×‘×¦×™× ×”××§×•×¨×™×™× × ×©××¨×™×)")
        
        return True
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™: {e}")
        return False

def migrate_data_to_sql_with_safety():
    """××‘×¦×¢ ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×©×œ ×›×œ ×”× ×ª×•× ×™× ×-data/ ×œ-SQL ×¢× ×“×™×‘××’ ××¤×•×¨×˜"""
    try:
        # ×‘×“×™×§×” ××”×™×¨×” ×× ×™×© × ×ª×•× ×™× ×œ××™×’×¨×¦×™×”
        def has_data_to_migrate():
            data_files = [
                "data/chat_history.json",
                "data/user_profiles.json", 
                "data/gpt_usage_log.jsonl",
                "data/openai_calls.jsonl"
            ]
            
            for file_path in data_files:
                if os.path.exists(file_path):
                    try:
                        if os.path.getsize(file_path) > 10:  # ×™×•×ª×¨ ×-10 bytes
                            return True
                    except:
                        pass
            return False
        
        if not has_data_to_migrate():
            print("â„¹ï¸ ××™×Ÿ × ×ª×•× ×™× ×œ××™×’×¨×¦×™×” - ×”××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×” ×œ×œ× ×¤×¢×•×œ×”")
            return True
        
        print("ğŸ” === ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×¢× ×§×•×“ ×¡×•×“×™ ===")
        print("ğŸš¨ ×× ×’× ×•× ×™ ×‘×˜×™×—×•×ª ××•×¤×¢×œ×™×:")
        print("   âœ… ×’×™×‘×•×™ ××•×˜×•××˜×™ ×œ×¤× ×™ ××™×’×¨×¦×™×”")
        print("   âœ… ×‘×“×™×§×ª ×ª×§×™× ×•×ª × ×ª×•× ×™×")
        print("   âœ… ×“×™×‘××’ ××¤×•×¨×˜ ×œ×›×œ ×©×œ×‘")
        print("   âœ… ×¢×¦×™×¨×” ×‘×©×’×™××”")
        print("   âœ… ×œ×•×’ ××¤×•×¨×˜ ×©×œ ×›×œ ×¤×¢×•×œ×”")
        print("   âœ… ××™××•×ª ×©×œ××•×ª × ×ª×•× ×™×")
        
        # === ×©×œ×‘ 1: ×’×™×‘×•×™ ××•×˜×•××˜×™ ===
        print("\nğŸ“ ×©×œ×‘ 1: ×’×™×‘×•×™ ××•×˜×•××˜×™ ×œ-Google Drive...")
        backup_success = backup_data_to_drive()
        if not backup_success:
            print("âŒ ×”×’×™×‘×•×™ × ×›×©×œ - ×”××™×’×¨×¦×™×” × ×¢×¦×¨×ª!")
            return False
        print("âœ… ×’×™×‘×•×™ ×”×•×©×œ× ×‘×”×¦×œ×—×”")
        
        # === ×©×œ×‘ 2: ×™×¦×™×¨×ª ×˜×‘×œ××•×ª ===
        print("\nğŸ—„ï¸ ×©×œ×‘ 2: ×™×¦×™×¨×ª/×‘×“×™×§×ª ×˜×‘×œ××•×ª SQL...")
        create_tables()
        print("âœ… ×˜×‘×œ××•×ª SQL ××•×›× ×•×ª")
        
        # === ×©×œ×‘ 3: ×¡×¤×™×¨×ª × ×ª×•× ×™× ×œ×¤× ×™ ××™×’×¨×¦×™×” ===
        print("\nğŸ“Š ×©×œ×‘ 3: ×¡×¤×™×¨×ª × ×ª×•× ×™× ×œ×¤× ×™ ××™×’×¨×¦×™×”...")
        pre_migration_counts = count_existing_data()
        print(f"ğŸ“ˆ × ×ª×•× ×™× ×§×™×™××™× ×‘-SQL: {pre_migration_counts}")
        
        # === ×©×œ×‘ 4: ××™×’×¨×¦×™×” ×¢× ×“×™×‘××’ ××¤×•×¨×˜ ===
        print("\nğŸ”„ ×©×œ×‘ 4: ××™×’×¨×¦×™×” ×¢× ×“×™×‘××’ ××¤×•×¨×˜...")
        migration_results = perform_detailed_migration()
        
        # === ×©×œ×‘ 5: ××™××•×ª ×©×œ××•×ª × ×ª×•× ×™× ===
        print("\nğŸ” ×©×œ×‘ 5: ××™××•×ª ×©×œ××•×ª × ×ª×•× ×™×...")
        post_migration_counts = count_existing_data()
        verification_results = verify_data_integrity(pre_migration_counts, post_migration_counts, migration_results)
        
        # === ×©×œ×‘ 6: ×¡×™×›×•× ××¤×•×¨×˜ ===
        print("\nğŸ“‹ ×©×œ×‘ 6: ×¡×™×›×•× ××¤×•×¨×˜...")
        print_detailed_summary(migration_results, verification_results)
        
        print("\nğŸ‰ === ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”! ===")
        return True
        
    except Exception as e:
        print(f"\nâŒ === ×©×’×™××” ×§×¨×™×˜×™×ª ×‘××™×’×¨×¦×™×” ===\n{str(e)}")
        print("ğŸš¨ ×”××™×’×¨×¦×™×” × ×¢×¦×¨×” - ×”× ×ª×•× ×™× ×”××§×•×¨×™×™× ×œ× × ×¤×’×¢×•!")
        return False

def count_existing_data():
    """×¡×•×¤×¨ × ×ª×•× ×™× ×§×™×™××™× ×‘-SQL"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        counts = {}
        
        # ×¡×¤×™×¨×ª ×”×•×“×¢×•×ª ×¦'××˜
        try:
            cur.execute("SELECT COUNT(*) FROM chat_messages")
            counts['chat_messages'] = cur.fetchone()[0]
        except:
            counts['chat_messages'] = 0
        
        # ×¡×¤×™×¨×ª ×¤×¨×•×¤×™×œ×™×
        try:
            cur.execute("SELECT COUNT(*) FROM user_profiles")
            counts['user_profiles'] = cur.fetchone()[0]
        except:
            counts['user_profiles'] = 0
        
        # ×¡×¤×™×¨×ª ×§×¨×™××•×ª GPT
        try:
            cur.execute("SELECT COUNT(*) FROM gpt_calls_log")
            counts['gpt_calls'] = cur.fetchone()[0]
        except:
            counts['gpt_calls'] = 0
        
        # ×¡×¤×™×¨×ª ×©×™××•×©
        try:
            cur.execute("SELECT COUNT(*) FROM gpt_usage_log")
            counts['gpt_usage'] = cur.fetchone()[0]
        except:
            counts['gpt_usage'] = 0
        
        # ×¡×¤×™×¨×ª ××©×ª××©×™× ×§×¨×™×˜×™×™×
        try:
            cur.execute("SELECT COUNT(*) FROM critical_users")
            counts['critical_users'] = cur.fetchone()[0]
        except:
            counts['critical_users'] = 0
        
        # ×¡×¤×™×¨×ª ×ª×–×›×•×¨×•×ª
        try:
            cur.execute("SELECT COUNT(*) FROM reminder_states")
            counts['reminder_states'] = cur.fetchone()[0]
        except:
            counts['reminder_states'] = 0
        
        # ×¡×¤×™×¨×ª × ×ª×•× ×™ ×—×™×•×‘
        try:
            cur.execute("SELECT COUNT(*) FROM billing_usage")
            counts['billing_usage'] = cur.fetchone()[0]
        except:
            counts['billing_usage'] = 0
        
        # ×¡×¤×™×¨×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×’×™××•×ª
        try:
            cur.execute("SELECT COUNT(*) FROM errors_stats")
            counts['errors_stats'] = cur.fetchone()[0]
        except:
            counts['errors_stats'] = 0
        
        # ×¡×¤×™×¨×ª ×œ×•×’×™ ×©×’×™××•×ª ×‘×•×˜
        try:
            cur.execute("SELECT COUNT(*) FROM bot_error_logs")
            counts['bot_errors'] = cur.fetchone()[0]
        except:
            counts['bot_errors'] = 0
        
        # ×¡×¤×™×¨×ª ×œ×•×’×™ trace ×‘×•×˜
        try:
            cur.execute("SELECT COUNT(*) FROM bot_trace_logs")
            counts['bot_trace'] = cur.fetchone()[0]
        except:
            counts['bot_trace'] = 0
        
        # ×¡×¤×™×¨×ª ×ª×•×¨ ×¡× ×›×¨×•×Ÿ
        try:
            cur.execute("SELECT COUNT(*) FROM sync_queue")
            counts['sync_queue'] = cur.fetchone()[0]
        except:
            counts['sync_queue'] = 0
        
        # ×¡×¤×™×¨×ª × ×ª×•× ×™ rollback
        try:
            cur.execute("SELECT COUNT(*) FROM rollback_data")
            counts['rollback_data'] = cur.fetchone()[0]
        except:
            counts['rollback_data'] = 0
        
        # ×¡×¤×™×¨×ª ××’×‘×œ×•×ª ××•×“×œ ×—×™× ××™
        try:
            cur.execute("SELECT COUNT(*) FROM free_model_limits")
            counts['free_limits'] = cur.fetchone()[0]
        except:
            counts['free_limits'] = 0
        
        # ×¡×¤×™×¨×ª ×§×‘×¦×™× ×–×× ×™×™×
        try:
            cur.execute("SELECT COUNT(*) FROM temp_critical_files")
            counts['temp_files'] = cur.fetchone()[0]
        except:
            counts['temp_files'] = 0
        
        cur.close()
        conn.close()
        
        return counts
        
    except Exception as e:
        print(f"âš ï¸ ×©×’×™××” ×‘×¡×¤×™×¨×ª × ×ª×•× ×™×: {e}")
        return {}

def perform_detailed_migration():
    """××‘×¦×¢ ××™×’×¨×¦×™×” ××¤×•×¨×˜×ª ×¢× ×“×™×‘××’"""
    results = {
        'chat_messages': {'migrated': 0, 'errors': 0, 'details': []},
        'user_profiles': {'migrated': 0, 'errors': 0, 'details': []},
        'gpt_usage': {'migrated': 0, 'errors': 0, 'details': []},
        'gpt_calls': {'migrated': 0, 'errors': 0, 'details': []},
        'critical_users': {'migrated': 0, 'errors': 0, 'details': []},
        'reminder_state': {'migrated': 0, 'errors': 0, 'details': []},
        'billing_usage': {'migrated': 0, 'errors': 0, 'details': []},
        'errors_stats': {'migrated': 0, 'errors': 0, 'details': []},
        'bot_errors': {'migrated': 0, 'errors': 0, 'details': []},
        'bot_trace': {'migrated': 0, 'errors': 0, 'details': []},
        'sync_queue': {'migrated': 0, 'errors': 0, 'details': []},
        'rollback_data': {'migrated': 0, 'errors': 0, 'details': []},
        'free_limits': {'migrated': 0, 'errors': 0, 'details': []},
        'temp_files': {'migrated': 0, 'errors': 0, 'details': []}
    }
    
    # === ××™×’×¨×¦×™×™×ª chat_history.json ===
    print("  ğŸ“ ××™×’×¨×¦×™×™×ª chat_history.json...")
    try:
        chat_history_path = "data/chat_history.json"
        if os.path.exists(chat_history_path):
            with open(chat_history_path, 'r', encoding='utf-8') as f:
                chat_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• {len(chat_data)} ×¦'××˜×™× ×œ××™×’×¨×¦×™×”")
            
            # ×¡×™×›×•× ×¤×™×¨×•×˜ ×œ×›×œ chat_id
            chat_summary = {}
            
            for chat_id, chat_info in chat_data.items():
                if "history" in chat_info:
                    history_count = len(chat_info["history"])
                    chat_summary[chat_id] = {'total': history_count, 'migrated': 0, 'errors': 0}
                    print(f"    ğŸ’¬ ××™×’×¨×¦×™×™×ª ×¦'××˜ {chat_id}: {history_count} ×”×•×“×¢×•×ª")
                    
                    for i, entry in enumerate(chat_info["history"]):
                        try:
                            user_msg = entry.get("user", "")
                            bot_msg = entry.get("bot", "")
                            timestamp_str = entry.get("timestamp", "")
                            
                            # ×”××¨×ª timestamp
                            from datetime import datetime
                            try:
                                if timestamp_str:
                                    timestamp = datetime.fromisoformat(timestamp_str.replace("Z", ""))
                                else:
                                    timestamp = datetime.utcnow()
                            except:
                                timestamp = datetime.utcnow()
                            
                            # ×©××™×¨×” ×œ-SQL
                            save_chat_message(chat_id, user_msg, bot_msg, timestamp)
                            results['chat_messages']['migrated'] += 1
                            chat_summary[chat_id]['migrated'] += 1
                            
                            if i % 100 == 0:  # ×“×™×‘××’ ×›×œ 100 ×”×•×“×¢×•×ª
                                print(f"      âœ… ×”×•×¢×‘×¨×• {i+1}/{history_count} ×”×•×“×¢×•×ª")
                                
                        except Exception as e:
                            results['chat_messages']['errors'] += 1
                            chat_summary[chat_id]['errors'] += 1
                            results['chat_messages']['details'].append(f"×©×’×™××” ×‘×”×•×“×¢×” {i} ×‘×¦'××˜ {chat_id}: {e}")
                            print(f"      âš ï¸ ×©×’×™××” ×‘×”×•×“×¢×” {i}: {e}")
                            continue
                    
                    print(f"    âœ… ×¦'××˜ {chat_id} ×”×•×©×œ×: {chat_summary[chat_id]['migrated']}/{chat_summary[chat_id]['total']} ×”×•×“×¢×•×ª")
            
            # ×¡×™×›×•× ××¤×•×¨×˜ ×œ×›×œ chat_id
            print(f"\n    ğŸ“‹ === ×¡×™×›×•× ××¤×•×¨×˜ ×œ×›×œ chat_id ===")
            for chat_id, summary in chat_summary.items():
                success_rate = (summary['migrated'] / summary['total'] * 100) if summary['total'] > 0 else 0
                status = "âœ…" if summary['errors'] == 0 else "âš ï¸"
                print(f"    {status} ×¦'××˜ {chat_id}: {summary['migrated']}/{summary['total']} ×”×•×“×¢×•×ª ({success_rate:.1f}%)")
                if summary['errors'] > 0:
                    print(f"        âŒ ×©×’×™××•×ª: {summary['errors']}")
            
            results['chat_messages']['chat_details'] = chat_summary
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ chat_history.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª chat_history: {e}")
        results['chat_messages']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª user_profiles.json ===
    print("  ğŸ‘¤ ××™×’×¨×¦×™×™×ª user_profiles.json...")
    try:
        user_profiles_path = "data/user_profiles.json"
        if os.path.exists(user_profiles_path):
            with open(user_profiles_path, 'r', encoding='utf-8') as f:
                profiles_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• {len(profiles_data)} ×¤×¨×•×¤×™×œ×™× ×œ××™×’×¨×¦×™×”")
            
            # ×¤×™×¨×•×˜ ×œ×›×œ ×¤×¨×•×¤×™×œ
            profile_summary = {}
            
            for chat_id, profile in profiles_data.items():
                try:
                    save_user_profile(chat_id, profile)
                    results['user_profiles']['migrated'] += 1
                    profile_summary[chat_id] = {'status': 'success', 'fields': len(profile) if isinstance(profile, dict) else 1}
                    print(f"    âœ… ×¤×¨×•×¤×™×œ {chat_id} ×”×•×¢×‘×¨ ({len(profile) if isinstance(profile, dict) else 1} ×©×“×•×ª)")
                except Exception as e:
                    results['user_profiles']['errors'] += 1
                    profile_summary[chat_id] = {'status': 'error', 'error': str(e)}
                    results['user_profiles']['details'].append(f"×©×’×™××” ×‘×¤×¨×•×¤×™×œ {chat_id}: {e}")
                    print(f"    âš ï¸ ×©×’×™××” ×‘×¤×¨×•×¤×™×œ {chat_id}: {e}")
                    continue
            
            # ×¡×™×›×•× ××¤×•×¨×˜ ×œ×›×œ ×¤×¨×•×¤×™×œ
            print(f"\n    ğŸ“‹ === ×¡×™×›×•× ×¤×¨×•×¤×™×œ×™× ===")
            successful_profiles = [chat_id for chat_id, info in profile_summary.items() if info['status'] == 'success']
            failed_profiles = [chat_id for chat_id, info in profile_summary.items() if info['status'] == 'error']
            
            print(f"    âœ… ×¤×¨×•×¤×™×œ×™× ×©×”×•×¢×‘×¨×• ×‘×”×¦×œ×—×” ({len(successful_profiles)}):")
            for chat_id in successful_profiles[:10]:  # ×¨×§ 10 ×”×¨××©×•× ×™×
                fields = profile_summary[chat_id]['fields']
                print(f"        â€¢ ×¦'××˜ {chat_id}: {fields} ×©×“×•×ª")
            if len(successful_profiles) > 10:
                print(f"        ... ×•×¢×•×“ {len(successful_profiles) - 10} ×¤×¨×•×¤×™×œ×™×")
            
            if failed_profiles:
                print(f"    âŒ ×¤×¨×•×¤×™×œ×™× ×©× ×›×©×œ×• ({len(failed_profiles)}):")
                for chat_id in failed_profiles:
                    print(f"        â€¢ ×¦'××˜ {chat_id}: {profile_summary[chat_id]['error']}")
            
            results['user_profiles']['profile_details'] = profile_summary
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ user_profiles.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª user_profiles: {e}")
        results['user_profiles']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª gpt_usage_log.jsonl ===
    print("  ğŸ“Š ××™×’×¨×¦×™×™×ª gpt_usage_log.jsonl...")
    try:
        usage_log_path = "data/gpt_usage_log.jsonl"
        if os.path.exists(usage_log_path):
            line_count = sum(1 for line in open(usage_log_path, 'r', encoding='utf-8'))
            print(f"    ğŸ“Š × ××¦××• {line_count} ×©×•×¨×•×ª ×œ××™×’×¨×¦×™×”")
            
            with open(usage_log_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        entry = json.loads(line.strip())
                        from datetime import datetime
                        timestamp = datetime.fromisoformat(entry.get("timestamp", "").replace("Z", ""))
                        
                        save_gpt_usage_log(
                            chat_id=entry.get("chat_id"),
                            model=entry.get("model", ""),
                            usage=entry.get("usage", {}),
                            cost_agorot=entry.get("cost_agorot", 0),
                            timestamp=timestamp
                        )
                        results['gpt_usage']['migrated'] += 1
                        
                        if line_num % 100 == 0:  # ×“×™×‘××’ ×›×œ 100 ×©×•×¨×•×ª
                            print(f"      âœ… ×”×•×¢×‘×¨×• {line_num}/{line_count} ×©×•×¨×•×ª")
                            
                    except Exception as e:
                        results['gpt_usage']['errors'] += 1
                        results['gpt_usage']['details'].append(f"×©×’×™××” ×‘×©×•×¨×” {line_num}: {e}")
                        print(f"      âš ï¸ ×©×’×™××” ×‘×©×•×¨×” {line_num}: {e}")
                        continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ gpt_usage_log.jsonl ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª usage_log: {e}")
        results['gpt_usage']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª openai_calls.jsonl ===
    print("  ğŸ¤– ××™×’×¨×¦×™×™×ª openai_calls.jsonl...")
    try:
        calls_log_path = "data/openai_calls.jsonl"
        if os.path.exists(calls_log_path):
            line_count = sum(1 for line in open(calls_log_path, 'r', encoding='utf-8'))
            print(f"    ğŸ“Š × ××¦××• {line_count} ×©×•×¨×•×ª ×œ××™×’×¨×¦×™×”")
            
            with open(calls_log_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        entry = json.loads(line.strip())
                        from datetime import datetime
                        timestamp = datetime.fromisoformat(entry.get("ts", "").replace("Z", ""))
                        
                        # ×—×™×œ×•×¥ ×¤×¨×˜×™× ××”×ª×’×•×‘×”
                        response = entry.get("response", {})
                        usage = response.get("usage", {})
                        
                        save_gpt_call_log(
                            chat_id=entry.get("chat_id"),
                            call_type=entry.get("gpt_type", "unknown"),
                            request_data=entry.get("request", {}),
                            response_data=response,
                            tokens_input=usage.get("prompt_tokens", 0),
                            tokens_output=usage.get("completion_tokens", 0),
                            cost_usd=entry.get("cost_usd", 0),
                            processing_time_seconds=0,
                            timestamp=timestamp
                        )
                        results['gpt_calls']['migrated'] += 1
                        
                        if line_num % 100 == 0:  # ×“×™×‘××’ ×›×œ 100 ×©×•×¨×•×ª
                            print(f"      âœ… ×”×•×¢×‘×¨×• {line_num}/{line_count} ×©×•×¨×•×ª")
                            
                    except Exception as e:
                        results['gpt_calls']['errors'] += 1
                        results['gpt_calls']['details'].append(f"×©×’×™××” ×‘×©×•×¨×” {line_num}: {e}")
                        print(f"      âš ï¸ ×©×’×™××” ×‘×©×•×¨×” {line_num}: {e}")
                        continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ openai_calls.jsonl ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª calls_log: {e}")
        results['gpt_calls']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª critical_error_users.json ===
    print("  ğŸš¨ ××™×’×¨×¦×™×™×ª critical_error_users.json...")
    try:
        critical_users_path = "data/critical_error_users.json"
        if os.path.exists(critical_users_path):
            with open(critical_users_path, 'r', encoding='utf-8') as f:
                critical_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• {len(critical_data)} ××©×ª××©×™× ×§×¨×™×˜×™×™× ×œ××™×’×¨×¦×™×”")
            
            for chat_id, user_info in critical_data.items():
                try:
                    save_critical_user_data(chat_id, user_info)
                    results['critical_users']['migrated'] += 1
                    print(f"    âœ… ××©×ª××© ×§×¨×™×˜×™ {chat_id} ×”×•×¢×‘×¨")
                except Exception as e:
                    results['critical_users']['errors'] += 1
                    results['critical_users']['details'].append(f"×©×’×™××” ×‘××©×ª××© ×§×¨×™×˜×™ {chat_id}: {e}")
                    print(f"    âš ï¸ ×©×’×™××” ×‘××©×ª××© ×§×¨×™×˜×™ {chat_id}: {e}")
                    continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ critical_error_users.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª critical_users: {e}")
        results['critical_users']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª reminder_state.json ===
    print("  â° ××™×’×¨×¦×™×™×ª reminder_state.json...")
    try:
        reminder_path = "data/reminder_state.json"
        if os.path.exists(reminder_path):
            with open(reminder_path, 'r', encoding='utf-8') as f:
                reminder_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• {len(reminder_data)} ×¨×©×•××•×ª ×ª×–×›×•×¨×•×ª ×œ××™×’×¨×¦×™×”")
            
            for chat_id, reminder_info in reminder_data.items():
                try:
                    save_reminder_state(chat_id, reminder_info)
                    results['reminder_state']['migrated'] += 1
                    print(f"    âœ… ×ª×–×›×•×¨×ª {chat_id} ×”×•×¢×‘×¨×”")
                except Exception as e:
                    results['reminder_state']['errors'] += 1
                    results['reminder_state']['details'].append(f"×©×’×™××” ×‘×ª×–×›×•×¨×ª {chat_id}: {e}")
                    print(f"    âš ï¸ ×©×’×™××” ×‘×ª×–×›×•×¨×ª {chat_id}: {e}")
                    continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ reminder_state.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª reminder_state: {e}")
        results['reminder_state']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª billing_usage.json ===
    print("  ğŸ’° ××™×’×¨×¦×™×™×ª billing_usage.json...")
    try:
        billing_path = "data/billing_usage.json"
        if os.path.exists(billing_path):
            with open(billing_path, 'r', encoding='utf-8') as f:
                billing_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• × ×ª×•× ×™ ×—×™×•×‘ ×œ××™×’×¨×¦×™×”")
            
            save_billing_usage_data(billing_data)
            results['billing_usage']['migrated'] += 1
            print(f"    âœ… × ×ª×•× ×™ ×—×™×•×‘ ×”×•×¢×‘×¨×•")
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ billing_usage.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª billing_usage: {e}")
        results['billing_usage']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª errors_stats.json ===
    print("  ğŸ“Š ××™×’×¨×¦×™×™×ª errors_stats.json...")
    try:
        errors_stats_path = "data/errors_stats.json"
        if os.path.exists(errors_stats_path):
            with open(errors_stats_path, 'r', encoding='utf-8') as f:
                errors_data = json.load(f)
            
            print(f"    ğŸš« [DISABLED] errors_stats table disabled - skipping migration")
            print(f"    â„¹ï¸ Error statistics will be calculated from bot_error_logs when needed")
            results['errors_stats']['migrated'] = 0
            results['errors_stats']['skipped'] = len(errors_data)
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ errors_stats.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª errors_stats: {e}")
        results['errors_stats']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª bot_errors.jsonl ===
    print("  ğŸ› ××™×’×¨×¦×™×™×ª bot_errors.jsonl...")
    try:
        bot_errors_path = "data/bot_errors.jsonl"
        if os.path.exists(bot_errors_path):
            line_count = sum(1 for line in open(bot_errors_path, 'r', encoding='utf-8'))
            print(f"    ğŸ“Š × ××¦××• {line_count} ×©×•×¨×•×ª ×©×’×™××•×ª ×‘×•×˜ ×œ××™×’×¨×¦×™×”")
            
            with open(bot_errors_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        entry = json.loads(line.strip())
                        save_bot_error_log(entry)
                        results['bot_errors']['migrated'] += 1
                        
                        if line_num % 50 == 0:  # ×“×™×‘××’ ×›×œ 50 ×©×•×¨×•×ª
                            print(f"      âœ… ×”×•×¢×‘×¨×• {line_num}/{line_count} ×©×•×¨×•×ª ×©×’×™××•×ª")
                            
                    except Exception as e:
                        results['bot_errors']['errors'] += 1
                        results['bot_errors']['details'].append(f"×©×’×™××” ×‘×©×•×¨×ª ×©×’×™××” {line_num}: {e}")
                        print(f"      âš ï¸ ×©×’×™××” ×‘×©×•×¨×ª ×©×’×™××” {line_num}: {e}")
                        continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ bot_errors.jsonl ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª bot_errors: {e}")
        results['bot_errors']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª bot_trace_log.jsonl ===
    print("  ğŸ” ××™×’×¨×¦×™×™×ª bot_trace_log.jsonl...")
    try:
        bot_trace_path = "data/bot_trace_log.jsonl"
        if os.path.exists(bot_trace_path):
            line_count = sum(1 for line in open(bot_trace_path, 'r', encoding='utf-8'))
            print(f"    ğŸ“Š × ××¦××• {line_count} ×©×•×¨×•×ª trace ×œ××™×’×¨×¦×™×”")
            
            with open(bot_trace_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        entry = json.loads(line.strip())
                        save_bot_trace_log(entry)
                        results['bot_trace']['migrated'] += 1
                        
                        if line_num % 100 == 0:  # ×“×™×‘××’ ×›×œ 100 ×©×•×¨×•×ª
                            print(f"      âœ… ×”×•×¢×‘×¨×• {line_num}/{line_count} ×©×•×¨×•×ª trace")
                            
                    except Exception as e:
                        results['bot_trace']['errors'] += 1
                        results['bot_trace']['details'].append(f"×©×’×™××” ×‘×©×•×¨×ª trace {line_num}: {e}")
                        print(f"      âš ï¸ ×©×’×™××” ×‘×©×•×¨×ª trace {line_num}: {e}")
                        continue
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ bot_trace_log.jsonl ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª bot_trace: {e}")
        results['bot_trace']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª sync_queue.json ===
    print("  ğŸ”„ ××™×’×¨×¦×™×™×ª sync_queue.json...")
    try:
        sync_queue_path = "data/sync_queue.json"
        if os.path.exists(sync_queue_path):
            with open(sync_queue_path, 'r', encoding='utf-8') as f:
                sync_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• × ×ª×•× ×™ ×ª×•×¨ ×¡× ×›×¨×•×Ÿ ×œ××™×’×¨×¦×™×”")
            
            save_sync_queue_data(sync_data)
            results['sync_queue']['migrated'] += 1
            print(f"    âœ… ×ª×•×¨ ×¡× ×›×¨×•×Ÿ ×”×•×¢×‘×¨")
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ sync_queue.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª sync_queue: {e}")
        results['sync_queue']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª rollback_history.json ×•-last_good_commit.json ===
    print("  â†©ï¸ ××™×’×¨×¦×™×™×ª × ×ª×•× ×™ rollback...")
    try:
        rollback_files = ["data/rollback_history.json", "data/last_good_commit.json"]
        for rollback_file in rollback_files:
            if os.path.exists(rollback_file):
                with open(rollback_file, 'r', encoding='utf-8') as f:
                    rollback_data = json.load(f)
                
                save_rollback_data(os.path.basename(rollback_file), rollback_data)
                results['rollback_data']['migrated'] += 1
                print(f"    âœ… {os.path.basename(rollback_file)} ×”×•×¢×‘×¨")
            else:
                print(f"    â„¹ï¸ ×§×•×‘×¥ {rollback_file} ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª rollback: {e}")
        results['rollback_data']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª free_model_limits.json ===
    print("  ğŸ†“ ××™×’×¨×¦×™×™×ª free_model_limits.json...")
    try:
        free_limits_path = "data/free_model_limits.json"
        if os.path.exists(free_limits_path):
            with open(free_limits_path, 'r', encoding='utf-8') as f:
                limits_data = json.load(f)
            
            print(f"    ğŸ“Š × ××¦××• ××’×‘×œ×•×ª ××•×“×œ ×—×™× ××™ ×œ××™×’×¨×¦×™×”")
            
            save_free_model_limits_data(limits_data)
            results['free_limits']['migrated'] += 1
            print(f"    âœ… ××’×‘×œ×•×ª ××•×“×œ ×—×™× ××™ ×”×•×¢×‘×¨×•")
        else:
            print("    â„¹ï¸ ×§×•×‘×¥ free_model_limits.json ×œ× ×§×™×™×")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª free_limits: {e}")
        results['free_limits']['errors'] += 1
    
    # === ××™×’×¨×¦×™×™×ª ×§×‘×¦×™× ×–×× ×™×™× temp_critical_user_*.json ===
    print("  ğŸ“ ××™×’×¨×¦×™×™×ª ×§×‘×¦×™× ×–×× ×™×™×...")
    try:
        data_dir = "data"
        if os.path.exists(data_dir):
            for filename in os.listdir(data_dir):
                if filename.startswith("temp_critical_user_") and filename.endswith(".json"):
                    temp_file_path = os.path.join(data_dir, filename)
                    try:
                        with open(temp_file_path, 'r', encoding='utf-8') as f:
                            temp_data = json.load(f)
                        
                        save_temp_critical_user_data(filename, temp_data)
                        results['temp_files']['migrated'] += 1
                        print(f"    âœ… ×§×•×‘×¥ ×–×× ×™ {filename} ×”×•×¢×‘×¨")
                    except Exception as e:
                        results['temp_files']['errors'] += 1
                        results['temp_files']['details'].append(f"×©×’×™××” ×‘×§×•×‘×¥ ×–×× ×™ {filename}: {e}")
                        print(f"    âš ï¸ ×©×’×™××” ×‘×§×•×‘×¥ ×–×× ×™ {filename}: {e}")
        else:
            print("    â„¹ï¸ ×ª×™×§×™×™×ª data ×œ× ×§×™×™××ª")
    except Exception as e:
        print(f"    âŒ ×©×’×™××” ×‘××™×’×¨×¦×™×™×ª ×§×‘×¦×™× ×–×× ×™×™×: {e}")
        results['temp_files']['errors'] += 1
    
    return results

def verify_data_integrity(pre_counts, post_counts, migration_results):
    """××××ª ××ª ×©×œ××•×ª ×”× ×ª×•× ×™×"""
    print("  ğŸ” ××™××•×ª ×©×œ××•×ª × ×ª×•× ×™×...")
    
    verification = {
        'chat_messages': {'verified': False, 'details': ''},
        'user_profiles': {'verified': False, 'details': ''},
        'gpt_usage': {'verified': False, 'details': ''},
        'gpt_calls': {'verified': False, 'details': ''},
        'critical_users': {'verified': False, 'details': ''},
        'reminder_state': {'verified': False, 'details': ''},
        'billing_usage': {'verified': False, 'details': ''},
        'errors_stats': {'verified': False, 'details': ''},
        'bot_errors': {'verified': False, 'details': ''},
        'bot_trace': {'verified': False, 'details': ''},
        'sync_queue': {'verified': False, 'details': ''},
        'rollback_data': {'verified': False, 'details': ''},
        'free_limits': {'verified': False, 'details': ''},
        'temp_files': {'verified': False, 'details': ''}
    }
    
    # ××™××•×ª ×”×•×“×¢×•×ª ×¦'××˜
    expected_chat = pre_counts.get('chat_messages', 0) + migration_results['chat_messages']['migrated']
    actual_chat = post_counts.get('chat_messages', 0)
    if expected_chat == actual_chat:
        verification['chat_messages']['verified'] = True
        verification['chat_messages']['details'] = f"âœ… {expected_chat} = {actual_chat}"
    else:
        verification['chat_messages']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_chat}, ×§×™×‘×œ×ª×™ {actual_chat}"
    
    # ××™××•×ª ×¤×¨×•×¤×™×œ×™×
    expected_profiles = pre_counts.get('user_profiles', 0) + migration_results['user_profiles']['migrated']
    actual_profiles = post_counts.get('user_profiles', 0)
    if expected_profiles == actual_profiles:
        verification['user_profiles']['verified'] = True
        verification['user_profiles']['details'] = f"âœ… {expected_profiles} = {actual_profiles}"
    else:
        verification['user_profiles']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_profiles}, ×§×™×‘×œ×ª×™ {actual_profiles}"
    
    # ××™××•×ª ×©×™××•×© GPT
    expected_usage = pre_counts.get('gpt_usage', 0) + migration_results['gpt_usage']['migrated']
    actual_usage = post_counts.get('gpt_usage', 0)
    if expected_usage == actual_usage:
        verification['gpt_usage']['verified'] = True
        verification['gpt_usage']['details'] = f"âœ… {expected_usage} = {actual_usage}"
    else:
        verification['gpt_usage']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_usage}, ×§×™×‘×œ×ª×™ {actual_usage}"
    
    # ××™××•×ª ×§×¨×™××•×ª GPT
    expected_calls = pre_counts.get('gpt_calls', 0) + migration_results['gpt_calls']['migrated']
    actual_calls = post_counts.get('gpt_calls', 0)
    if expected_calls == actual_calls:
        verification['gpt_calls']['verified'] = True
        verification['gpt_calls']['details'] = f"âœ… {expected_calls} = {actual_calls}"
    else:
        verification['gpt_calls']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_calls}, ×§×™×‘×œ×ª×™ {actual_calls}"
    
    # ××™××•×ª ××©×ª××©×™× ×§×¨×™×˜×™×™×
    expected_critical = pre_counts.get('critical_users', 0) + migration_results['critical_users']['migrated']
    actual_critical = post_counts.get('critical_users', 0)
    if expected_critical == actual_critical:
        verification['critical_users']['verified'] = True
        verification['critical_users']['details'] = f"âœ… {expected_critical} = {actual_critical}"
    else:
        verification['critical_users']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_critical}, ×§×™×‘×œ×ª×™ {actual_critical}"
    
    # ××™××•×ª ×ª×–×›×•×¨×•×ª
    expected_reminder = pre_counts.get('reminder_states', 0) + migration_results['reminder_state']['migrated']
    actual_reminder = post_counts.get('reminder_states', 0)
    if expected_reminder == actual_reminder:
        verification['reminder_state']['verified'] = True
        verification['reminder_state']['details'] = f"âœ… {expected_reminder} = {actual_reminder}"
    else:
        verification['reminder_state']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_reminder}, ×§×™×‘×œ×ª×™ {actual_reminder}"
    
    # ××™××•×ª × ×ª×•× ×™ ×—×™×•×‘
    expected_billing = pre_counts.get('billing_usage', 0) + migration_results['billing_usage']['migrated']
    actual_billing = post_counts.get('billing_usage', 0)
    if expected_billing == actual_billing:
        verification['billing_usage']['verified'] = True
        verification['billing_usage']['details'] = f"âœ… {expected_billing} = {actual_billing}"
    else:
        verification['billing_usage']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_billing}, ×§×™×‘×œ×ª×™ {actual_billing}"
    
    # ××™××•×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×©×’×™××•×ª
    expected_errors_stats = pre_counts.get('errors_stats', 0) + migration_results['errors_stats']['migrated']
    actual_errors_stats = post_counts.get('errors_stats', 0)
    if expected_errors_stats == actual_errors_stats:
        verification['errors_stats']['verified'] = True
        verification['errors_stats']['details'] = f"âœ… {expected_errors_stats} = {actual_errors_stats}"
    else:
        verification['errors_stats']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_errors_stats}, ×§×™×‘×œ×ª×™ {actual_errors_stats}"
    
    # ××™××•×ª ×œ×•×’×™ ×©×’×™××•×ª ×‘×•×˜
    expected_bot_errors = pre_counts.get('bot_errors', 0) + migration_results['bot_errors']['migrated']
    actual_bot_errors = post_counts.get('bot_errors', 0)
    if expected_bot_errors == actual_bot_errors:
        verification['bot_errors']['verified'] = True
        verification['bot_errors']['details'] = f"âœ… {expected_bot_errors} = {actual_bot_errors}"
    else:
        verification['bot_errors']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_bot_errors}, ×§×™×‘×œ×ª×™ {actual_bot_errors}"
    
    # ××™××•×ª ×œ×•×’×™ trace ×‘×•×˜
    expected_bot_trace = pre_counts.get('bot_trace', 0) + migration_results['bot_trace']['migrated']
    actual_bot_trace = post_counts.get('bot_trace', 0)
    if expected_bot_trace == actual_bot_trace:
        verification['bot_trace']['verified'] = True
        verification['bot_trace']['details'] = f"âœ… {expected_bot_trace} = {actual_bot_trace}"
    else:
        verification['bot_trace']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_bot_trace}, ×§×™×‘×œ×ª×™ {actual_bot_trace}"
    
    # ××™××•×ª ×ª×•×¨ ×¡× ×›×¨×•×Ÿ
    expected_sync = pre_counts.get('sync_queue', 0) + migration_results['sync_queue']['migrated']
    actual_sync = post_counts.get('sync_queue', 0)
    if expected_sync == actual_sync:
        verification['sync_queue']['verified'] = True
        verification['sync_queue']['details'] = f"âœ… {expected_sync} = {actual_sync}"
    else:
        verification['sync_queue']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_sync}, ×§×™×‘×œ×ª×™ {actual_sync}"
    
    # ××™××•×ª × ×ª×•× ×™ rollback
    expected_rollback = pre_counts.get('rollback_data', 0) + migration_results['rollback_data']['migrated']
    actual_rollback = post_counts.get('rollback_data', 0)
    if expected_rollback == actual_rollback:
        verification['rollback_data']['verified'] = True
        verification['rollback_data']['details'] = f"âœ… {expected_rollback} = {actual_rollback}"
    else:
        verification['rollback_data']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_rollback}, ×§×™×‘×œ×ª×™ {actual_rollback}"
    
    # ××™××•×ª ××’×‘×œ×•×ª ××•×“×œ ×—×™× ××™
    expected_free_limits = pre_counts.get('free_limits', 0) + migration_results['free_limits']['migrated']
    actual_free_limits = post_counts.get('free_limits', 0)
    if expected_free_limits == actual_free_limits:
        verification['free_limits']['verified'] = True
        verification['free_limits']['details'] = f"âœ… {expected_free_limits} = {actual_free_limits}"
    else:
        verification['free_limits']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_free_limits}, ×§×™×‘×œ×ª×™ {actual_free_limits}"
    
    # ××™××•×ª ×§×‘×¦×™× ×–×× ×™×™×
    expected_temp = pre_counts.get('temp_files', 0) + migration_results['temp_files']['migrated']
    actual_temp = post_counts.get('temp_files', 0)
    if expected_temp == actual_temp:
        verification['temp_files']['verified'] = True
        verification['temp_files']['details'] = f"âœ… {expected_temp} = {actual_temp}"
    else:
        verification['temp_files']['details'] = f"âŒ ×¦×™×¤×™×ª×™ {expected_temp}, ×§×™×‘×œ×ª×™ {actual_temp}"
    
    return verification

def print_detailed_summary(migration_results, verification_results):
    """××“×¤×™×¡ ×¡×™×›×•× ××¤×•×¨×˜ ×•×’× ×©×•××¨ ×œ×§×•×‘×¥ ×œ×•×’ ×•×©×•×œ×— ×œ××“××™×Ÿ"""
    import os
    from notifications import send_admin_notification
    def log_to_file(msg):
        with open("migration_log.txt", "a", encoding="utf-8") as f:
            f.write(msg + "\n")
    
    summary_lines = []
    summary_lines.append("\nğŸ“‹ === ×¡×™×›×•× ××™×’×¨×¦×™×” ××¤×•×¨×˜ ===")
    total_migrated = 0
    total_errors = 0
    for category, results in migration_results.items():
        migrated = results['migrated']
        errors = results['errors']
        total_migrated += migrated
        total_errors += errors
        status = "âœ…" if verification_results[category]['verified'] else "âŒ"
        summary_lines.append(f"\n{status} {category.upper()}:")
        summary_lines.append(f"   ğŸ“Š ×”×•×¢×‘×¨×•: {migrated}")
        summary_lines.append(f"   âš ï¸ ×©×’×™××•×ª: {errors}")
        summary_lines.append(f"   ğŸ” ××™××•×ª: {verification_results[category]['details']}")
        if errors > 0 and results['details']:
            summary_lines.append(f"   ğŸ“ ×¤×¨×˜×™ ×©×’×™××•×ª:")
            for detail in results['details'][:5]:
                summary_lines.append(f"      â€¢ {detail}")
            if len(results['details']) > 5:
                summary_lines.append(f"      ... ×•×¢×•×“ {len(results['details']) - 5} ×©×’×™××•×ª")
    summary_lines.append(f"\nğŸ¯ ×¡×™×›×•× ×›×œ×œ×™:")
    summary_lines.append(f"   ğŸ“Š ×¡×”×´×› ×”×•×¢×‘×¨×•: {total_migrated}")
    summary_lines.append(f"   âš ï¸ ×¡×”×´×› ×©×’×™××•×ª: {total_errors}")
    summary_lines.append(f"   ğŸ“ˆ ××—×•×– ×”×¦×œ×—×”: {((total_migrated - total_errors) / max(total_migrated, 1) * 100):.1f}%")
    
    # ×‘×“×™×§×” ×× ×”×™×™×ª×” ××™×’×¨×¦×™×” ×××™×ª×™×ª
    if total_migrated == 0:
        summary_lines.append(f"\nâ„¹ï¸ ×”×¢×¨×”: ×œ× ×”×•×¢×‘×¨×• × ×ª×•× ×™× - ×™×ª×›×Ÿ ×©×”×§×‘×¦×™× ×¨×™×§×™× ××• ×œ× ×§×™×™××™×")
        summary_lines.append(f"â„¹ï¸ ×–×• ×œ× ×©×’×™××” - ×”××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×” ×œ×œ× × ×ª×•× ×™× ×œ××™×’×¨×¦×™×”")
    
    # ×”×•×¡×¤×ª ×¤×™×¨×•×˜ ××¤×•×¨×˜ ×œ×›×œ chat_id
    if 'chat_details' in migration_results.get('chat_messages', {}):
        summary_lines.append(f"\nğŸ“‹ === ×¤×™×¨×•×˜ ××¤×•×¨×˜ ×œ×›×œ chat_id ===")
        chat_details = migration_results['chat_messages']['chat_details']
        for chat_id, details in list(chat_details.items())[:15]:  # ×¨×§ 15 ×”×¨××©×•× ×™×
            success_rate = (details['migrated'] / details['total'] * 100) if details['total'] > 0 else 0
            status = "âœ…" if details['errors'] == 0 else "âš ï¸"
            summary_lines.append(f"   {status} ×¦'××˜ {chat_id}: {details['migrated']}/{details['total']} ×”×•×“×¢×•×ª ({success_rate:.1f}%)")
        if len(chat_details) > 15:
            summary_lines.append(f"   ... ×•×¢×•×“ {len(chat_details) - 15} ×¦'××˜×™×")
    
    # ×”×•×¡×¤×ª ×¤×™×¨×•×˜ ×¤×¨×•×¤×™×œ×™×
    if 'profile_details' in migration_results.get('user_profiles', {}):
        summary_lines.append(f"\nğŸ‘¤ === ×¤×™×¨×•×˜ ×¤×¨×•×¤×™×œ×™× ===")
        profile_details = migration_results['user_profiles']['profile_details']
        successful_profiles = [chat_id for chat_id, info in profile_details.items() if info['status'] == 'success']
        failed_profiles = [chat_id for chat_id, info in profile_details.items() if info['status'] == 'error']
        
        summary_lines.append(f"   âœ… ×¤×¨×•×¤×™×œ×™× ××•×¦×œ×—×™×: {len(successful_profiles)}")
        for chat_id in successful_profiles[:10]:  # ×¨×§ 10 ×”×¨××©×•× ×™×
            fields = profile_details[chat_id]['fields']
            summary_lines.append(f"      â€¢ ×¦'××˜ {chat_id}: {fields} ×©×“×•×ª")
        if len(successful_profiles) > 10:
            summary_lines.append(f"      ... ×•×¢×•×“ {len(successful_profiles) - 10} ×¤×¨×•×¤×™×œ×™×")
        
        if failed_profiles:
            summary_lines.append(f"   âŒ ×¤×¨×•×¤×™×œ×™× ×©× ×›×©×œ×•: {len(failed_profiles)}")
    
    # ×”×•×¡×¤×ª ××™×“×¢ ×¢×œ ×’×•×“×œ ×§×‘×¦×™×
    try:
        def file_mb(path):
            return os.path.getsize(path)/1024/1024 if os.path.exists(path) else 0
        files = ["data/chat_history.json", "data/user_profiles.json", "data/gpt_usage_log.jsonl", "data/openai_calls.jsonl"]
        summary_lines.append(f"\nğŸ“¦ === ×’×•×“×œ ×§×‘×¦×™× ===")
        for f in files:
            mb = file_mb(f)
            summary_lines.append(f"   ğŸ“¦ {f}: {mb:.2f}MB")
    except Exception as e:
        summary_lines.append(f"   âš ï¸ ×©×’×™××” ×‘×—×™×©×•×‘ ×’×•×“×œ ×§×‘×¦×™×: {e}")
    # ×”×“×¤×¡×”, ×©××™×¨×” ×œ×§×•×‘×¥, ×•×©×œ×™×—×” ×œ××“××™×Ÿ
    summary = "\n".join(summary_lines)
    print(summary)
    log_to_file(summary)
    
    # ×©×œ×™×—×” ×œ××“××™×Ÿ ×¨×§ ×× ×”×™×™×ª×” ××™×’×¨×¦×™×” ×××™×ª×™×ª
    if total_migrated > 0:
        try:
            send_admin_notification(f"ğŸ“‹ ×¡×™×›×•× ××™×’×¨×¦×™×”:\n{summary[:3500]}")
        except Exception as e:
            print(f"âš ï¸ ×©×’×™××” ×‘×©×œ×™×—×ª ×¡×™×›×•× ×œ××“××™×Ÿ: {e}")
    else:
        print("â„¹ï¸ ×œ× × ×©×œ×—×” ×”×•×“×¢×ª ××™×’×¨×¦×™×” ×œ××“××™×Ÿ - ×œ× ×”×™×• × ×ª×•× ×™× ×œ××™×’×¨×¦×™×”")

async def handle_migrate_command(update, context):
    """××˜×¤×œ ×‘×¤×§×•×“×ª /migrate_all_data ×¢× ×§×•×“ ×¡×•×“×™"""
    try:
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×”×•× ××“××™×Ÿ ×œ×¤×™ chat_id ×‘×œ×‘×“
        chat_id = str(update.effective_chat.id)
        if chat_id != "111709341":
            await update.message.reply_text("âŒ ×¨×§ ××“××™×Ÿ ×™×›×•×œ ×œ×”×¨×™×¥ ×¤×§×•×“×” ×–×•")
            return
        
        # ×‘×“×™×§×ª ×§×•×“ ×¡×•×“×™
        message_text = update.message.text.strip()
        if not message_text.endswith(" SECRET_MIGRATION_2024"):
            await update.message.reply_text(
                "ğŸ” × ×“×¨×© ×§×•×“ ×¡×•×“×™ ×œ××™×’×¨×¦×™×”!\n"
                "×”×©×ª××© ×‘×¤×§×•×“×”: /migrate_all_data SECRET_MIGRATION_2024"
            )
            return
        
        await update.message.reply_text(
            "ğŸ” === ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×¢× ×§×•×“ ×¡×•×“×™ ===\n"
            "ğŸš¨ ×× ×’× ×•× ×™ ×‘×˜×™×—×•×ª ××•×¤×¢×œ×™×:\n"
            "   âœ… ×’×™×‘×•×™ ××•×˜×•××˜×™ ×œ×¤× ×™ ××™×’×¨×¦×™×”\n"
            "   âœ… ×‘×“×™×§×ª ×ª×§×™× ×•×ª × ×ª×•× ×™×\n"
            "   âœ… ×“×™×‘××’ ××¤×•×¨×˜ ×œ×›×œ ×©×œ×‘\n"
            "   âœ… ×¢×¦×™×¨×” ×‘×©×’×™××”\n"
            "   âœ… ×œ×•×’ ××¤×•×¨×˜ ×©×œ ×›×œ ×¤×¢×•×œ×”\n"
            "   âœ… ××™××•×ª ×©×œ××•×ª × ×ª×•× ×™×\n\n"
            "ğŸš€ ××ª×—×™×œ ××™×’×¨×¦×™×”..."
        )
        
        # ×”×¨×¦×ª ×”××™×’×¨×¦×™×” ×‘-thread × ×¤×¨×“
        import threading
        def run_migration():
            success = migrate_data_to_sql_with_safety()
            if success:
                print("âœ… ××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”")
            else:
                print("âŒ ××™×’×¨×¦×™×” × ×›×©×œ×”")
        
        migration_thread = threading.Thread(target=run_migration)
        migration_thread.start()
        
        await update.message.reply_text("âœ… ××™×’×¨×¦×™×” ×”×•×—×œ×” - ×ª×§×‘×œ ×¢×“×›×•×Ÿ ××¤×•×¨×˜ ×›×©×ª×¡×ª×™×™×")
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×¤×§×•×“×ª ××™×’×¨×¦×™×”: {e}")

async def handle_show_logs_command(update, context):
    """××˜×¤×œ ×‘×¤×§×•×“×ª /show_logs ×œ×§×¨×™××ª ×œ×•×’×™× ××¨× ×“×¨"""
    try:
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×”×•× ××“××™×Ÿ
        chat_id = str(update.effective_chat.id)
        if chat_id != "111709341":
            await update.message.reply_text("âŒ ×¨×§ ××“××™×Ÿ ×™×›×•×œ ×œ×”×¨×™×¥ ×¤×§×•×“×” ×–×•")
            return
        
        # ×§×‘×œ×ª ×”×¤×¨××˜×¨×™× ××”×¤×§×•×“×”
        message_text = update.message.text.strip()
        parts = message_text.split()
        
        # ×‘×¨×™×¨×ª ××—×“×œ: 50 ×©×•×¨×•×ª ××—×¨×•× ×•×ª
        lines = 50
        log_type = "service"
        
        # ×¤×¨×¡×•×¨ ×¤×¨××˜×¨×™×
        if len(parts) > 1:
            try:
                lines = int(parts[1])
                lines = min(lines, 500)  # ××§×¡×™××•× 500 ×©×•×¨×•×ª
            except ValueError:
                log_type = parts[1]
        
        if len(parts) > 2:
            log_type = parts[2]
        
        await update.message.reply_text(f"ğŸ“‹ ×§×•×¨× {lines} ×©×•×¨×•×ª ××—×¨×•× ×•×ª ××œ×•×’ {log_type}...")
        
        # ×”×¨×¦×ª ×§×¨×™××ª ×œ×•×’×™× ×‘-thread × ×¤×¨×“
        import threading
        def read_logs():
            try:
                logs = get_render_logs(log_type, lines)
                
                # ×©×œ×™×—×ª ×”×œ×•×’×™× ×œ×˜×œ×’×¨×
                import asyncio
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(send_logs_to_telegram(update, logs, log_type, lines))
                loop.close()
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘×§×¨×™××ª ×œ×•×’×™×: {e}")
        
        logs_thread = threading.Thread(target=read_logs)
        logs_thread.start()
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×¤×§×•×“×ª ×œ×•×’×™×: {e}")

def get_render_logs(log_type="service", lines=50):
    """×§×•×¨× ×œ×•×’×™× ××¨× ×“×¨ ×“×¨×š SSH"""
    try:
        # ××™×¤×•×™ ×¡×•×’×™ ×œ×•×’×™×
        log_paths = {
            "service": "/var/log/render/service.log",
            "python": "/var/log/render/python.log", 
            "error": "/var/log/render/error.log",
            "access": "/var/log/render/access.log"
        }
        
        log_path = log_paths.get(log_type, "/var/log/render/service.log")
        ssh_host = "srv-d0r895be5dus73fmsc8g@ssh.frankfurt.render.com"
        
        # ×¤×§×•×“×ª SSH ×œ×§×¨×™××ª ×œ×•×’×™×
        cmd = f"ssh {ssh_host} 'tail -n {lines} {log_path}'"
        
        print(f"ğŸ“‹ ××¨×™×¥ ×¤×§×•×“×”: {cmd}")
        
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0:
            return result.stdout
        else:
            return f"âŒ ×©×’×™××” ×‘×§×¨×™××ª ×œ×•×’×™×: {result.stderr}"
            
    except subprocess.TimeoutExpired:
        return "â° ×”×–××Ÿ ×œ×§×¨×™××ª ×œ×•×’×™× ×¤×’ - ×”×¨× ×“×¨ ×œ× ××’×™×‘"
    except Exception as e:
        return f"âŒ ×©×’×™××” ×‘×§×¨×™××ª ×œ×•×’×™×: {e}"

async def send_logs_to_telegram(update, logs, log_type, lines):
    """×©×•×œ×— ×œ×•×’×™× ×œ×˜×œ×’×¨× (×¢× ×—×œ×•×§×” ×œ×—×œ×§×™× ×× × ×“×¨×©)"""
    try:
        if not logs or not logs.strip():
            await update.message.reply_text(f"ğŸ“‹ ××™×Ÿ ×œ×•×’×™× ×–××™× ×™× ×¢×‘×•×¨ {log_type}")
            return
        
        # ×”×•×¡×¤×ª ×›×•×ª×¨×ª
        header = f"ğŸ“‹ **×œ×•×’×™× ××¨× ×“×¨ - {log_type}**\n"
        header += f"ğŸ“Š {lines} ×©×•×¨×•×ª ××—×¨×•× ×•×ª\n"
        header += f"ğŸ• {datetime.datetime.now().strftime('%H:%M:%S')}\n"
        header += "=" * 40 + "\n\n"
        
        formatted_logs = header + logs
        
        # ×—×œ×•×§×” ×œ×—×œ×§×™× (×˜×œ×’×¨× ××•×’×‘×œ ×œ-4096 ×ª×•×•×™×)
        max_length = 4000  # ×”×©××¨×ª ××§×•× ×œ×¤×•×¨××˜×™× ×’
        
        if len(formatted_logs) <= max_length:
            await update.message.reply_text(f"```\n{formatted_logs}\n```", parse_mode="Markdown")
        else:
            # ×—×œ×•×§×” ×œ×—×œ×§×™×
            parts = []
            current_part = header
            
            for line in logs.split('\n'):
                if len(current_part) + len(line) + 1 > max_length:
                    parts.append(current_part)
                    current_part = line + '\n'
                else:
                    current_part += line + '\n'
            
            if current_part.strip():
                parts.append(current_part)
            
            # ×©×œ×™×—×ª ×›×œ ×—×œ×§
            for i, part in enumerate(parts):
                part_header = f"ğŸ“‹ ×—×œ×§ {i+1}/{len(parts)}\n" + "=" * 20 + "\n"
                await update.message.reply_text(f"```\n{part_header}{part}\n```", parse_mode="Markdown")
                
                # ×× ×™×¢×ª spam - ×”××ª× ×” ×‘×™×Ÿ ×—×œ×§×™×
                if i < len(parts) - 1:
                    await asyncio.sleep(1)
        
        # ×¡×™×›×•×
        await update.message.reply_text(f"âœ… ×œ×•×’×™× × ×©×œ×—×• ×‘×”×¦×œ×—×”!\nğŸ“Š ×¡×”\"×› {len(logs.split())} ×©×•×¨×•×ª")
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×œ×•×’×™×: {e}")

async def handle_search_logs_command(update, context):
    """××˜×¤×œ ×‘×¤×§×•×“×ª /search_logs ×œ×—×™×¤×•×© ×œ×•×’×™×"""
    try:
        # ×‘×“×™×§×” ×× ×”××©×ª××© ×”×•× ××“××™×Ÿ
        chat_id = str(update.effective_chat.id)
        if chat_id != "111709341":
            await update.message.reply_text("âŒ ×¨×§ ××“××™×Ÿ ×™×›×•×œ ×œ×”×¨×™×¥ ×¤×§×•×“×” ×–×•")
            return
        
        # ×§×‘×œ×ª ×”×¤×¨××˜×¨×™× ××”×¤×§×•×“×”
        message_text = update.message.text.strip()
        parts = message_text.split()
        
        if len(parts) < 2:
            await update.message.reply_text(
                "â“ ×©×™××•×©: /search_logs <××™×œ×ª_×—×™×¤×•×©> [×¡×•×’_×œ×•×’] [××¡×¤×¨_×©×•×¨×•×ª]\n"
                "×“×•×’××”: /search_logs error service 100"
            )
            return
        
        search_term = parts[1]
        log_type = parts[2] if len(parts) > 2 else "service"
        lines = int(parts[3]) if len(parts) > 3 and parts[3].isdigit() else 200
        lines = min(lines, 1000)  # ××§×¡×™××•× 1000 ×©×•×¨×•×ª
        
        await update.message.reply_text(f"ğŸ” ××—×¤×© '{search_term}' ×‘-{lines} ×©×•×¨×•×ª ××—×¨×•× ×•×ª ×©×œ {log_type}...")
        
        # ×”×¨×¦×ª ×—×™×¤×•×© ×œ×•×’×™× ×‘-thread × ×¤×¨×“
        import threading
        def search_logs():
            try:
                logs = get_render_logs(log_type, lines)
                search_results = search_logs_in_file(logs, search_term)
                
                # ×©×œ×™×—×ª ×”×ª×•×¦××•×ª ×œ×˜×œ×’×¨×
                import asyncio
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(send_search_results_to_telegram(update, search_results, log_type, search_term))
                loop.close()
            except Exception as e:
                print(f"âŒ ×©×’×™××” ×‘×—×™×¤×•×© ×œ×•×’×™×: {e}")
        
        logs_thread = threading.Thread(target=search_logs)
        logs_thread.start()
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×¤×§×•×“×ª ×—×™×¤×•×© ×œ×•×’×™×: {e}")

def search_logs_in_file(file_content, search_term):
    """×—×™×¤×•×© ×œ×•×’×™× ×‘×ª×•×›×Ÿ ×§×•×‘×¥"""
    search_results = []
    for line in file_content.splitlines():
        if search_term.lower() in line.lower():
            search_results.append(line)
    return search_results

async def send_search_results_to_telegram(update, search_results, log_type, search_term):
    """×©×•×œ×— ×ª×•×¦××•×ª ×—×™×¤×•×© ×œ×•×’×™× ×œ×˜×œ×’×¨×"""
    try:
        if not search_results:
            await update.message.reply_text(f"âŒ ×œ× × ××¦××• ×ª×•×¦××•×ª ×¢×‘×•×¨ '{search_term}' ×‘×œ×•×’ {log_type}")
            return
        
        # ×”×•×¡×¤×ª ×›×•×ª×¨×ª
        header = f"ğŸ” **×ª×•×¦××•×ª ×—×™×¤×•×© ×œ×•×’×™× - {log_type}**\n"
        header += f"ğŸ”¤ ×—×™×¤×•×©: '{search_term}'\n"
        header += f"ğŸ“Š × ××¦××•: {len(search_results)} ×©×•×¨×•×ª\n"
        header += f"ğŸ• {datetime.datetime.now().strftime('%H:%M:%S')}\n"
        header += "=" * 40 + "\n\n"
        
        formatted_results = header + "\n".join(search_results)
        
        # ×—×œ×•×§×” ×œ×—×œ×§×™× ×× × ×“×¨×©
        max_length = 4000
        
        if len(formatted_results) <= max_length:
            await update.message.reply_text(f"```\n{formatted_results}\n```", parse_mode="Markdown")
        else:
            # ×—×œ×•×§×” ×œ×—×œ×§×™×
            parts = []
            current_part = header
            
            for line in search_results:
                if len(current_part) + len(line) + 1 > max_length:
                    parts.append(current_part)
                    current_part = line + '\n'
                else:
                    current_part += line + '\n'
            
            if current_part.strip():
                parts.append(current_part)
            
            # ×©×œ×™×—×ª ×›×œ ×—×œ×§
            for i, part in enumerate(parts):
                part_header = f"ğŸ” ×—×œ×§ {i+1}/{len(parts)}\n" + "=" * 20 + "\n"
                await update.message.reply_text(f"```\n{part_header}{part}\n```", parse_mode="Markdown")
                
                # ×× ×™×¢×ª spam - ×”××ª× ×” ×‘×™×Ÿ ×—×œ×§×™×
                if i < len(parts) - 1:
                    await asyncio.sleep(1)
        
        # ×¡×™×›×•×
        await update.message.reply_text(f"âœ… ×—×™×¤×•×© ×”×•×©×œ×!\nğŸ“Š × ××¦××• {len(search_results)} ×©×•×¨×•×ª ×¢× '{search_term}'")
        
    except Exception as e:
        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×ª×•×¦××•×ª ×—×™×¤×•×©: {e}")

def count_table_rows():
    """×¡×¤×™×¨×ª ×©×•×¨×•×ª ×‘×˜×‘×œ××•×ª ×”×§×¨×™×˜×™×•×ª ×‘×œ×‘×“"""
    counts = {}
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ğŸŸ¢ ×˜×‘×œ××•×ª ×§×¨×™×˜×™×•×ª ×‘×œ×‘×“
        critical_tables = [
            'chat_messages',
            'user_profiles', 
            'gpt_calls_log',
            'reminder_states',
            'bot_error_logs',
            'bot_trace_logs'
        ]
        
        for table in critical_tables:
            try:
                cur.execute(f"SELECT COUNT(*) FROM {table}")
                counts[table] = cur.fetchone()[0]
            except Exception as e:
                print(f"    âš ï¸ ×˜×‘×œ×” {table} ×œ× ×§×™×™××ª ××• ×©×’×™××”: {e}")
                counts[table] = 0
        
        # ğŸš« ×˜×‘×œ××•×ª ××™×•×ª×¨×•×ª - ×œ× × ×¡×¤×¨×•×ª ×™×•×ª×¨
        disabled_tables = [
            'gpt_usage_log',
            'system_logs', 
            'critical_users',
            'billing_usage',
            'errors_stats',
            'free_model_limits'
        ]
        
        for table in disabled_tables:
            counts[table] = "DISABLED"
        
        cur.close()
        conn.close()
        
        print("ğŸ“Š ××¡×¤×¨ ×”×©×•×¨×•×ª ×‘×˜×‘×œ××•×ª:")
        for table, count in counts.items():
            if count == "DISABLED":
                print(f"    ğŸš« {table}: ×”×•×©×‘×ª×”")
            else:
                print(f"    ğŸ“‹ {table}: {count}")
        
        return counts
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¡×¤×™×¨×ª ×©×•×¨×•×ª: {e}")
        return {}

if __name__ == "__main__":
    # ×× ×”×¨×¦× ×• ×™×©×™×¨×•×ª ××”-Shell, × ×¨×™×¥ ××™×’×¨×¦×™×”
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "migrate":
        # ×‘×“×™×§×ª ×§×•×“ ×¡×•×“×™
        if len(sys.argv) < 3 or sys.argv[2] != "SECRET_MIGRATION_2024":
            print("ğŸ” === ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×¢× ×§×•×“ ×¡×•×“×™ ===")
            print("âŒ × ×“×¨×© ×§×•×“ ×¡×•×“×™ ×œ××™×’×¨×¦×™×”!")
            print("×”×©×ª××© ×‘×¤×§×•×“×”: python bot_setup.py migrate SECRET_MIGRATION_2024")
            sys.exit(1)
        
        print("ğŸ” === ××™×’×¨×¦×™×” ×‘×˜×•×—×” ×¢× ×§×•×“ ×¡×•×“×™ ===")
        print("âœ… ×§×•×“ ×¡×•×“×™ ××•××ª - ××ª×—×™×œ ××™×’×¨×¦×™×”...")
        success = migrate_data_to_sql_with_safety()
        if success:
            print("âœ… ××™×’×¨×¦×™×” ×”×•×©×œ××” ×‘×”×¦×œ×—×”!")
            sys.exit(0)
        else:
            print("âŒ ××™×’×¨×¦×™×” × ×›×©×œ×”!")
            sys.exit(1)
    else:
        # ×”×¨×¦×” ×¨×’×™×œ×” ×©×œ ×”×‘×•×˜
        print("ğŸ¤– ××ª×—×™×œ ××ª ×”×‘×•×˜...")
        app = setup_bot()
        app.run_polling() 