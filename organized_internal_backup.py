#!/usr/bin/env python3
"""
ğŸ—„ï¸ ××¢×¨×›×ª ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨×ª ×‘××¡×“ ×”× ×ª×•× ×™×
×™×•×¦×¨×ª schema "backup" ×¢× ×˜×‘×œ××•×ª ××¡×•×“×¨×•×ª ×œ×›×œ ×ª××¨×™×š
×›××• ×ª×™×§×™×•×ª ××‘×œ ×‘××¡×“ × ×ª×•× ×™× - ××ª××©×š ×‘-Render!
"""

import psycopg2
from datetime import datetime, timedelta
from config import config
from simple_logger import logger
from admin_notifications import send_admin_notification

DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")

# ğŸ¯ ×”×’×“×¨×•×ª ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨
TABLES_TO_BACKUP = ["user_profiles", "chat_messages", "interactions_log"]
BACKUP_SCHEMA = "backup"
BACKUP_RETENTION_DAYS = 30

def create_backup_schema():
    """×™×•×¦×¨ ××ª ×”-schema ×œ×’×™×‘×•×™ ×× ×œ× ×§×™×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×™×¦×™×¨×ª schema ×× ×œ× ×§×™×™×
        cur.execute(f"CREATE SCHEMA IF NOT EXISTS {BACKUP_SCHEMA}")
        conn.commit()
        
        cur.close()
        conn.close()
        
        logger.info(f"âœ… Schema {BACKUP_SCHEMA} ××•×›×Ÿ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª backup schema: {e}")
        return False

def backup_table_to_internal_organized(table_name, backup_date):
    """××’×‘×” ×˜×‘×œ×” ×œ×˜×‘×œ×ª ×’×™×‘×•×™ ××¡×•×“×¨×ª ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×©× ×”×˜×‘×œ×” ×”××¡×•×“×¨×ª
        backup_table_name = f"{table_name}_backup_{backup_date}"
        full_backup_table = f"{BACKUP_SCHEMA}.{backup_table_name}"
        
        # ××—×™×§×ª ×”×˜×‘×œ×” ×× ×§×™×™××ª (×’×™×‘×•×™ ××—×“×©)
        cur.execute(f"DROP TABLE IF EXISTS {full_backup_table}")
        
        # ×™×¦×™×¨×ª ×”×˜×‘×œ×” ×”×—×“×©×” ×¢× × ×ª×•× ×™ ×”×’×™×‘×•×™
        cur.execute(f"""
            CREATE TABLE {full_backup_table} AS 
            SELECT *, 
                   '{backup_date}' as backup_date,
                   '{datetime.now().isoformat()}' as backup_timestamp
            FROM {table_name}
        """)
        
        # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª ×©× ×•×¡×¤×•
        cur.execute(f"SELECT COUNT(*) FROM {full_backup_table}")
        records_count = cur.fetchone()[0]
        
        # ×§×‘×œ×ª ×’×•×“×œ ×”×˜×‘×œ×”
        cur.execute(f"""
            SELECT pg_size_pretty(pg_total_relation_size('{full_backup_table}'))
        """)
        table_size = cur.fetchone()[0]
        
        conn.commit()
        cur.close()
        conn.close()
        
        backup_info = {
            "table_name": table_name,
            "backup_table_name": backup_table_name,
            "full_backup_table": full_backup_table,
            "records_count": records_count,
            "table_size": table_size,
            "backup_date": backup_date,
            "confirmation_code": f"IB-{table_name.upper()[:3]}-{backup_date}-{records_count:04d}",
            "backup_timestamp": datetime.now()
        }
        
        logger.info(f"âœ… {table_name} â†’ {backup_table_name}: {records_count} ×¨×©×•××•×ª ({table_size})")
        return backup_info
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ {table_name}: {e}")
        return None

def run_organized_internal_backup():
    """××¨×™×¥ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ××œ×"""
    try:
        backup_date = datetime.now().strftime("%d_%m_%Y")
        logger.info(f"ğŸ—„ï¸ ××ª×—×™×œ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×œ×ª××¨×™×š {backup_date}")
        
        # ×™×¦×™×¨×ª schema ×”×’×™×‘×•×™
        if not create_backup_schema():
            return False
        
        # ×’×™×‘×•×™ ×›×œ ×˜×‘×œ×”
        backup_results = {}
        total_records = 0
        
        for table_name in TABLES_TO_BACKUP:
            backup_info = backup_table_to_internal_organized(table_name, backup_date)
            
            if backup_info:
                backup_results[table_name] = backup_info
                total_records += backup_info["records_count"]
        
        # ×‘×“×™×§×ª ×”×¦×œ×—×”
        if len(backup_results) == len(TABLES_TO_BACKUP):
            logger.info(f"ğŸ‰ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×”×•×©×œ×: {total_records} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª")
            
            # ×”×©×•×•××” ×œ×™×•× ×§×•×“×
            yesterday_comparison = compare_with_yesterday_internal(backup_date, backup_results)
            
            # ×©×œ×™×—×ª ×”×ª×¨××” ××¤×•×¨×˜×ª
            send_detailed_internal_backup_notification(backup_results, total_records, yesterday_comparison)
            
            return True
        else:
            logger.error(f"âŒ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ × ×›×©×œ: {len(backup_results)}/{len(TABLES_TO_BACKUP)} ×˜×‘×œ××•×ª")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨: {e}")
        return False

def compare_with_yesterday_internal(today_date, today_results):
    """××©×•×•×” ××ª ×”×’×™×‘×•×™ ×©×œ ×”×™×•× ×¢× ×××© ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%d_%m_%Y")
        comparison = {}
        
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        for table_name, today_info in today_results.items():
            yesterday_table = f"{BACKUP_SCHEMA}.{table_name}_backup_{yesterday}"
            
            # ×‘×“×™×§×” ×× ×”×˜×‘×œ×” ×©×œ ×××© ×§×™×™××ª
            cur.execute(f"""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = '{BACKUP_SCHEMA}' 
                    AND table_name = '{table_name}_backup_{yesterday}'
                )
            """)
            table_exists = cur.fetchone()[0]
            
            if table_exists:
                # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª ××××©
                cur.execute(f"SELECT COUNT(*) FROM {yesterday_table}")
                yesterday_records = cur.fetchone()[0]
                
                # ×§×‘×œ×ª ×’×•×“×œ ×”×˜×‘×œ×” ××××©
                cur.execute(f"""
                    SELECT pg_size_pretty(pg_total_relation_size('{yesterday_table}'))
                """)
                yesterday_size = cur.fetchone()[0]
                
                # ğŸš¨ ×”×’× ×” ××¤× ×™ ×™×¨×™×“×•×ª ×“×¨×¡×˜×™×•×ª ×‘-chat_messages
                records_diff = today_info["records_count"] - yesterday_records
                if table_name == "chat_messages" and records_diff < -10:
                    logger.error(f"ğŸš¨ ALERT: {table_name} ×™×¨×“ ×‘-{abs(records_diff)} ×”×•×“×¢×•×ª! ×–×” ×—×©×•×“ ×œ××—×™×§×”!")
                    send_admin_notification(
                        f"ğŸš¨ **××–×”×¨×ª ××—×™×§×” ×—×©×•×“×”!**\n\n" +
                        f"ğŸ“‹ **×˜×‘×œ×”:** {table_name}\n" +
                        f"ğŸ“Š **××ª××•×œ:** {yesterday_records:,} ×”×•×“×¢×•×ª\n" +
                        f"ğŸ“Š **×”×™×•×:** {today_info['records_count']:,} ×”×•×“×¢×•×ª\n" +
                        f"ğŸ“‰ **×™×¨×™×“×”:** {abs(records_diff):,} ×”×•×“×¢×•×ª\n\n" +
                        f"âš ï¸ **chat_messages ×××•×¨ ×¨×§ ×œ×¦×‘×•×¨ ×•×œ× ×œ××—×•×§!**\n" +
                        f"ğŸ” **×‘×“×•×§ ×× ××™×©×”×• ×”×¨×™×¥ ××—×™×§×” ××• clear_user_from_database**",
                        urgent=True
                    )
                
                comparison[table_name] = {
                    "yesterday_records": yesterday_records,
                    "today_records": today_info["records_count"],
                    "records_diff": records_diff,
                    "yesterday_size": yesterday_size,
                    "today_size": today_info["table_size"],
                    "has_yesterday": True
                }
            else:
                comparison[table_name] = {
                    "yesterday_records": 0,
                    "today_records": today_info["records_count"],
                    "records_diff": today_info["records_count"],
                    "yesterday_size": "0 bytes",
                    "today_size": today_info["table_size"],
                    "has_yesterday": False
                }
        
        cur.close()
        conn.close()
        
        return comparison
        
    except Exception as e:
        logger.warning(f"âš ï¸ ×©×’×™××” ×‘×”×©×•×•××” ×¢× ×××©: {e}")
        return {}

def generate_visual_backup_tree(backup_results, yesterday_comparison):
    """×™×•×¦×¨ ×ª×¦×•×’×” ×•×™×–×•××œ×™×ª ×©×œ ××‘× ×” ×ª×™×§×™×•×ª ×”×’×™×‘×•×™"""
    tree = f"```\n{BACKUP_SCHEMA}/\n"
    
    # ××™×¤×•×™ ×©××•×ª ×œ×ª×™×§×™×•×ª ×•×™×–×•××œ×™×•×ª
    folder_mapping = {
        "user_profiles": "user_profile_backup",
        "chat_messages": "chat_history_backup", 
        "interactions_log": "interactions_backup"  # ×”×—×œ×™×¤×” ××ª gpt_calls_log
    }
    
    table_count = len(backup_results)
    for i, (table_name, info) in enumerate(backup_results.items()):
        is_last_table = (i == table_count - 1)
        folder_prefix = "â””â”€â”€ " if is_last_table else "â”œâ”€â”€ "
        
        # ×©× ×”×ª×™×§×™×” ×”×•×™×–×•××œ×™×ª
        visual_folder = folder_mapping.get(table_name, f"{table_name}_backup")
        tree += f"{folder_prefix}ğŸ“ {visual_folder}/\n"
        
        # ×§×‘×œ×ª ×’×™×‘×•×™×™× ×§×•×“××™× ×œ××•×ª×” ×˜×‘×œ×” 
        previous_backups = get_previous_backups_for_table(table_name)
        
        # ×”×•×¡×¤×ª ×”×’×™×‘×•×™ ×”× ×•×›×—×™ ×œ×¨×©×™××”
        all_backups = previous_backups + [info]
        all_backups = sorted(all_backups, key=lambda x: x.get('backup_date', ''), reverse=True)
        
        # ×”×¦×’×ª ×¢×“ 3 ×’×™×‘×•×™×™× ××—×¨×•× ×™×
        backups_to_show = all_backups[:3]
        
        for j, backup in enumerate(backups_to_show):
            is_last_backup = (j == len(backups_to_show) - 1)
            is_today = backup.get('backup_date') == datetime.now().strftime("%d_%m_%Y")
            
            if is_last_table:
                backup_prefix = "    â””â”€â”€ " if is_last_backup else "    â”œâ”€â”€ "
            else:
                backup_prefix = "â”‚   â””â”€â”€ " if is_last_backup else "â”‚   â”œâ”€â”€ "
            
            # ×¤×•×¨××˜ ×”×§×•×‘×¥ ×”×•×™×–×•××œ×™  
            file_name = f"{visual_folder.replace('_backup', '')}_backup_{backup.get('backup_date', 'unknown')}.json"
            size_info = backup.get('table_size', 'unknown')
            
            # ×¡×™××•×Ÿ ×”×’×™×‘×•×™ ×©×œ ×”×™×•×
            today_marker = " ğŸ†•" if is_today else ""
            
            # ×”×©×•×•××” ×¢× ×××©
            change_info = ""
            if is_today and table_name in yesterday_comparison:
                comp = yesterday_comparison[table_name]
                if comp["has_yesterday"]:
                    records_change = comp["records_diff"]
                    if records_change > 0:
                        change_info = f" (+{records_change})"
                    elif records_change < 0:
                        change_info = f" ({records_change})"
            
            tree += f"{backup_prefix}{file_name}  ({size_info}){change_info}{today_marker}\n"
        
        # ×× ×™×© ×™×•×ª×¨ ×’×™×‘×•×™×™×
        if len(all_backups) > 3:
            remaining = len(all_backups) - 3
            if is_last_table:
                tree += f"    â””â”€â”€ ... ×•×¢×•×“ {remaining} ×’×™×‘×•×™×™×\n"
            else:
                tree += f"â”‚   â””â”€â”€ ... ×•×¢×•×“ {remaining} ×’×™×‘×•×™×™×\n"
    
    tree += "```"
    return tree

def get_previous_backups_for_table(table_name):
    """××§×‘×œ ×¨×©×™××ª ×’×™×‘×•×™×™× ×§×•×“××™× ×œ×˜×‘×œ×” ××¡×•×™××ª ××”××¡×“"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×§×‘×œ×ª ×›×œ ×”×˜×‘×œ××•×ª ×©×œ ××•×ª×• ×¡×•×’ ××”××¡×“
        cur.execute(f"""
            SELECT table_name, 
                   pg_size_pretty(pg_total_relation_size('{BACKUP_SCHEMA}.' || table_name)) as size
            FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            AND table_name LIKE '{table_name}_backup_%'
            AND table_name != '{table_name}_backup_{datetime.now().strftime("%d_%m_%Y")}'
            ORDER BY table_name DESC
        """)
        
        backup_tables = cur.fetchall()
        previous_backups = []
        
        for backup_table_name, size in backup_tables:
            # ×—×™×œ×•×¥ ×ª××¨×™×š ×”×’×™×‘×•×™
            backup_date = backup_table_name.split("_backup_")[-1]
            
            previous_backups.append({
                "table_name": table_name,
                "backup_table_name": backup_table_name,
                "backup_date": backup_date,
                "table_size": size
            })
        
        cur.close()
        conn.close()
        
        return previous_backups
        
    except Exception as e:
        logger.warning(f"âš ï¸ ×©×’×™××” ×‘×§×‘×œ×ª ×’×™×‘×•×™×™× ×§×•×“××™× ×œ-{table_name}: {e}")
        return []

def send_detailed_internal_backup_notification(backup_results, total_records, yesterday_comparison):
    """×©×•×œ×— ×”×ª×¨××” ××¤×•×¨×˜×ª ×¢× ×ª×¦×•×’×” ×•×™×–×•××œ×™×ª ×©×œ ×”×’×™×‘×•×™ ×”×¤× ×™××™ ×”××¡×•×“×¨"""
    try:
        backup_time = datetime.now()
        
        # ×›×•×ª×¨×ª ×”×”×•×“×¢×”
        notification = f"ğŸ—„ï¸ **×’×™×‘×•×™ ××¡×•×“×¨ ×™×•××™ ×”×•×©×œ× ×‘×”×¦×œ×—×”**\n\n"
        notification += f"ğŸ“… **{backup_time.strftime('%d/%m/%Y %H:%M')}**\n"
        notification += f"ğŸ“Š **×¡×”\"×›:** {total_records:,} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª\n"
        notification += f"ğŸ”’ **××‘×˜×—×”:** ×’×™×‘×•×™ ××š ×•×¨×§ ×‘××¡×“ × ×ª×•× ×™×\n\n"
        
        # ğŸ¨ ×ª×¦×•×’×” ×•×™×–×•××œ×™×ª ×©×œ ××‘× ×” ×”×ª×™×§×™×•×ª
        notification += f"ğŸ“‚ **××‘× ×” ×’×™×‘×•×™ ×•×™×–×•××œ×™:**\n"
        visual_tree = generate_visual_backup_tree(backup_results, yesterday_comparison)
        notification += f"{visual_tree}\n\n"
        
        # ğŸ”§ ×¤×¨×˜×™× ×˜×›× ×™×™× ××“×•×™×§×™× ×¢× ××¡×¤×¨ ×©×•×¨×•×ª
        notification += f"âš™ï¸ **×¤×¨×˜×™× ×˜×›× ×™×™× ××“×•×™×§×™×:**\n"
        for table_name, info in backup_results.items():
            table_short = table_name.replace("_", " ").title()[:15]
            notification += f"â€¢ **{table_short}:** {info['records_count']:,} ×©×•×¨×•×ª\n"
        
        # ×”×©×•×•××” ×¢× ××ª××•×œ - ××¡×¤×¨×™× ××“×•×™×§×™×
        if yesterday_comparison:
            notification += f"\nğŸ“ˆ **×”×©×•×•××” ××“×•×™×§×ª ×¢× ××ª××•×œ:**\n"
            for table_name, comp in yesterday_comparison.items():
                if comp["has_yesterday"]:
                    diff = comp["records_diff"]
                    if diff > 0:
                        notification += f"â€¢ **{table_name.replace('_', ' ').title()}:** +{diff:,} ×©×•×¨×•×ª\n"
                    elif diff < 0:
                        notification += f"â€¢ **{table_name.replace('_', ' ').title()}:** {diff:,} ×©×•×¨×•×ª âš ï¸\n"
                    else:
                        notification += f"â€¢ **{table_name.replace('_', ' ').title()}:** ×œ×œ× ×©×™× ×•×™\n"
        
        # ×§×•×“×™ ××™×©×•×¨
        notification += f"\nğŸ” **×§×•×“×™ ××™×©×•×¨:**\n"
        for table_name, info in backup_results.items():
            notification += f"â€¢ `{info['confirmation_code']}`\n"
        
        # ××™×§×•× ×•××“×™× ×™×•×ª
        notification += f"\nğŸ“ **Schema:** `{BACKUP_SCHEMA}` | "
        notification += f"ğŸ—“ï¸ **×©××™×¨×”:** {BACKUP_RETENTION_DAYS} ×™××™× | "
        notification += f"â˜ï¸ **××ª××©×š ×‘-Render**"
        
        send_admin_notification(notification)
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”×ª×¨××” ××¤×•×¨×˜×ª: {e}")
        # ×’×™×‘×•×™ - ×”×•×“×¢×” ×§×¦×¨×” ×× ×”××¨×•×›×” × ×›×©×œ×ª
        try:
            backup_summary = f"âœ… **×’×™×‘×•×™ ××¡×•×“×¨ ×”×•×©×œ×**\n"
            backup_summary += f"ğŸ“Š {total_records:,} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª\n"
            backup_summary += f"ğŸ“… {backup_time.strftime('%d/%m/%Y %H:%M')}\n"
            backup_summary += f"ğŸ”’ ××š ×•×¨×§ ×‘××¡×“ × ×ª×•× ×™×"
            send_admin_notification(backup_summary)
        except Exception as e2:
            logger.error(f"âŒ ×©×’×™××” ×’× ×‘×”×•×“×¢×” ×”×§×¦×¨×”: {e2}")

def list_organized_internal_backups():
    """××¦×™×’ ×¨×©×™××ª ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×§×‘×œ×ª ×›×œ ×”×˜×‘×œ××•×ª ×‘-schema ×”×’×™×‘×•×™
        cur.execute(f"""
            SELECT table_name, 
                   pg_size_pretty(pg_total_relation_size('{BACKUP_SCHEMA}.' || table_name)) as size
            FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            ORDER BY table_name DESC
        """)
        
        backup_tables = cur.fetchall()
        
        if not backup_tables:
            print("ğŸ“­ ××™×Ÿ ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™×")
            return
        
        print("ğŸ—„ï¸ ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™× ×–××™× ×™×:")
        print("=" * 60)
        
        # ×§×™×‘×•×¥ ×œ×¤×™ ×˜×‘×œ×” ××§×•×¨×™×ª
        grouped_backups = {}
        for table_name, size in backup_tables:
            # ×—×™×œ×•×¥ ×©× ×”×˜×‘×œ×” ×”××§×•×¨×™×ª
            if "_backup_" in table_name:
                original_table = table_name.split("_backup_")[0]
                if original_table not in grouped_backups:
                    grouped_backups[original_table] = []
                grouped_backups[original_table].append((table_name, size))
        
        for original_table, backups in grouped_backups.items():
            print(f"\nğŸ“‚ {original_table}:")
            
            for backup_table, size in backups[:10]:  # ×”×¦×’ ×¢×“ 10 ××—×¨×•× ×™×
                # ×—×™×œ×•×¥ ×ª××¨×™×š ×”×’×™×‘×•×™
                backup_date = backup_table.split("_backup_")[-1]
                
                # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª
                cur.execute(f"SELECT COUNT(*) FROM {BACKUP_SCHEMA}.{backup_table}")
                records_count = cur.fetchone()[0]
                
                # ×§×‘×œ×ª ×–××Ÿ ×”×’×™×‘×•×™
                cur.execute(f"""
                    SELECT backup_timestamp FROM {BACKUP_SCHEMA}.{backup_table} 
                    LIMIT 1
                """)
                result = cur.fetchone()
                backup_timestamp = result[0] if result else "unknown"
                
                print(f"   ğŸ“„ {backup_table}")
                print(f"      ğŸ“… {backup_date} | ğŸ“Š {records_count:,} ×¨×©×•××•×ª | ğŸ’¾ {size}")
                print(f"      ğŸ• {backup_timestamp}")
            
            if len(backups) > 10:
                print(f"   ... ×•×¢×•×“ {len(backups) - 10} ×’×™×‘×•×™×™×")
        
        cur.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")

def cleanup_old_organized_internal_backups(days_to_keep=30, force_cleanup=False, dry_run=False):
    """×× ×§×” ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™× ×™×©× ×™× ×¢× ×”×’× ×•×ª ××¨×•×‘×•×ª ×¨×‘×“×™×"""
    try:
        # ğŸ›¡ï¸ LAYER 1: ×”×’× ×” ××¤× ×™ ××—×™×§×” ××•×§×“××ª ××“×™
        MINIMUM_RETENTION_DAYS = 7  # ××™× ×™××•× 7 ×™××™× ×©××™×¨×” - ××¡×•×¨ ×œ××—×•×§!
        if days_to_keep < MINIMUM_RETENTION_DAYS:
            logger.error(f"ğŸš¨ BLOCKED: × ×™×¡×™×•×Ÿ ××—×™×§×ª ×’×™×‘×•×™×™× ×¦×¢×™×¨×™× ×-{MINIMUM_RETENTION_DAYS} ×™××™×!")
            send_admin_notification(
                f"ğŸš¨ **××–×”×¨×ª ××‘×˜×—×” - ××—×™×§×ª ×’×™×‘×•×™ ×—×¡×•××”!**\n\n" +
                f"âŒ **× ×™×¡×™×•×Ÿ ××—×™×§×”:** {days_to_keep} ×™××™×\n" +
                f"ğŸ›¡ï¸ **××™× ×™××•× ××•×’×Ÿ:** {MINIMUM_RETENTION_DAYS} ×™××™×\n" +
                f"â›” **×¤×¢×•×œ×” × ×—×¡××”** - ×”×’× ×ª × ×ª×•× ×™× ×¤×¢×™×œ×”!",
                urgent=True
            )
            return False
        
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ğŸ›¡ï¸ LAYER 2: ×‘×“×™×§×ª ××¡×¤×¨ ×’×™×‘×•×™×™× ×›×œ×œ×™
        cur.execute(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            AND table_name LIKE '%_backup_%'
        """)
        total_backups = cur.fetchone()[0]
        
        if total_backups < 3:  # ×”×’× ×” ××¤× ×™ ××—×™×§×ª ×›×œ ×”×’×™×‘×•×™×™×
            logger.error(f"ğŸš¨ BLOCKED: ×¨×§ {total_backups} ×’×™×‘×•×™×™× - ×œ× ××•×—×§!")
            send_admin_notification(
                f"ğŸš¨ **×”×’× ×ª ×’×™×‘×•×™ ×¤×¢×™×œ×”!**\n\n" +
                f"ğŸ“Š **×’×™×‘×•×™×™× ×–××™× ×™×:** {total_backups}\n" +
                f"ğŸ›¡ï¸ **××™× ×™××•× × ×“×¨×©:** 3 ×’×™×‘×•×™×™×\n" +
                f"â›” **××—×™×§×” ×—×¡×•××”** - ×”×’× ×ª × ×ª×•× ×™×!",
                urgent=True
            )
            return False
        
        # ×§×‘×œ×ª ×¨×©×™××ª ×’×™×‘×•×™×™× ×œ××—×™×§×”
        cur.execute(f"""
            SELECT table_name FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            AND table_name LIKE '%_backup_%'
        """)
        backup_tables = cur.fetchall()
        
        # ğŸ›¡ï¸ LAYER 3: ×¡×™××•×œ×¦×™×” ×•×‘×“×™×§×ª ×‘×˜×™×—×•×ª
        tables_to_delete = []
        tables_by_type = {}
        
        for (table_name,) in backup_tables:
            try:
                if "_backup_" in table_name:
                    backup_date_str = table_name.split("_backup_")[-1]
                    backup_date = datetime.strptime(backup_date_str, "%d_%m_%Y")
                    
                    if backup_date < cutoff_date:
                        # ×§×™×‘×•×¥ ×œ×¤×™ ×¡×•×’ ×˜×‘×œ×”
                        original_table = table_name.split("_backup_")[0]
                        if original_table not in tables_by_type:
                            tables_by_type[original_table] = []
                        tables_by_type[original_table].append(table_name)
                        tables_to_delete.append(table_name)
                        
            except Exception as e:
                logger.warning(f"âš ï¸ ×©×’×™××” ×‘×‘×“×™×§×ª ×ª××¨×™×š {table_name}: {e}")
        
        # ğŸ›¡ï¸ LAYER 4: ×”×’× ×” ××¤× ×™ ××—×™×§×ª ×›×œ ×”×’×™×‘×•×™×™× ××¡×•×’ ××¡×•×™×
        for original_table, tables_for_deletion in tables_by_type.items():
            # ×¡×¤×™×¨×ª ×›××” ×’×™×‘×•×™×™× × ×©××¨×™× ×œ××—×¨ ×”××—×™×§×”
            cur.execute(f"""
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = '{BACKUP_SCHEMA}'
                AND table_name LIKE '{original_table}_backup_%'
            """)
            total_for_type = cur.fetchone()[0]
            remaining_after_deletion = total_for_type - len(tables_for_deletion)
            
            if remaining_after_deletion < 2:  # ×—×™×™×‘ ×œ×”×©××™×¨ ×œ×¤×—×•×ª 2 ×’×™×‘×•×™×™×
                logger.error(f"ğŸš¨ BLOCKED: {original_table} ×™×™×©××¨ ×¢× {remaining_after_deletion} ×’×™×‘×•×™×™× ×‘×œ×‘×“!")
                send_admin_notification(
                    f"ğŸš¨ **×”×’× ×ª ×’×™×‘×•×™ ×¡×¤×¦×™×¤×™×ª ×¤×¢×™×œ×”!**\n\n" +
                    f"ğŸ“‹ **×˜×‘×œ×”:** {original_table}\n" +
                    f"ğŸ“Š **×’×™×‘×•×™×™× × ×•×›×—×™×™×:** {total_for_type}\n" +
                    f"ğŸ“‰ **×™×™×©××¨×• ××—×¨×™ ××—×™×§×”:** {remaining_after_deletion}\n" +
                    f"ğŸ›¡ï¸ **××™× ×™××•× × ×“×¨×©:** 2 ×’×™×‘×•×™×™×\n" +
                    f"â›” **××—×™×§×” ×—×¡×•××”** - ×”×’× ×ª × ×ª×•× ×™×!",
                    urgent=True
                )
                return False
        
        if not tables_to_delete:
            logger.info("ğŸ§¹ ××™×Ÿ ×˜×‘×œ××•×ª ×’×™×‘×•×™ ×™×©× ×•×ª ×œ××—×™×§×” (×›×œ ×”×”×’× ×•×ª ×¤×¢×™×œ×•×ª)")
            return True
        
        # ğŸ›¡ï¸ LAYER 5: ××¦×‘ ×¡×™××•×œ×¦×™×” (Dry Run)
        if dry_run:
            logger.info(f"ğŸ§ª DRY RUN: ×”×™×• × ××—×§×•×ª {len(tables_to_delete)} ×˜×‘×œ××•×ª:")
            for table in tables_to_delete:
                logger.info(f"   ğŸ—‘ï¸ [SIMULATION] {table}")
            send_admin_notification(
                f"ğŸ§ª **×¡×™××•×œ×¦×™×” - ××—×™×§×ª ×’×™×‘×•×™×™×**\n\n" +
                f"ğŸ—‘ï¸ **×”×™×• × ××—×§×•×ª:** {len(tables_to_delete)} ×˜×‘×œ××•×ª\n" +
                f"ğŸ“… **×™×©× ×•×ª ×:** {cutoff_date.strftime('%d/%m/%Y')}\n" +
                f"ğŸ’¡ **×–×”×• ××¦×‘ ×¡×™××•×œ×¦×™×” - ×©×•× ×“×‘×¨ ×œ× × ××—×§!**"
            )
            return True
        
        # ğŸ›¡ï¸ LAYER 6: ×“×¨×™×©×ª ××™×©×•×¨ ××¤×•×¨×© (×‘××¦×‘ ×œ× ×›×¤×•×™)
        if not force_cleanup:
            logger.warning(f"âš ï¸ × ×“×¨×© ××™×©×•×¨ ××¤×•×¨×© ×œ××—×™×§×ª {len(tables_to_delete)} ×’×™×‘×•×™×™×")
            send_admin_notification(
                f"âš ï¸ **×‘×§×©×ª ××™×©×•×¨ ××—×™×§×ª ×’×™×‘×•×™×™×**\n\n" +
                f"ğŸ—‘ï¸ **×œ×”××—×§×”:** {len(tables_to_delete)} ×˜×‘×œ××•×ª\n" +
                f"ğŸ“… **×™×©× ×•×ª ×:** {cutoff_date.strftime('%d/%m/%Y')}\n" +
                f"âš¡ **×œ××™×©×•×¨:** ×”×¨×¥ ×¢× `force_cleanup=True`\n" +
                f"ğŸ§ª **×œ×¡×™××•×œ×¦×™×”:** ×”×¨×¥ ×¢× `dry_run=True`\n" +
                f"ğŸ›¡ï¸ **×”×’× ×ª × ×ª×•× ×™× ×¤×¢×™×œ×”!**",
                urgent=True
            )
            return False
        
        # ğŸ›¡ï¸ LAYER 7: ××—×™×§×” ××•×’× ×ª ×¢× ×œ×•×’×™× ××¤×•×¨×˜×™×
        deleted_tables = 0
        for table_name in tables_to_delete:
            try:
                # ×¨×™×©×•× ××¤×•×¨×˜ ×œ×¤× ×™ ××—×™×§×”
                cur.execute(f"SELECT COUNT(*) FROM {BACKUP_SCHEMA}.{table_name}")
                records_count = cur.fetchone()[0]
                
                logger.info(f"ğŸ—‘ï¸ ××•×—×§ ×’×™×‘×•×™ ××•×’×Ÿ: {table_name} ({records_count:,} ×¨×©×•××•×ª)")
                
                cur.execute(f"DROP TABLE {BACKUP_SCHEMA}.{table_name}")
                deleted_tables += 1
                
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘××—×™×§×ª {table_name}: {e}")
        
        conn.commit()
        cur.close()
        conn.close()
        
        # ×”×ª×¨××” ××¤×•×¨×˜×ª ×¢×œ ×”××—×™×§×”
        if deleted_tables > 0:
            logger.info(f"ğŸ§¹ × ××—×§×• {deleted_tables} ×˜×‘×œ××•×ª ×’×™×‘×•×™ (××•×’×Ÿ)")
            
            send_admin_notification(
                f"ğŸ§¹ **× ×™×§×•×™ ×’×™×‘×•×™×™× ×”×•×©×œ× ×‘×”×¦×œ×—×”**\n\n" +
                f"ğŸ—‘ï¸ **× ××—×§×•:** {deleted_tables} ×˜×‘×œ××•×ª\n" +
                f"ğŸ“… **×™×©× ×•×ª ×:** {cutoff_date.strftime('%d/%m/%Y')}\n" +
                f"ğŸ’¾ **×©××™×¨×”:** {days_to_keep} ×™××™×\n" +
                f"ğŸ›¡ï¸ **×”×’× ×•×ª ×©×¢×‘×¨×•:** âœ… ××™× ×™××•× {MINIMUM_RETENTION_DAYS} ×™××™×\n" +
                f"ğŸ—ƒï¸ **Schema:** `{BACKUP_SCHEMA}`\n" +
                f"âš¡ **××¦×‘:** ×›×¤×•×™ (force_cleanup=True)"
            )
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™× ××•×’×Ÿ: {e}")
        send_admin_notification(
            f"ğŸš¨ **×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™×!**\n\n" +
            f"âŒ **×©×’×™××”:** {str(e)[:200]}\n" +
            f"ğŸ›¡ï¸ **×”×’× ×ª × ×ª×•× ×™×:** ×¤×¢×™×œ×”\n" +
            f"ğŸ’¡ **×”××œ×¦×”:** ×‘×“×•×§ ×”×œ×•×’×™×",
            urgent=True
        )
        return False

def safe_backup_cleanup(days_to_keep=30, force=False):
    """× ×™×§×•×™ ×’×™×‘×•×™×™× ×‘×˜×•×— ×¢× ×”×’× ×•×ª ××¨×•×‘×•×ª ×¨×‘×“×™×"""
    try:
        logger.info(f"ğŸ›¡ï¸ ××ª×—×™×œ × ×™×§×•×™ ×’×™×‘×•×™×™× ××•×’×Ÿ (×©××™×¨×”: {days_to_keep} ×™××™×)")
        
        # ×ª×—×™×œ×” - ×¡×™××•×œ×¦×™×” ×œ×¨××•×ª ××” ×”×™×” × ××—×§
        logger.info("ğŸ§ª ××¨×™×¥ ×¡×™××•×œ×¦×™×”...")
        cleanup_old_organized_internal_backups(days_to_keep, force_cleanup=False, dry_run=True)
        
        # ×× ×–×” ×œ× ×›×¤×•×™, ×¨×§ × ×¦×™×’ ××” ×”×™×” ×§×•×¨×” ×•× ×‘×§×© ××™×©×•×¨
        if not force:
            logger.info("âš ï¸ × ×™×§×•×™ ×’×™×‘×•×™×™× ×“×•×¨×© ××™×©×•×¨ ××¤×•×¨×©")
            send_admin_notification(
                f"ğŸ›¡ï¸ **× ×™×§×•×™ ×’×™×‘×•×™×™× ××•×’×Ÿ ××•×›×Ÿ**\n\n" +
                f"ğŸ“… **×œ×©××™×¨×”:** {days_to_keep} ×™××™×\n" +
                f"ğŸ§ª **×¡×™××•×œ×¦×™×” ×”×•×©×œ××”** - ×¨××” ×¤×¨×˜×™× ×‘×œ×•×’\n" +
                f"âš¡ **×œ×‘×™×¦×•×¢:** ×”×¨×¥ ×¢× `force=True`\n" +
                f"ğŸ›¡ï¸ **×”×’× ×•×ª ×¤×¢×™×œ×•×ª:** ××™× ×™××•× 7 ×™××™× + 2 ×’×™×‘×•×™×™× ×œ×˜×‘×œ×”"
            )
            return False
        
        # ×‘×™×¦×•×¢ ×××™×ª×™ ×¢× ×”×’× ×•×ª
        logger.info("âš¡ ××¨×™×¥ × ×™×§×•×™ ×××™×ª×™ ×¢× ×”×’× ×•×ª...")
        return cleanup_old_organized_internal_backups(days_to_keep, force_cleanup=True, dry_run=False)
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×‘×˜×•×—: {e}")
        return False

def get_backup_security_status():
    """×‘×•×“×§ ××¦×‘ ××‘×˜×—×ª ×”×’×™×‘×•×™×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×¡×˜×˜×™×¡×˜×™×§×•×ª ×›×œ×œ×™×•×ª
        cur.execute(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
        """)
        total_backups = cur.fetchone()[0]
        
        # ×‘×“×™×§×” ×œ×¤×™ ×¡×•×’ ×˜×‘×œ×”
        security_status = {
            "total_backups": total_backups,
            "by_table_type": {},
            "oldest_backup": None,
            "newest_backup": None,
            "security_level": "unknown"
        }
        
        for table_name in TABLES_TO_BACKUP:
            cur.execute(f"""
                SELECT COUNT(*) FROM information_schema.tables 
                WHERE table_schema = '{BACKUP_SCHEMA}'
                AND table_name LIKE '{table_name}_backup_%'
            """)
            count = cur.fetchone()[0]
            security_status["by_table_type"][table_name] = count
        
        # ××¦×™××ª ×”×’×™×‘×•×™ ×”×™×©×Ÿ ×•×”×—×“×© ×‘×™×•×ª×¨
        cur.execute(f"""
            SELECT table_name FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            AND table_name LIKE '%_backup_%'
            ORDER BY table_name
        """)
        
        backup_tables = [row[0] for row in cur.fetchall()]
        if backup_tables:
            # ×—×™×œ×•×¥ ×ª××¨×™×›×™×
            dates = []
            for table in backup_tables:
                try:
                    date_str = table.split("_backup_")[-1]
                    date_obj = datetime.strptime(date_str, "%d_%m_%Y")
                    dates.append(date_obj)
                except:
                    pass
            
            if dates:
                security_status["oldest_backup"] = min(dates)
                security_status["newest_backup"] = max(dates)
                
                # ×”×¢×¨×›×ª ×¨××ª ××‘×˜×—×”
                days_coverage = (max(dates) - min(dates)).days
                min_backups_per_type = min(security_status["by_table_type"].values()) if security_status["by_table_type"] else 0
                
                if min_backups_per_type >= 7 and days_coverage >= 7:
                    security_status["security_level"] = "excellent"
                elif min_backups_per_type >= 3 and days_coverage >= 3:
                    security_status["security_level"] = "good"
                elif min_backups_per_type >= 2:
                    security_status["security_level"] = "minimal"
                else:
                    security_status["security_level"] = "critical"
        
        cur.close()
        conn.close()
        
        return security_status
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×‘×“×™×§×ª ××¦×‘ ××‘×˜×—×”: {e}")
        return None

def send_backup_security_report():
    """×©×•×œ×— ×“×•×— ××‘×˜×—×ª ×’×™×‘×•×™×™× ×œ××“××™×Ÿ"""
    try:
        status = get_backup_security_status()
        storage = get_backup_storage_info()
        
        if not status or not storage:
            send_admin_notification("âŒ **×©×’×™××” ×‘×“×•×— ××‘×˜×—×ª ×’×™×‘×•×™×™×** - ×œ× × ×™×ª×Ÿ ×œ×§×‘×œ × ×ª×•× ×™×")
            return
        
        # ××™×™×§×•× ×™× ×œ×¤×™ ×¨××ª ××‘×˜×—×”
        security_icons = {
            "excellent": "ğŸŸ¢",
            "good": "ğŸŸ¡", 
            "minimal": "ğŸŸ ",
            "critical": "ğŸ”´",
            "unknown": "âšª"
        }
        
        icon = security_icons.get(status["security_level"], "âšª")
        
        report = f"{icon} **×“×•×— ××‘×˜×—×ª ×’×™×‘×•×™×™×**\n\n"
        report += f"ğŸ›¡ï¸ **×¨××ª ××‘×˜×—×”:** {status['security_level'].upper()}\n"
        report += f"ğŸ“Š **×¡×”\"×› ×’×™×‘×•×™×™×:** {status['total_backups']}\n"
        report += f"ğŸ’¾ **×’×•×“×œ ×›×•×œ×œ:** {storage['total_backup_size']}\n\n"
        
        report += f"ğŸ“‹ **×¤×™×¨×•×˜ ×œ×¤×™ ×˜×‘×œ×”:**\n"
        for table, count in status["by_table_type"].items():
            table_icon = "âœ…" if count >= 3 else "âš ï¸" if count >= 2 else "âŒ"
            report += f"{table_icon} **{table.replace('_', ' ').title()}:** {count} ×’×™×‘×•×™×™×\n"
        
        if status["oldest_backup"] and status["newest_backup"]:
            days_coverage = (status["newest_backup"] - status["oldest_backup"]).days
            report += f"\nğŸ“… **×›×™×¡×•×™ ×–××Ÿ:** {days_coverage} ×™××™×\n"
            report += f"ğŸ“† **×:** {status['oldest_backup'].strftime('%d/%m/%Y')}\n"
            report += f"ğŸ“† **×¢×“:** {status['newest_backup'].strftime('%d/%m/%Y')}\n"
        
        # ×”××œ×¦×•×ª
        report += f"\nğŸ’¡ **×”××œ×¦×•×ª ××‘×˜×—×”:**\n"
        if status["security_level"] == "critical":
            report += "ğŸš¨ **×“×—×•×£:** ×™×© ×¤×—×•×ª ×-2 ×’×™×‘×•×™×™× ×œ×˜×‘×œ×”!\n"
        elif status["security_level"] == "minimal":
            report += "âš ï¸ **×–×”×™×¨×•×ª:** ××•××œ×¥ ×œ×”×’×“×™×œ ××¡×¤×¨ ×’×™×‘×•×™×™×\n"
        else:
            report += "âœ… **××¦×•×™×Ÿ:** ×¨××ª ×”×’× ×” ×˜×•×‘×”\n"
        
        report += f"ğŸ—ƒï¸ **Schema:** `{BACKUP_SCHEMA}`"
        
        send_admin_notification(report)
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×“×•×— ××‘×˜×—×”: {e}")

def get_backup_storage_info():
    """××—×–×™×¨ ××™×“×¢ ×¢×œ ×©×˜×— ×”×’×™×‘×•×™ ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×’×•×“×œ schema ×”×’×™×‘×•×™
        cur.execute(f"""
            SELECT 
                pg_size_pretty(
                    sum(pg_total_relation_size('{BACKUP_SCHEMA}.' || table_name))
                ) as total_backup_size
            FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
        """)
        
        result = cur.fetchone()
        total_backup_size = result[0] if result and result[0] else "0 bytes"
        
        # ××¡×¤×¨ ×˜×‘×œ××•×ª ×’×™×‘×•×™
        cur.execute(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
        """)
        
        backup_tables_count = cur.fetchone()[0]
        
        # ×’×•×“×œ ××¡×“ × ×ª×•× ×™× ×›×œ×œ×™
        cur.execute("SELECT pg_size_pretty(pg_database_size(current_database()))")
        total_db_size = cur.fetchone()[0]
        
        cur.close()
        conn.close()
        
        return {
            "total_backup_size": total_backup_size,
            "backup_tables_count": backup_tables_count,
            "total_db_size": total_db_size,
            "backup_schema": BACKUP_SCHEMA
        }
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×§×‘×œ×ª ××™×“×¢ ××—×¡×•×Ÿ: {e}")
        return None

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "backup":
            run_organized_internal_backup()
        elif command == "list":
            list_organized_internal_backups()
        elif command == "info":
            info = get_backup_storage_info()
            if info:
                print(f"ğŸ—ƒï¸ Schema: {info['backup_schema']}")
                print(f"ğŸ“Š ×˜×‘×œ××•×ª ×’×™×‘×•×™: {info['backup_tables_count']}")
                print(f"ğŸ’¾ ×’×•×“×œ ×’×™×‘×•×™: {info['total_backup_size']}")
                print(f"ğŸ—„ï¸ ×’×•×“×œ ××¡×“ ×›×œ×œ×™: {info['total_db_size']}")
        
        # ğŸ›¡ï¸ ×¤×§×•×“×•×ª × ×™×§×•×™ ××•×’× ×•×ª
        elif command == "cleanup":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            print(f"ğŸ›¡ï¸ ××¨×™×¥ × ×™×§×•×™ ××•×’×Ÿ (×©××™×¨×”: {days} ×™××™×)")
            print("âš ï¸ ×–×•×”×™ ×¤×¢×•×œ×” ××•×’× ×ª - ×¨×§ ×¡×™××•×œ×¦×™×”!")
            cleanup_old_organized_internal_backups(days, force_cleanup=False, dry_run=True)
            
        elif command == "cleanup-force":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            print(f"âš¡ ××¨×™×¥ × ×™×§×•×™ ×›×¤×•×™ (×©××™×¨×”: {days} ×™××™×)")
            print("ğŸš¨ ×–×•×”×™ ×¤×¢×•×œ×” ×××™×ª×™×ª ×¢× ×”×’× ×•×ª!")
            cleanup_old_organized_internal_backups(days, force_cleanup=True, dry_run=False)
            
        elif command == "safe-cleanup":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            force = len(sys.argv) > 3 and sys.argv[3] == "force"
            print(f"ğŸ›¡ï¸ ××¨×™×¥ × ×™×§×•×™ ×‘×˜×•×— ××œ× (×©××™×¨×”: {days} ×™××™×)")
            safe_backup_cleanup(days, force)
            
        # ğŸ” ×¤×§×•×“×•×ª ×‘×“×™×§×” ×•×“×™×•×•×—
        elif command == "security":
            print("ğŸ” ×‘×•×“×§ ××¦×‘ ××‘×˜×—×ª ×’×™×‘×•×™×™×...")
            status = get_backup_security_status()
            if status:
                print(f"ğŸ›¡ï¸ ×¨××ª ××‘×˜×—×”: {status['security_level']}")
                print(f"ğŸ“Š ×¡×”\"×› ×’×™×‘×•×™×™×: {status['total_backups']}")
                for table, count in status["by_table_type"].items():
                    icon = "âœ…" if count >= 3 else "âš ï¸" if count >= 2 else "âŒ"
                    print(f"{icon} {table}: {count} ×’×™×‘×•×™×™×")
            else:
                print("âŒ ×©×’×™××” ×‘×‘×“×™×§×ª ××‘×˜×—×”")
                
        elif command == "security-report":
            print("ğŸ“§ ×©×•×œ×— ×“×•×— ××‘×˜×—×” ×œ××“××™×Ÿ...")
            send_backup_security_report()
            print("âœ… ×“×•×— × ×©×œ×—")
            
        # ğŸ§ª ×¤×§×•×“×•×ª ×‘×“×™×§×”
        elif command == "dry-run":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            print(f"ğŸ§ª ××¨×™×¥ ×¡×™××•×œ×¦×™×” ××œ××” (×©××™×¨×”: {days} ×™××™×)")
            cleanup_old_organized_internal_backups(days, force_cleanup=False, dry_run=True)
            
        else:
            print("ğŸ›¡ï¸ ××¢×¨×›×ª ×’×™×‘×•×™ ××•×’× ×ª - ×¤×§×•×“×•×ª ×–××™× ×•×ª:")
            print("=" * 50)
            print("ğŸ“¦ ×’×™×‘×•×™:")
            print("  backup              - ×¦×•×¨ ×’×™×‘×•×™ ×—×“×©")
            print("  list                - ×”×¦×’ ×¨×©×™××ª ×’×™×‘×•×™×™×")
            print("  info                - ××™×“×¢ ×¢×œ ××—×¡×•×Ÿ")
            print()
            print("ğŸ›¡ï¸ × ×™×§×•×™ ××•×’×Ÿ:")
            print("  cleanup [days]      - ×¡×™××•×œ×¦×™×” ×‘×œ×‘×“ (×‘×¨×™×¨×ª ××—×“×œ: 30)")
            print("  cleanup-force [days]- × ×™×§×•×™ ×××™×ª×™ ×¢× ×”×’× ×•×ª")
            print("  safe-cleanup [days] [force] - × ×™×§×•×™ ×‘×˜×•×— ××œ×")
            print("  dry-run [days]      - ×¡×™××•×œ×¦×™×” ××¤×•×¨×˜×ª")
            print()
            print("ğŸ” ×‘×“×™×§×•×ª ××‘×˜×—×”:")
            print("  security            - ×‘×“×•×§ ××¦×‘ ××‘×˜×—×”")
            print("  security-report     - ×©×œ×— ×“×•×— ×œ××“××™×Ÿ")
            print()
            print("ğŸ›¡ï¸ ×”×’× ×•×ª ×¤×¢×™×œ×•×ª:")
            print("  â€¢ ××™× ×™××•× 7 ×™××™× ×©××™×¨×”")
            print("  â€¢ ××™× ×™××•× 2 ×’×™×‘×•×™×™× ×œ×˜×‘×œ×”")
            print("  â€¢ ××™× ×™××•× 3 ×’×™×‘×•×™×™× ×›×œ×œ×™")
            print("  â€¢ ×¡×™××•×œ×¦×™×” ×œ×¤× ×™ ××—×™×§×”")
            print("  â€¢ ×“×¨×™×©×ª ××™×©×•×¨ ××¤×•×¨×©")
    else:
        # ×’×™×‘×•×™ ×¨×’×™×œ
        run_organized_internal_backup() 