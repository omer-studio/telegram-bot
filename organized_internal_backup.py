#!/usr/bin/env python3
"""
ğŸ—„ï¸ ××¢×¨×›×ª ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨×ª ×‘××¡×“ ×”× ×ª×•× ×™×
×™×•×¦×¨×ª schema "backup" ×¢× ×˜×‘×œ××•×ª ××¡×•×“×¨×•×ª ×œ×›×œ ×ª××¨×™×š
×›××• ×ª×™×§×™×•×ª ××‘×œ ×‘××¡×“ × ×ª×•× ×™× - ××ª××©×š ×‘-Render!
"""

import psycopg2
from datetime import datetime, timedelta
from config import config
from simple_logger import logger
from admin_notifications import send_admin_notification

DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")

# ğŸ¯ ×”×’×“×¨×•×ª ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨
TABLES_TO_BACKUP = ["user_profiles", "chat_messages", "gpt_calls_log"]
BACKUP_SCHEMA = "backup"
BACKUP_RETENTION_DAYS = 30

def create_backup_schema():
    """×™×•×¦×¨ ××ª ×”-schema ×œ×’×™×‘×•×™ ×× ×œ× ×§×™×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×™×¦×™×¨×ª schema ×× ×œ× ×§×™×™×
        cur.execute(f"CREATE SCHEMA IF NOT EXISTS {BACKUP_SCHEMA}")
        conn.commit()
        
        cur.close()
        conn.close()
        
        logger.info(f"âœ… Schema {BACKUP_SCHEMA} ××•×›×Ÿ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª backup schema: {e}")
        return False

def backup_table_to_internal_organized(table_name, backup_date):
    """××’×‘×” ×˜×‘×œ×” ×œ×˜×‘×œ×ª ×’×™×‘×•×™ ××¡×•×“×¨×ª ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×©× ×”×˜×‘×œ×” ×”××¡×•×“×¨×ª
        backup_table_name = f"{table_name}_backup_{backup_date}"
        full_backup_table = f"{BACKUP_SCHEMA}.{backup_table_name}"
        
        # ××—×™×§×ª ×”×˜×‘×œ×” ×× ×§×™×™××ª (×’×™×‘×•×™ ××—×“×©)
        cur.execute(f"DROP TABLE IF EXISTS {full_backup_table}")
        
        # ×™×¦×™×¨×ª ×”×˜×‘×œ×” ×”×—×“×©×” ×¢× × ×ª×•× ×™ ×”×’×™×‘×•×™
        cur.execute(f"""
            CREATE TABLE {full_backup_table} AS 
            SELECT *, 
                   '{backup_date}' as backup_date,
                   '{datetime.now().isoformat()}' as backup_timestamp
            FROM {table_name}
        """)
        
        # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª ×©× ×•×¡×¤×•
        cur.execute(f"SELECT COUNT(*) FROM {full_backup_table}")
        records_count = cur.fetchone()[0]
        
        # ×§×‘×œ×ª ×’×•×“×œ ×”×˜×‘×œ×”
        cur.execute(f"""
            SELECT pg_size_pretty(pg_total_relation_size('{full_backup_table}'))
        """)
        table_size = cur.fetchone()[0]
        
        conn.commit()
        cur.close()
        conn.close()
        
        backup_info = {
            "table_name": table_name,
            "backup_table_name": backup_table_name,
            "full_backup_table": full_backup_table,
            "records_count": records_count,
            "table_size": table_size,
            "backup_date": backup_date,
            "confirmation_code": f"IB-{table_name.upper()[:3]}-{backup_date}-{records_count:04d}",
            "backup_timestamp": datetime.now()
        }
        
        logger.info(f"âœ… {table_name} â†’ {backup_table_name}: {records_count} ×¨×©×•××•×ª ({table_size})")
        return backup_info
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ {table_name}: {e}")
        return None

def run_organized_internal_backup():
    """××¨×™×¥ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ××œ×"""
    try:
        backup_date = datetime.now().strftime("%d_%m_%Y")
        logger.info(f"ğŸ—„ï¸ ××ª×—×™×œ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×œ×ª××¨×™×š {backup_date}")
        
        # ×™×¦×™×¨×ª schema ×”×’×™×‘×•×™
        if not create_backup_schema():
            return False
        
        # ×’×™×‘×•×™ ×›×œ ×˜×‘×œ×”
        backup_results = {}
        total_records = 0
        
        for table_name in TABLES_TO_BACKUP:
            backup_info = backup_table_to_internal_organized(table_name, backup_date)
            
            if backup_info:
                backup_results[table_name] = backup_info
                total_records += backup_info["records_count"]
        
        # ×‘×“×™×§×ª ×”×¦×œ×—×”
        if len(backup_results) == len(TABLES_TO_BACKUP):
            logger.info(f"ğŸ‰ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ ×”×•×©×œ×: {total_records} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª")
            
            # ×”×©×•×•××” ×œ×™×•× ×§×•×“×
            yesterday_comparison = compare_with_yesterday_internal(backup_date, backup_results)
            
            # ×©×œ×™×—×ª ×”×ª×¨××” ××¤×•×¨×˜×ª
            send_detailed_internal_backup_notification(backup_results, total_records, yesterday_comparison)
            
            return True
        else:
            logger.error(f"âŒ ×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨ × ×›×©×œ: {len(backup_results)}/{len(TABLES_TO_BACKUP)} ×˜×‘×œ××•×ª")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¤× ×™××™ ××¡×•×“×¨: {e}")
        return False

def compare_with_yesterday_internal(today_date, today_results):
    """××©×•×•×” ××ª ×”×’×™×‘×•×™ ×©×œ ×”×™×•× ×¢× ×××© ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        yesterday = (datetime.now() - timedelta(days=1)).strftime("%d_%m_%Y")
        comparison = {}
        
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        for table_name, today_info in today_results.items():
            yesterday_table = f"{BACKUP_SCHEMA}.{table_name}_backup_{yesterday}"
            
            # ×‘×“×™×§×” ×× ×”×˜×‘×œ×” ×©×œ ×××© ×§×™×™××ª
            cur.execute(f"""
                SELECT EXISTS (
                    SELECT 1 FROM information_schema.tables 
                    WHERE table_schema = '{BACKUP_SCHEMA}' 
                    AND table_name = '{table_name}_backup_{yesterday}'
                )
            """)
            table_exists = cur.fetchone()[0]
            
            if table_exists:
                # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª ××××©
                cur.execute(f"SELECT COUNT(*) FROM {yesterday_table}")
                yesterday_records = cur.fetchone()[0]
                
                # ×§×‘×œ×ª ×’×•×“×œ ×”×˜×‘×œ×” ××××©
                cur.execute(f"""
                    SELECT pg_size_pretty(pg_total_relation_size('{yesterday_table}'))
                """)
                yesterday_size = cur.fetchone()[0]
                
                comparison[table_name] = {
                    "yesterday_records": yesterday_records,
                    "today_records": today_info["records_count"],
                    "records_diff": today_info["records_count"] - yesterday_records,
                    "yesterday_size": yesterday_size,
                    "today_size": today_info["table_size"],
                    "has_yesterday": True
                }
            else:
                comparison[table_name] = {
                    "yesterday_records": 0,
                    "today_records": today_info["records_count"],
                    "records_diff": today_info["records_count"],
                    "yesterday_size": "0 bytes",
                    "today_size": today_info["table_size"],
                    "has_yesterday": False
                }
        
        cur.close()
        conn.close()
        
        return comparison
        
    except Exception as e:
        logger.warning(f"âš ï¸ ×©×’×™××” ×‘×”×©×•×•××” ×¢× ×××©: {e}")
        return {}

def send_detailed_internal_backup_notification(backup_results, total_records, yesterday_comparison):
    """×©×•×œ×— ×”×ª×¨××” ××¤×•×¨×˜×ª ×¢×œ ×”×’×™×‘×•×™ ×”×¤× ×™××™ ×”××¡×•×“×¨"""
    try:
        backup_time = datetime.now()
        
        # ×›×•×ª×¨×ª ×”×”×•×“×¢×” - ×§×•××¤×§×˜×™×ª ×™×•×ª×¨
        notification = f"ğŸ—„ï¸ **×’×™×‘×•×™ ××¡×•×“×¨ ×™×•××™ ×”×•×©×œ× ×‘×”×¦×œ×—×”**\n\n"
        notification += f"ğŸ“… **{backup_time.strftime('%d/%m/%Y %H:%M')}**\n"
        notification += f"ğŸ“Š **×¡×”\"×›:** {total_records:,} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª\n"
        notification += f"ğŸ—ï¸ **Schema:** `{BACKUP_SCHEMA}`\n\n"
        
        # ×¤×™×¨×•×˜ ×§×•××¤×§×˜×™ ×œ×›×œ ×˜×‘×œ×”
        notification += f"ğŸ“‹ **×¤×™×¨×•×˜ ×˜×‘×œ××•×ª:**\n"
        for table_name, info in backup_results.items():
            # ×©× ×§×¦×¨ ×œ×˜×‘×œ×”
            table_short = table_name.replace("_", " ").title()[:15]
            notification += f"â€¢ **{table_short}:** {info['records_count']:,} ×¨×©×•××•×ª ({info['table_size']})\n"
            
            # ×”×©×•×•××” ×¢× ×××© - ×§×•××¤×§×˜×™×ª
            if table_name in yesterday_comparison:
                comp = yesterday_comparison[table_name]
                if comp["has_yesterday"]:
                    records_change = comp["records_diff"]
                    
                    if records_change > 0:
                        notification += f"  ğŸ“ˆ +{records_change} ×××ª××•×œ\n"
                    elif records_change < 0:
                        notification += f"  ğŸ“‰ {records_change} ×××ª××•×œ\n"
                    else:
                        notification += f"  â– ×œ×œ× ×©×™× ×•×™\n"
                else:
                    notification += f"  ğŸ†• ×’×™×‘×•×™ ×¨××©×•×Ÿ\n"
        
        # ×§×•×“×™ ××™×©×•×¨
        notification += f"\nğŸ” **×§×•×“×™ ××™×©×•×¨:**\n"
        for table_name, info in backup_results.items():
            notification += f"â€¢ `{info['confirmation_code']}`\n"
        
        # ××™×§×•× ×•××“×™× ×™×•×ª - ×§×•××¤×§×˜×™
        notification += f"\nğŸ“ **××™×§×•×:** PostgreSQL/{BACKUP_SCHEMA}\n"
        notification += f"ğŸ—“ï¸ **×©××™×¨×”:** {BACKUP_RETENTION_DAYS} ×™××™×\n"
        notification += f"â˜ï¸ **××ª××©×š ×‘-Render** - ×œ× × ××—×§!"
        
        send_admin_notification(notification)
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×”×ª×¨××” ××¤×•×¨×˜×ª: {e}")
        # ×’×™×‘×•×™ - ×”×•×“×¢×” ×§×¦×¨×” ×× ×”××¨×•×›×” × ×›×©×œ×ª
        try:
            backup_summary = f"âœ… **×’×™×‘×•×™ ××¡×•×“×¨ ×”×•×©×œ×**\n"
            backup_summary += f"ğŸ“Š {total_records:,} ×¨×©×•××•×ª ×‘-{len(backup_results)} ×˜×‘×œ××•×ª\n"
            backup_summary += f"ğŸ“… {backup_time.strftime('%d/%m/%Y %H:%M')}"
            send_admin_notification(backup_summary)
        except Exception as e2:
            logger.error(f"âŒ ×©×’×™××” ×’× ×‘×”×•×“×¢×” ×”×§×¦×¨×”: {e2}")

def list_organized_internal_backups():
    """××¦×™×’ ×¨×©×™××ª ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×§×‘×œ×ª ×›×œ ×”×˜×‘×œ××•×ª ×‘-schema ×”×’×™×‘×•×™
        cur.execute(f"""
            SELECT table_name, 
                   pg_size_pretty(pg_total_relation_size('{BACKUP_SCHEMA}.' || table_name)) as size
            FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            ORDER BY table_name DESC
        """)
        
        backup_tables = cur.fetchall()
        
        if not backup_tables:
            print("ğŸ“­ ××™×Ÿ ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™×")
            return
        
        print("ğŸ—„ï¸ ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™× ×–××™× ×™×:")
        print("=" * 60)
        
        # ×§×™×‘×•×¥ ×œ×¤×™ ×˜×‘×œ×” ××§×•×¨×™×ª
        grouped_backups = {}
        for table_name, size in backup_tables:
            # ×—×™×œ×•×¥ ×©× ×”×˜×‘×œ×” ×”××§×•×¨×™×ª
            if "_backup_" in table_name:
                original_table = table_name.split("_backup_")[0]
                if original_table not in grouped_backups:
                    grouped_backups[original_table] = []
                grouped_backups[original_table].append((table_name, size))
        
        for original_table, backups in grouped_backups.items():
            print(f"\nğŸ“‚ {original_table}:")
            
            for backup_table, size in backups[:10]:  # ×”×¦×’ ×¢×“ 10 ××—×¨×•× ×™×
                # ×—×™×œ×•×¥ ×ª××¨×™×š ×”×’×™×‘×•×™
                backup_date = backup_table.split("_backup_")[-1]
                
                # ×§×‘×œ×ª ××¡×¤×¨ ×”×¨×©×•××•×ª
                cur.execute(f"SELECT COUNT(*) FROM {BACKUP_SCHEMA}.{backup_table}")
                records_count = cur.fetchone()[0]
                
                # ×§×‘×œ×ª ×–××Ÿ ×”×’×™×‘×•×™
                cur.execute(f"""
                    SELECT backup_timestamp FROM {BACKUP_SCHEMA}.{backup_table} 
                    LIMIT 1
                """)
                result = cur.fetchone()
                backup_timestamp = result[0] if result else "unknown"
                
                print(f"   ğŸ“„ {backup_table}")
                print(f"      ğŸ“… {backup_date} | ğŸ“Š {records_count:,} ×¨×©×•××•×ª | ğŸ’¾ {size}")
                print(f"      ğŸ• {backup_timestamp}")
            
            if len(backups) > 10:
                print(f"   ... ×•×¢×•×“ {len(backups) - 10} ×’×™×‘×•×™×™×")
        
        cur.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™×: {e}")

def cleanup_old_organized_internal_backups(days_to_keep=30):
    """×× ×§×” ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™× ×™×©× ×™×"""
    try:
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        cutoff_date_str = cutoff_date.strftime("%d_%m_%Y")
        
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×§×‘×œ×ª ×›×œ ×”×˜×‘×œ××•×ª ×‘-schema ×”×’×™×‘×•×™
        cur.execute(f"""
            SELECT table_name FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
            AND table_name LIKE '%_backup_%'
        """)
        
        backup_tables = cur.fetchall()
        deleted_tables = 0
        
        for (table_name,) in backup_tables:
            try:
                # ×—×™×œ×•×¥ ×ª××¨×™×š ×”×’×™×‘×•×™
                if "_backup_" in table_name:
                    backup_date_str = table_name.split("_backup_")[-1]
                    
                    # ×”××¨×ª ×ª××¨×™×š ×œ×¤×•×¨××˜ datetime
                    backup_date = datetime.strptime(backup_date_str, "%d_%m_%Y")
                    
                    # ×‘×“×™×§×” ×× ×”×˜×‘×œ×” ×™×©× ×” ××“×™
                    if backup_date < cutoff_date:
                        cur.execute(f"DROP TABLE {BACKUP_SCHEMA}.{table_name}")
                        deleted_tables += 1
                        logger.info(f"ğŸ—‘ï¸ × ××—×§×” ×˜×‘×œ×” ×™×©× ×”: {table_name}")
                        
            except Exception as e:
                logger.warning(f"âš ï¸ ×©×’×™××” ×‘×‘×“×™×§×ª ×ª××¨×™×š {table_name}: {e}")
        
        conn.commit()
        cur.close()
        conn.close()
        
        if deleted_tables > 0:
            logger.info(f"ğŸ§¹ × ××—×§×• {deleted_tables} ×˜×‘×œ××•×ª ×’×™×‘×•×™ ×™×©× ×•×ª")
            
            send_admin_notification(
                f"ğŸ§¹ **× ×™×§×•×™ ×’×™×‘×•×™×™× ×¤× ×™××™×™× ××¡×•×“×¨×™×**\n\n" +
                f"ğŸ—‘ï¸ **× ××—×§×•:** {deleted_tables} ×˜×‘×œ××•×ª\n" +
                f"ğŸ“… **×™×©× ×•×ª ×:** {cutoff_date.strftime('%d/%m/%Y')}\n" +
                f"ğŸ’¾ **×©××™×¨×ª:** {days_to_keep} ×™××™× ××—×¨×•× ×™×\n" +
                f"ğŸ—ƒï¸ **Schema:** `{BACKUP_SCHEMA}`"
            )
        else:
            logger.info("ğŸ§¹ ××™×Ÿ ×˜×‘×œ××•×ª ×’×™×‘×•×™ ×™×©× ×•×ª ×œ××—×™×§×”")
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘× ×™×§×•×™ ×’×™×‘×•×™×™×: {e}")

def get_backup_storage_info():
    """××—×–×™×¨ ××™×“×¢ ×¢×œ ×©×˜×— ×”×’×™×‘×•×™ ×‘××¡×“ × ×ª×•× ×™×"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # ×’×•×“×œ schema ×”×’×™×‘×•×™
        cur.execute(f"""
            SELECT 
                pg_size_pretty(
                    sum(pg_total_relation_size('{BACKUP_SCHEMA}.' || table_name))
                ) as total_backup_size
            FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
        """)
        
        result = cur.fetchone()
        total_backup_size = result[0] if result and result[0] else "0 bytes"
        
        # ××¡×¤×¨ ×˜×‘×œ××•×ª ×’×™×‘×•×™
        cur.execute(f"""
            SELECT COUNT(*) FROM information_schema.tables 
            WHERE table_schema = '{BACKUP_SCHEMA}'
        """)
        
        backup_tables_count = cur.fetchone()[0]
        
        # ×’×•×“×œ ××¡×“ × ×ª×•× ×™× ×›×œ×œ×™
        cur.execute("SELECT pg_size_pretty(pg_database_size(current_database()))")
        total_db_size = cur.fetchone()[0]
        
        cur.close()
        conn.close()
        
        return {
            "total_backup_size": total_backup_size,
            "backup_tables_count": backup_tables_count,
            "total_db_size": total_db_size,
            "backup_schema": BACKUP_SCHEMA
        }
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×§×‘×œ×ª ××™×“×¢ ××—×¡×•×Ÿ: {e}")
        return None

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "backup":
            run_organized_internal_backup()
        elif command == "list":
            list_organized_internal_backups()
        elif command == "cleanup":
            days = int(sys.argv[2]) if len(sys.argv) > 2 else 30
            cleanup_old_organized_internal_backups(days)
        elif command == "info":
            info = get_backup_storage_info()
            if info:
                print(f"ğŸ—ƒï¸ Schema: {info['backup_schema']}")
                print(f"ğŸ“Š ×˜×‘×œ××•×ª ×’×™×‘×•×™: {info['backup_tables_count']}")
                print(f"ğŸ’¾ ×’×•×“×œ ×’×™×‘×•×™: {info['total_backup_size']}")
                print(f"ğŸ—„ï¸ ×’×•×“×œ ××¡×“ ×›×œ×œ×™: {info['total_db_size']}")
        else:
            print("×©×™××•×©: python organized_internal_backup.py [backup|list|cleanup|info]")
    else:
        # ×’×™×‘×•×™ ×¨×’×™×œ
        run_organized_internal_backup() 