"""
gpt_e_handler.py
----------------
×ž× ×•×¢ gpt_e: ×—×™×“×•×“, ×ª×™×§×•×Ÿ ×•×”×©×œ×ž×ª ×¤×¨×•×¤×™×œ ×¨×’×©×™ ×¢×œ ×‘×¡×™×¡ ×”×™×¡×˜×•×¨×™×” ×•×¤×¨×•×¤×™×œ ×§×™×™×.
×ž×©×ª×ž×© ×‘-Gemini 1.5 Pro (×—×™× ×ž×™) - ×œ×œ× ×¦×•×¨×š ×‘-fallback.

- ×ž×•×¤×¢×œ ×›×œ 50 ×¨×™×¦×•×ª gpt_c, ××• ×ž×¢×œ 20 ×¨×™×¦×•×ª gpt_c ×× ×¢×‘×¨×• 24 ×©×¢×•×ª ×ž××– ×”×¨×™×¦×” ×”××—×¨×•× ×”.
- ×©×•×œ×— ×œ-GPT ××ª ×”×”×™×¡×˜×•×¨×™×” ×•×”×¤×¨×•×¤×™×œ, ×ž×§×‘×œ ×©×“×•×ª ×—×“×©×™×/×ž×ª×•×§× ×™× ×‘×œ×‘×“.
- ×ž×¢×“×›×Ÿ Google Sheets, user_state, ×•×œ×•×’×™×.
"""

import logging
import asyncio
import json
import litellm
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any

# ×™×™×‘×•× ×¤×•× ×§×¦×™×•×ª ×¢×–×¨
from utils import get_chat_history_messages
from sheets_handler import get_user_summary, update_user_profile, get_user_state, reset_gpt_c_run_count
from prompts import PROFILE_EXTRACTION_ENHANCED_PROMPT
from gpt_utils import normalize_usage_dict, safe_get_usage_value
from config import GPT_MODELS, GPT_PARAMS

# ×”×’×“×¨×ª ×œ×•×’×¨
logger = logging.getLogger(__name__)

def should_run_gpt_e(chat_id: str, gpt_c_run_count: int, last_gpt_e_timestamp: Optional[str]) -> bool:
    """
    ×‘×•×“×§ ×”×× ×¦×¨×™×š ×œ×”×¤×¢×™×œ ××ª gpt_e ×œ×¤×™ ×”×ª× ××™× ×©×”×•×’×“×¨×•.
    
    :param chat_id: ×ž×–×”×” ×”×ž×©×ª×ž×©
    :param gpt_c_run_count: ×ž×¡×¤×¨ ×¨×™×¦×•×ª gpt_c ×ž××– ×”×¤×¢× ×”××—×¨×•× ×” ×©-gpt_e ×¨×¥
    :param last_gpt_e_timestamp: ×˜×™×™×ž×¡×˜×ž×¤ ×©×œ ×”×¨×™×¦×” ×”××—×¨×•× ×” ×©×œ gpt_e
    :return: True ×× ×¦×¨×™×š ×œ×”×¤×¢×™×œ gpt_e, False ××—×¨×ª
    """
    # ×ª× ××™ 1: ×”×’×¢× ×• ×œ-50 ×¨×™×¦×•×ª gpt_c
    if gpt_c_run_count >= 50:
        logger.info(f"[gpt_e] Triggering run - gpt_c_run_count >= 50 ({gpt_c_run_count})")
        return True
    
    # ×ª× ××™ 2: ×ž×¢×œ 20 ×¨×™×¦×•×ª gpt_c ×•×¢×‘×¨×• 24 ×©×¢×•×ª ×ž××– ×”×¨×™×¦×” ×”××—×¨×•× ×”
    if gpt_c_run_count > 20 and last_gpt_e_timestamp:
        try:
            last_run = datetime.fromisoformat(last_gpt_e_timestamp.replace('Z', '+00:00'))
            time_since_last_run = datetime.now(last_run.tzinfo) - last_run
            
            if time_since_last_run >= timedelta(hours=24):
                logger.info(f"[gpt_e] Triggering run - {gpt_c_run_count} gpt_c runs and {time_since_last_run.total_seconds()/3600:.1f} hours since last run")
                return True
        except Exception as e:
            logger.error(f"[gpt_e] Error parsing last_gpt_e_timestamp: {e}")
    
    return False

def prepare_gpt_e_prompt(chat_history: List[Dict], current_profile: str) -> str:
    """
    ×ž×›×™×Ÿ ××ª ×”×¤×¨×•×ž×¤×˜ ×œ-gpt_e ×¢× ×”×”×™×¡×˜×•×¨×™×” ×•×”×¤×¨×•×¤×™×œ ×”×§×™×™×.
    
    :param chat_history: ×¨×©×™×ž×ª ×”×•×“×¢×•×ª ×ž×”×©×™×—×”
    :param current_profile: ×”×¤×¨×•×¤×™×œ ×”×¨×’×©×™ ×”×§×™×™×
    :return: ×¤×¨×•×ž×¤×˜ ×ž×•×›×Ÿ ×œ×©×œ×™×—×” ×œ-GPT
    """
    # ×”×ž×¨×ª ×”×™×¡×˜×•×¨×™×” ×œ×¤×•×¨×ž×˜ ×ž×ª××™×
    formatted_history = []
    for msg in chat_history:
        if msg.get('role') in ['user', 'assistant']:
            formatted_history.append({
                'role': msg['role'],
                'content': msg.get('text', msg.get('content', ''))
            })
    
    # ×™×¦×™×¨×ª ×¤×¨×•×ž×¤×˜ ×ž×•×ª×× ×œ-gpt_e
    user_prompt = f"""
××ª×” ×ž×§×‘×œ ×”×™×¡×˜×•×¨×™×” ×©×œ ×©×™×—×” ×‘×™×Ÿ ×ž×©×ª×ž×© ×œ×‘×•×˜, ×•×¤×¨×•×¤×™×œ ×¨×’×©×™ ×§×™×™× ×©×œ ×”×ž×©×ª×ž×©.

×ž×˜×¨×ª×š: ×œ×–×”×•×ª ×ž×™×“×¢ ×—×“×©, ×œ×ª×§×Ÿ ×˜×¢×•×™×•×ª, ×•×œ×—×“×“ ××ª ×”×¤×¨×•×¤×™×œ ×”×¨×’×©×™.

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×” (50 ×”×•×“×¢×•×ª ××—×¨×•× ×•×ª):
{json.dumps(formatted_history, ensure_ascii=False, indent=2)}

×¤×¨×•×¤×™×œ ×¨×’×©×™ ×§×™×™×:
{current_profile}

×”× ×—×™×•×ª:
1. ×–×”×” ×ž×™×“×¢ ×—×“×© ×©×œ× × ×›×œ×œ ×‘×¤×¨×•×¤×™×œ ×”×§×™×™×
2. ×ª×§×Ÿ ×˜×¢×•×™×•×ª ××• ××™-×“×™×•×§×™× ×‘×¤×¨×•×¤×™×œ ×”×§×™×™×
3. ×—×“×“ ×ž×™×“×¢ ×§×™×™× ×¢× ×¤×¨×˜×™× × ×•×¡×¤×™×
4. ×”×—×–×¨ ×¨×§ ×©×“×•×ª ×—×“×©×™×/×ž×ª×•×§× ×™× ×‘×¤×•×¨×ž×˜ JSON
5. ×× ××™×Ÿ ×ž×™×“×¢ ×—×“×© - ×”×—×–×¨ {{}}
6. ×× ×™×© ×ž×™×“×¢ ××™×©×™ ×©×œ× × ×›× ×¡ ×œ×©×•× ×©×“×” - ×”×•×¡×£ ×œ-"other_insights"

×©×“×•×ª ×ž×•×ª×¨×™×:
- age, relationship_type, parental_status, occupation_or_role
- self_religious_affiliation, self_religiosity_level, family_religiosity
- closet_status, who_knows, who_doesnt_know, attracted_to
- attends_therapy, primary_conflict, trauma_history
- goal_in_course, fears_concerns, future_vision
- other_insights (×ž×™×“×¢ ××™×©×™ × ×•×¡×£)

×”×—×–×¨ JSON ×‘×œ×‘×“:
"""

    return user_prompt

def run_gpt_e(chat_id: str) -> Dict[str, Any]:
    """
    ×ž×‘×¦×¢ ×—×™×“×•×“ ×•×ª×™×§×•×Ÿ ×¤×¨×•×¤×™×œ ×¨×’×©×™ ×œ×ž×©×ª×ž×© ×œ×¤×™ ×”×”× ×—×™×•×ª.
    
    :param chat_id: ×ž×–×”×” ×”×ž×©×ª×ž×©
    :return: ×ž×™×œ×•×Ÿ ×¢× ×ª×•×¦××•×ª ×”×¨×™×¦×” (success, changes, errors)
    """
    start_time = datetime.now()
    logger.info(f"[gpt_e] Starting run_gpt_e for chat_id={chat_id} at {start_time.isoformat()}")
    
    result = {
        'success': False,
        'changes': {},
        'errors': [],
        'tokens_used': 0,
        'execution_time': 0
    }
    
    try:
        # ×©×œ×‘ 1: ×©×œ×™×¤×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”
        logger.info(f"[gpt_e] Fetching chat history for chat_id={chat_id}")
        chat_history = get_chat_history_messages(chat_id, limit=50)
        
        if not chat_history:
            result['errors'].append("No chat history found")
            logger.warning(f"[gpt_e] No chat history found for chat_id={chat_id}")
            return result
        
        logger.info(f"[gpt_e] Retrieved {len(chat_history)} messages from chat history")
        
        # ×©×œ×‘ 2: ×©×œ×™×¤×ª ×¤×¨×•×¤×™×œ ×§×™×™×
        logger.info(f"[gpt_e] Fetching current profile for chat_id={chat_id}")
        current_profile = get_user_summary(chat_id)
        
        if not current_profile:
            current_profile = "××™×Ÿ ×¤×¨×•×¤×™×œ ×§×™×™×"
            logger.info(f"[gpt_e] No existing profile found for chat_id={chat_id}")
        
        # ×©×œ×‘ 3: ×”×›× ×ª ×¤×¨×•×ž×¤×˜
        user_prompt = prepare_gpt_e_prompt(chat_history, current_profile)
        
        # ×©×œ×‘ 4: ×©×œ×™×—×” ×œ-GPT
        logger.info(f"[gpt_e] Sending request to GPT for chat_id={chat_id}")
        
        try:
            metadata = {"gpt_identifier": "gpt_e", "chat_id": chat_id}
            params = GPT_PARAMS["gpt_e"]
            model = GPT_MODELS["gpt_e"]
            
            completion_params = {
                "model": model,
                "messages": [
                    {"role": "system", "content": PROFILE_EXTRACTION_ENHANCED_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": params["temperature"],
                "max_tokens": params["max_tokens"],
                "metadata": metadata,
                "store": True
            }
            
            from gpt_utils import measure_llm_latency
            with measure_llm_latency(model):
                response = litellm.completion(**completion_params)
            
            # ×—×™×œ×•×¥ ×”×ª×•×›×Ÿ ×ž×”×ª×’×•×‘×”
            content = response.choices[0].message.content.strip()
            logger.info(f"[gpt_e] Received response from GPT: {content[:200]}...")
            
            # × ×™×¨×ž×•×œ usage ×‘××•×¤×Ÿ ×‘×˜×•×—
            usage = normalize_usage_dict(response.usage, response.model)
            
            # ×—×™×œ×•×¥ cached_tokens ×‘×‘×˜×—×”
            cached_tokens = safe_get_usage_value(response.usage, 'cached_tokens', 0)
            if cached_tokens == 0 and hasattr(response.usage, 'prompt_tokens_details'):
                cached_tokens = safe_get_usage_value(response.usage.prompt_tokens_details, 'cached_tokens', 0)
            
            # ×¢×“×›×•×Ÿ ×”-usage ×¢× cached_tokens
            usage["cached_tokens"] = cached_tokens
            
            result['tokens_used'] = response.usage.total_tokens
            result['cost_data'] = usage
            
        except Exception as e:
            result['errors'].append(f"GPT API error: {str(e)}")
            logger.error(f"[gpt_e] GPT API error for chat_id={chat_id}: {e}")
            return result
        
        if not content:
            result['errors'].append("Empty response from GPT")
            logger.error(f"[gpt_e] Empty response from GPT for chat_id={chat_id}")
            return result

        # ×©×œ×‘ 5: × ×™×ª×•×— ×”×ª×’×•×‘×”
        # × ×™×¡×™×•×Ÿ ×œ×—×œ×¥ JSON ×ž×”×ª×’×•×‘×”
        try:
            # ×—×™×¤×•×© JSON ×‘×ª×’×•×‘×”
            if content.startswith('{') and content.endswith('}'):
                changes = json.loads(content)
            else:
                # ×—×™×¤×•×© JSON ×‘×ª×•×š ×”×˜×§×¡×˜
                start_idx = content.find('{')
                end_idx = content.rfind('}') + 1
                if start_idx != -1 and end_idx > start_idx:
                    json_str = content[start_idx:end_idx]
                    changes = json.loads(json_str)
                else:
                    changes = {}
            
            logger.info(f"[gpt_e] Parsed changes: {changes}")
            
            # ×©×œ×‘ 6: ×¢×“×›×•×Ÿ ×”×¤×¨×•×¤×™×œ ×× ×™×© ×©×™× ×•×™×™×
            if changes and isinstance(changes, dict):
                # ×”×¡×¨×ª ×©×“×•×ª ×¨×™×§×™×
                changes = {k: v for k, v in changes.items() if v and v != ""}
                
                if changes:
                    logger.info(f"[gpt_e] Updating profile with changes: {changes}")
                    # ×”×“×¤×¡×ª ×ž×™×“×¢ ×—×©×•×‘ ×¢×œ ×¢×“×›×•×Ÿ × ×ª×•× ×™× (×ª×ž×™×“ ×™×•×¤×™×¢!)
                    print(f"ðŸ”„ [GPT-E] ×ž×¢×“×›×Ÿ {len(changes)} ×©×“×•×ª: {list(changes.keys())}")
                    if 'cost_data' in result and result['cost_data']:
                        print(f"ðŸ’° [GPT-E] ×¢×œ×•×ª: {result['cost_data'].get('cost_total', 0):.6f}$ | ×˜×•×§× ×™×: {result['cost_data'].get('total_tokens', 0)}")
                    update_user_profile(chat_id, changes)
                    result['changes'] = changes
                    logger.info(f"[gpt_e] Profile updated successfully for chat_id={chat_id}")
                    print(f"âœ… [GPT-E] ×¢×“×›×•×Ÿ ×”×¤×¨×•×¤×™×œ ×”×•×©×œ× ×‘×”×¦×œ×—×”")
                else:
                    logger.info(f"[gpt_e] No meaningful changes found for chat_id={chat_id}")
            else:
                logger.info(f"[gpt_e] No changes to apply for chat_id={chat_id}")
                
        except json.JSONDecodeError as e:
            result['errors'].append(f"Failed to parse JSON response: {e}")
            logger.error(f"[gpt_e] JSON parsing error for chat_id={chat_id}: {e}")
            return result
        
        # ×©×œ×‘ 7: ×¢×“×›×•×Ÿ ×¡×˜×˜×™×¡×˜×™×§×•×ª
        result['success'] = True
        result['execution_time'] = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"[gpt_e] Completed successfully for chat_id={chat_id} in {result['execution_time']:.2f}s")
        
    except Exception as e:
        result['errors'].append(f"Unexpected error: {str(e)}")
        logger.error(f"[gpt_e] Unexpected error for chat_id={chat_id}: {e}", exc_info=True)
    
    return result

def update_user_state_after_gpt_e(chat_id: str, result: Dict[str, Any]) -> None:
    """
    ×ž×¢×“×›×Ÿ ××ª ×ž×¦×‘ ×”×ž×©×ª×ž×© ×œ××—×¨ ×¨×™×¦×ª gpt_e.
    
    :param chat_id: ×ž×–×”×” ×”×ž×©×ª×ž×©
    :param result: ×ª×•×¦××•×ª ×”×¨×™×¦×”
    """
    try:
        if result['success']:
            # ××™×¤×•×¡ ×ž×•× ×” gpt_c_run_count ×•×¢×“×›×•×Ÿ last_gpt_e_timestamp
            success = reset_gpt_c_run_count(chat_id)
            
            if success:
                logger.info(f"[gpt_e] Updated user state for chat_id={chat_id} after successful run")
            else:
                logger.error(f"[gpt_e] Failed to update user state for chat_id={chat_id}")
        else:
            logger.warning(f"[gpt_e] Not updating user state for chat_id={chat_id} due to failed run")
        
    except Exception as e:
        logger.error(f"[gpt_e] Error updating user state for chat_id={chat_id}: {e}")

def log_gpt_e_run(chat_id: str, result: Dict[str, Any]) -> None:
    """
    ×ž×ª×¢×“ ××ª ×¨×™×¦×ª gpt_e ×‘×œ×•×’×™×.
    
    :param chat_id: ×ž×–×”×” ×”×ž×©×ª×ž×©
    :param result: ×ª×•×¦××•×ª ×”×¨×™×¦×”
    """
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'chat_id': chat_id,
        'success': result['success'],
        'changes_count': len(result.get('changes', {})),
        'tokens_used': result.get('tokens_used', 0),
        'execution_time': result.get('execution_time', 0),
        'errors': result.get('errors', [])
    }
    
    if result.get('changes'):
        log_entry['changes'] = result['changes']
    
    logger.info(f"[gpt_e] Run log: {json.dumps(log_entry, ensure_ascii=False)}")

def execute_gpt_e_if_needed(chat_id: str, gpt_c_run_count: int, last_gpt_e_timestamp: str = None) -> Optional[Dict[str, Any]]:
    """
    ×‘×•×“×§ ×× ×¦×¨×™×š ×œ×”×¤×¢×™×œ gpt_e ×•×ž×¤×¢×™×œ ×× ×›×Ÿ.
    
    ×”×ª× ××™× ×œ×”×¤×¢×œ×”:
    1. gpt_c_run_count >= 50
    2. ××• gpt_c_run_count >= 21 AND ×¢×‘×¨×• 24 ×©×¢×•×ª ×ž××– ×”×¨×™×¦×” ×”××—×¨×•× ×”
    
    :param chat_id: ×ž×–×”×” ×”×ž×©×ª×ž×©
    :param gpt_c_run_count: ×ž×¡×¤×¨ ×¨×™×¦×•×ª gpt_c ×ž××– ×”×¨×™×¦×” ×”××—×¨×•× ×” ×©×œ gpt_e
    :param last_gpt_e_timestamp: ×˜×™×™×ž×¡×˜×ž×¤ ×©×œ ×”×¨×™×¦×” ×”××—×¨×•× ×” ×©×œ gpt_e
    :return: ×ª×•×¦××•×ª ×”×¨×™×¦×” ×× ×”×•×¤×¢×œ, None ×× ×œ× ×”×•×¤×¢×œ
    """
    logger.info(f"[gpt_e] Checking conditions for chat_id={chat_id}, gpt_c_run_count={gpt_c_run_count}")
    
    # ×‘×“×™×§×” ×× ×™×© ×¦×•×¨×š ×œ×”×¤×¢×™×œ gpt_e
    should_run = False
    reason = ""
    
    # ×ª× ××™ 1: 50 ×¨×™×¦×•×ª ××• ×™×•×ª×¨
    if gpt_c_run_count >= 50:
        should_run = True
        reason = f"gpt_c_run_count >= 50 (current: {gpt_c_run_count})"
    
    # ×ª× ××™ 2: 21-49 ×¨×™×¦×•×ª + 24 ×©×¢×•×ª
    elif gpt_c_run_count >= 21:
        if last_gpt_e_timestamp:
            try:
                from datetime import datetime
                last_run = datetime.fromisoformat(last_gpt_e_timestamp.replace('Z', '+00:00'))
                now = datetime.now(last_run.tzinfo) if last_run.tzinfo else datetime.now()
                hours_since_last = (now - last_run).total_seconds() / 3600
                
                if hours_since_last >= 24:
                    should_run = True
                    reason = f"gpt_c_run_count >= 21 ({gpt_c_run_count}) AND 24+ hours passed ({hours_since_last:.1f}h)"
                else:
                    logger.info(f"[gpt_e] Not enough time passed: {hours_since_last:.1f}h < 24h")
            except Exception as e:
                logger.error(f"[gpt_e] Error parsing timestamp {last_gpt_e_timestamp}: {e}")
                # ×× ×™×© ×©×’×™××” ×‘×¤×¢× ×•×— ×”×˜×™×™×ž×¡×˜×ž×¤, × ×¤×¢×™×œ gpt_e
                should_run = True
                reason = f"Error parsing timestamp, running gpt_e as fallback"
        else:
            # ××™×Ÿ ×˜×™×™×ž×¡×˜×ž×¤ ×§×•×“×, × ×¤×¢×™×œ gpt_e
            should_run = True
            reason = f"No previous gpt_e timestamp, running gpt_e"
    
    if should_run:
        logger.info(f"[gpt_e] Conditions met for chat_id={chat_id}: {reason}")
        result = run_gpt_e(chat_id)
        
        # ×¢×“×›×•×Ÿ ×ž×¦×‘ ×”×ž×©×ª×ž×© ×•×œ×•×’×™×
        if result['success']:
            update_user_state_after_gpt_e(chat_id, result)
        
        log_gpt_e_run(chat_id, result)
        
        return result
    else:
        logger.info(f"[gpt_e] Conditions not met for chat_id={chat_id}, gpt_c_run_count={gpt_c_run_count}")
        return None 