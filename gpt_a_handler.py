"""
gpt_a_handler.py
----------------
注 gpt_a: 拽转 转砖 专砖转 (main response logic)
"""

import logging
from datetime import datetime
import json
import litellm
from prompts import SYSTEM_PROMPT
from config import GPT_MODELS, GPT_PARAMS
from gpt_utils import normalize_usage_dict
from gpt_utils import billing_guard
from notifications import alert_billing_issue

# 驻拽爪 专砖转 - 砖转 注 -gpt_a

def get_main_response(full_messages, chat_id=None, message_id=None):
    """
     砖 注 -gpt_a 注 Gemini 2.5 Pro ( 转专).
    驻砖 砖专 - 转   转专.
    """
    metadata = {"gpt_identifier": "gpt_a", "chat_id": chat_id, "message_id": message_id}
    params = GPT_PARAMS["gpt_a"]
    model = GPT_MODELS["gpt_a"]  # gemini/gemini-2.5-pro
    
    completion_params = {
        "model": model,
        "messages": full_messages,
        "temperature": params["temperature"],
        "metadata": metadata,
        "store": True
    }
    
    # 住驻转 max_tokens 专拽    None
    if params["max_tokens"] is not None:
        completion_params["max_tokens"] = params["max_tokens"]
    
    try:
        import litellm
        response = litellm.completion(**completion_params)
        
        bot_reply = response.choices[0].message.content.strip()
        usage = normalize_usage_dict(response.usage, response.model)
        
        #  注拽 专 
        if hasattr(response, 'usage'):
            try:
                cost_usd = litellm.completion_cost(completion_response=response)
                if cost_usd > 0:
                    billing_status = billing_guard.add_cost(cost_usd, response.model, "paid")
                    
                    # 转专转 
                    if billing_status["warnings"]:
                        for warning in billing_status["warnings"]:
                            logging.warning(f"[ 转拽爪] {warning}")
                    
                    # 转专 专  爪专
                    status = billing_guard.get_current_status()
                    alert_billing_issue(
                        cost_usd=cost_usd,
                        model_name=response.model,
                        tier="paid",
                        daily_usage=status["daily_usage"],
                        monthly_usage=status["monthly_usage"],
                        daily_limit=status["daily_limit"],
                        monthly_limit=status["monthly_limit"]
                    )
                
            except Exception as cost_error:
                logging.error(f"[] 砖 砖 注转: {cost_error}")
        
        return {
            "bot_reply": bot_reply, 
            "usage": usage, 
            "model": response.model
        }
        
    except Exception as e:
        logging.error(f"[gpt_a] 砖: {e}")
        return {
            "bot_reply": "[砖 注 专砖 - 住 砖]", 
            "usage": {}, 
            "model": model
        } 