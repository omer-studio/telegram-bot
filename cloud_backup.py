#!/usr/bin/env python3
"""
â˜ï¸ ×ž×¢×¨×›×ª ×’×™×‘×•×™ ×¢× ×Ÿ ×œ×ž×¡×“ × ×ª×•× ×™× × ×¤×¨×“
×©×•×ž×¨ ×’×™×‘×•×™×™× ×‘×ž×¡×“ × ×ª×•× ×™× ×—×™×¦×•× ×™ ×›×’×™×‘×•×™ × ×•×¡×£
"""

import os
import json
import psycopg2
from datetime import datetime
from config import config
from simple_logger import logger
from admin_notifications import send_admin_notification

DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL")

# ðŸŒ URL ×œ×ž×¡×“ ×’×™×‘×•×™ (× ×¤×¨×“ ×ž×”×ž×¡×“ ×”×¨××©×™)
BACKUP_DB_URL = os.getenv("BACKUP_DATABASE_URL")  # ×ž×¡×“ × ×ª×•× ×™× × ×¤×¨×“ ×œ×’×™×‘×•×™×™×

def setup_backup_database():
    """×™×•×¦×¨ ×ž×¡×“ × ×ª×•× ×™× ×œ×’×™×‘×•×™×™× ×‘×ž×¡×“ × ×¤×¨×“"""
    if not BACKUP_DB_URL:
        logger.warning("âš ï¸ BACKUP_DATABASE_URL ×œ× ×ž×•×’×“×¨ - ×ž×©×ª×ž×© ×‘×ž×¡×“ ×”×¨××©×™")
        return DB_URL
    
    try:
        conn = psycopg2.connect(BACKUP_DB_URL)
        cur = conn.cursor()
        
        # ×™×¦×™×¨×ª ×˜×‘×œ×ª ×’×™×‘×•×™×™×
        cur.execute("""
            CREATE TABLE IF NOT EXISTS database_backups (
                id SERIAL PRIMARY KEY,
                backup_date DATE NOT NULL,
                table_name TEXT NOT NULL,
                backup_data JSONB NOT NULL,
                backup_size_mb DECIMAL(10,2),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                checksum TEXT,
                UNIQUE(backup_date, table_name)
            )
        """)
        
        # ×™×¦×™×¨×ª ××™× ×“×§×¡×™× ×œ×‘×™×¦×•×¢×™×
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_backups_date_table 
            ON database_backups(backup_date, table_name)
        """)
        
        cur.execute("""
            CREATE INDEX IF NOT EXISTS idx_backups_created 
            ON database_backups(created_at)
        """)
        
        conn.commit()
        cur.close()
        conn.close()
        
        logger.info("âœ… ×ž×¡×“ ×’×™×‘×•×™×™× ×ž×•×›×Ÿ")
        return BACKUP_DB_URL
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×”×›× ×ª ×ž×¡×“ ×’×™×‘×•×™×™×: {e}")
        return DB_URL

def calculate_checksum(data):
    """×ž×—×©×‘ checksum ×œ× ×ª×•× ×™× ×œ×•×•×“× ×©×œ×ž×•×ª"""
    import hashlib
    json_str = json.dumps(data, sort_keys=True, default=str)
    return hashlib.md5(json_str.encode()).hexdigest()

def backup_table_to_cloud(table_name, backup_date, data):
    """×ž×’×‘×” ×˜×‘×œ×” ×œ×ž×¡×“ ×¢× ×Ÿ × ×¤×¨×“"""
    try:
        backup_db = setup_backup_database()
        conn = psycopg2.connect(backup_db)
        cur = conn.cursor()
        
        # ×—×™×©×•×‘ × ×ª×•× ×™×
        data_size_mb = len(json.dumps(data, default=str)) / (1024 * 1024)
        checksum = calculate_checksum(data)
        
        # ×©×ž×™×¨×ª ×”×’×™×‘×•×™ (UPSERT)
        cur.execute("""
            INSERT INTO database_backups 
            (backup_date, table_name, backup_data, backup_size_mb, checksum)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (backup_date, table_name)
            DO UPDATE SET 
                backup_data = EXCLUDED.backup_data,
                backup_size_mb = EXCLUDED.backup_size_mb,
                checksum = EXCLUDED.checksum,
                created_at = CURRENT_TIMESTAMP
        """, (backup_date, table_name, json.dumps(data, default=str), data_size_mb, checksum))
        
        conn.commit()
        cur.close()
        conn.close()
        
        logger.info(f"â˜ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ {table_name}: {len(data)} ×¨×©×•×ž×•×ª ({data_size_mb:.2f}MB)")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ {table_name}: {e}")
        return False

def restore_from_cloud_backup(table_name, backup_date):
    """×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×¢× ×Ÿ"""
    try:
        backup_db = setup_backup_database()
        conn = psycopg2.connect(backup_db)
        cur = conn.cursor()
        
        # ×§×¨×™××ª ×”×’×™×‘×•×™
        cur.execute("""
            SELECT backup_data, backup_size_mb, checksum, created_at
            FROM database_backups
            WHERE backup_date = %s AND table_name = %s
        """, (backup_date, table_name))
        
        result = cur.fetchone()
        if not result:
            print(f"âŒ ×œ× × ×ž×¦× ×’×™×‘×•×™ ×¢× ×Ÿ ×¢×‘×•×¨ {table_name} ×ž×ª××¨×™×š {backup_date}")
            return False
        
        backup_data, size_mb, checksum, created_at = result
        
        # ×•×™×“×•× ×©×œ×ž×•×ª
        if calculate_checksum(backup_data) != checksum:
            print(f"âŒ ×‘×¢×™×” ×‘×©×œ×ž×•×ª ×”×’×™×‘×•×™ ×¢×‘×•×¨ {table_name}")
            return False
        
        print(f"âœ… × ×ž×¦× ×’×™×‘×•×™ ×¢× ×Ÿ ×ª×§×™×Ÿ:")
        print(f"   ðŸ“… ×ª××¨×™×š: {backup_date}")
        print(f"   ðŸ“Š ×’×•×“×œ: {size_mb:.2f}MB")
        print(f"   ðŸ• × ×•×¦×¨: {created_at}")
        print(f"   ðŸ“ ×¨×©×•×ž×•×ª: {len(backup_data)}")
        
        # ××™×©×•×¨ ×©×—×–×•×¨
        confirm = input("\n×”×× ×œ×‘×¦×¢ ×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×”×¢× ×Ÿ? (YES/no): ")
        if confirm != "YES":
            print("âŒ ×©×—×–×•×¨ ×‘×•×˜×œ")
            return False
        
        # ×‘×™×¦×•×¢ ×”×©×—×–×•×¨ ×‘×ž×¡×“ ×”×¨××©×™
        main_conn = psycopg2.connect(DB_URL)
        main_cur = main_conn.cursor()
        
        # ×ž×—×™×§×ª × ×ª×•× ×™× × ×•×›×—×™×™×
        main_cur.execute(f"DELETE FROM {table_name}")
        
        # ×©×—×–×•×¨ ×”× ×ª×•× ×™×
        if backup_data:
            columns = list(backup_data[0].keys())
            placeholders = ', '.join(['%s'] * len(columns))
            
            insert_sql = f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})"
            
            for row in backup_data:
                values = [row[col] for col in columns]
                main_cur.execute(insert_sql, values)
        
        main_conn.commit()
        main_cur.close()
        main_conn.close()
        
        cur.close()
        conn.close()
        
        print(f"âœ… ×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×¢× ×Ÿ ×”×•×©×œ×: {len(backup_data)} ×¨×©×•×ž×•×ª")
        
        # ×”×ª×¨××” ×œ××“×ž×™×Ÿ
        send_admin_notification(
            f"ðŸ”„ **×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×¢× ×Ÿ**\n\n" +
            f"ðŸ“Š **×˜×‘×œ×”:** {table_name}\n" +
            f"ðŸ“… **×ª××¨×™×š ×’×™×‘×•×™:** {backup_date}\n" +
            f"ðŸ“ **×¨×©×•×ž×•×ª ×©×•×—×–×¨×•:** {len(backup_data)}\n" +
            f"ðŸ’¾ **×’×•×“×œ:** {size_mb:.2f}MB"
        )
        
        return True
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×¢× ×Ÿ: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×©×—×–×•×¨ ×ž×’×™×‘×•×™ ×¢× ×Ÿ: {e}")
        return False

def run_cloud_backup():
    """×ž×¨×™×¥ ×’×™×‘×•×™ ×¢× ×Ÿ ×ž×œ×"""
    try:
        logger.info("â˜ï¸ ×ž×ª×—×™×œ ×’×™×‘×•×™ ×¢× ×Ÿ")
        
        # ×§×¨×™××ª ×”× ×ª×•× ×™× ×ž×”×ž×¡×“ ×”×¨××©×™
        from daily_backup import CRITICAL_TABLES, backup_table_to_json
        
        backup_date = datetime.now().strftime("%Y-%m-%d")
        successful_backups = 0
        
        for table in CRITICAL_TABLES:
            try:
                # ×§×¨×™××ª ×”× ×ª×•× ×™×
                conn = psycopg2.connect(DB_URL)
                cur = conn.cursor()
                
                cur.execute(f"SELECT * FROM {table}")
                rows = cur.fetchall()
                
                # ×©×œ×™×¤×ª ×©×ž×•×ª ×”×¢×ž×•×“×•×ª
                cur.execute(f"""
                    SELECT column_name 
                    FROM information_schema.columns 
                    WHERE table_name = '{table}' 
                    ORDER BY ordinal_position
                """)
                columns = [row[0] for row in cur.fetchall()]
                
                # ×”×ž×¨×” ×œ-JSON
                data = []
                for row in rows:
                    row_dict = {}
                    for i, col in enumerate(columns):
                        value = row[i]
                        if isinstance(value, datetime):
                            value = value.isoformat()
                        row_dict[col] = value
                    data.append(row_dict)
                
                cur.close()
                conn.close()
                
                # ×’×™×‘×•×™ ×œ×¢× ×Ÿ
                if backup_table_to_cloud(table, backup_date, data):
                    successful_backups += 1
                
            except Exception as e:
                logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ {table}: {e}")
        
        if successful_backups == len(CRITICAL_TABLES):
            logger.info(f"â˜ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ ×”×•×©×œ× ×‘×”×¦×œ×—×”: {successful_backups}/{len(CRITICAL_TABLES)} ×˜×‘×œ××•×ª")
            
            # ×”×ª×¨××” ×œ××“×ž×™×Ÿ
            send_admin_notification(
                f"â˜ï¸ **×’×™×‘×•×™ ×¢× ×Ÿ ×”×•×©×œ×**\n\n" +
                f"âœ… **×˜×‘×œ××•×ª × ×•×’×‘×•:** {successful_backups}/{len(CRITICAL_TABLES)}\n" +
                f"ðŸ“… **×ª××¨×™×š:** {backup_date}\n" +
                f"ðŸ”’ **×ž×™×§×•×:** ×ž×¡×“ × ×ª×•× ×™× × ×¤×¨×“"
            )
            
            return True
        else:
            logger.warning(f"âš ï¸ ×’×™×‘×•×™ ×¢× ×Ÿ ×—×œ×§×™: {successful_backups}/{len(CRITICAL_TABLES)} ×˜×‘×œ××•×ª")
            return False
        
    except Exception as e:
        logger.error(f"âŒ ×©×’×™××” ×‘×’×™×‘×•×™ ×¢× ×Ÿ: {e}")
        return False

def list_cloud_backups():
    """×ž×¦×™×’ ×¨×©×™×ž×ª ×’×™×‘×•×™×™× ×¢× ×Ÿ ×–×ž×™× ×™×"""
    try:
        backup_db = setup_backup_database()
        conn = psycopg2.connect(backup_db)
        cur = conn.cursor()
        
        cur.execute("""
            SELECT backup_date, table_name, backup_size_mb, created_at
            FROM database_backups
            ORDER BY backup_date DESC, table_name
        """)
        
        backups = cur.fetchall()
        
        if not backups:
            print("ðŸ“‹ ××™×Ÿ ×’×™×‘×•×™×™× ×¢× ×Ÿ ×–×ž×™× ×™×")
            return
        
        print("â˜ï¸ ×’×™×‘×•×™×™× ×¢× ×Ÿ ×–×ž×™× ×™×:")
        print("=" * 80)
        
        current_date = None
        for backup_date, table_name, size_mb, created_at in backups:
            if backup_date != current_date:
                current_date = backup_date
                print(f"\nðŸ“… {backup_date}:")
            
            print(f"   ðŸ“Š {table_name}: {size_mb:.2f}MB (× ×•×¦×¨: {created_at.strftime('%H:%M:%S')})")
        
        cur.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™× ×¢× ×Ÿ: {e}")
        logger.error(f"âŒ ×©×’×™××” ×‘×¦×¤×™×™×” ×‘×’×™×‘×•×™×™× ×¢× ×Ÿ: {e}")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "backup":
            run_cloud_backup()
        elif command == "list":
            list_cloud_backups()
        elif command == "restore":
            if len(sys.argv) < 4:
                print("×©×™×ž×•×©: python cloud_backup.py restore <table_name> <backup_date>")
                print("×“×•×’×ž×”: python cloud_backup.py restore user_profiles 2025-01-09")
            else:
                table_name = sys.argv[2]
                backup_date = sys.argv[3]
                restore_from_cloud_backup(table_name, backup_date)
        else:
            print("×©×™×ž×•×©: python cloud_backup.py [backup|list|restore]")
    else:
        # ×’×™×‘×•×™ ×¨×’×™×œ
        run_cloud_backup() 