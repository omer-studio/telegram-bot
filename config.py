"""
================================================================================
ğŸš¨ ×—×©×•×‘ ×××•×“ - ×©×ª×™ ×¡×‘×™×‘×•×ª × ×¤×¨×“×•×ª! ğŸš¨
================================================================================

×¡×‘×™×‘×” 1 - ×¨× ×“×¨ (×™×™×¦×•×¨):
   - ×”×§×•×‘×¥ ×”×–×” ×¨×¥ ×™×©×™×¨×•×ª: python main.py
   - ×œ× ××©×ª××© ×‘-ngrok
   - ×œ× ××©×ª××© ×‘-sandbox.py
   - ×¨×¥ ×¢×œ ×¤×•×¨×˜ 8000 ×¢× HTTP server ×¤×©×•×˜

×¡×‘×™×‘×” 2 - ×œ×•×§××œ×™×ª (×¤×™×ª×•×—):
   - ×”×§×•×‘×¥ ×”×–×” ×¨×¥ ×“×¨×š sandbox.py: python sandbox.py
   - ××©×ª××© ×‘-ngrok
   - ×¨×¥ ×¢×œ ×¤×•×¨×˜ 10000 ×¢× uvicorn

âš ï¸  ××œ ×ª×©× ×” ××ª ×”×§×•×‘×¥ ×”×–×” ×›×“×™ ×©×™×ª××™× ×œ×¡×‘×™×‘×” ×œ×•×§××œ×™×ª!
   ×”×¡×‘×™×‘×” ×‘×¨× ×“×¨ ×œ× ×××•×¨×” ×œ×“×¢×ª ×‘×›×œ×œ ×¢×œ sandbox.py!
   ×›×œ ×©×™× ×•×™ ×›××Ÿ ×™×©×¤×™×¢ ×¢×œ ×”×¡×‘×™×‘×” ×‘×¨× ×“×¨!

================================================================================

config.py
---------
×§×•×‘×¥ ×–×” ××¨×›×– ××ª ×›×œ ×”×”×’×“×¨×•×ª (config) ×©×œ ×”×‘×•×˜: ×˜×•×§× ×™×, ××¤×ª×—×•×ª, ×§×‘×¦×™×, Sheets, ×•×¢×•×“.
×”×¨×¦×™×•× ×œ: ×›×œ ×§×•× ×¤×™×’×•×¨×¦×™×” ×‘××§×•× ××—×“, ×›×•×œ×œ ×˜×¢×™× ×”, ×‘×“×™×§×•×ª, ×•×™×¦×™×¨×ª ×§×œ×™×™× ×˜×™×.
"""
import os
import json
import time
import logging
from typing import Optional

# Helper function to handle encoding issues in Windows/CI environments
def safe_print(message, fallback_prefix="[CONFIG]"):
    """
    Print message safely, handling encoding issues in Windows/CI environments.
    If encoding fails, prints a simplified ASCII version.
    """
    try:
        print(message)
    except UnicodeEncodeError:
        # Fallback for Windows with cp1255 or other problematic encodings
        # Remove emojis and problematic Unicode characters
        import re
        clean_message = re.sub(r'[^\x00-\x7F]+', '', str(message))
        print(f"{fallback_prefix} {clean_message}")
    except Exception:
        # Ultimate fallback
        print(f"{fallback_prefix} <message with encoding issues>")

# ×–×™×”×•×™ ×¡×‘×™×‘×ª CI/CD ×œ×¤× ×™ imports ×—×™×¦×•× ×™×™×
IS_CI_ENVIRONMENT = any([
    os.getenv("GITHUB_ACTIONS"),
    os.getenv("CI"),
    os.getenv("CONTINUOUS_INTEGRATION"),
    os.getenv("RUNNER_OS")
])

# imports ×ª×œ×•×™×™ dependencies - ×¨×§ ×‘×¡×‘×™×‘×ª ×™×™×¦×•×¨/×¤×™×ª×•×—
if not IS_CI_ENVIRONMENT:
    try:
        # ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
        # import gspread
        # from oauth2client.service_account import ServiceAccountCredentials
        from lazy_litellm import completion
        from fields_dict import FIELDS_DICT
        # ×™×™×‘×•× ×™×©×™×¨ ×©×œ ×”×¤×¨×•××˜ ×”×¨××©×™ - ×¨×§ ×‘×¡×‘×™×‘×ª ×™×™×¦×•×¨
        try:
            from prompts import SYSTEM_PROMPT
        except ImportError:
            SYSTEM_PROMPT = "dummy system prompt"
    except ImportError as e:
        print(f"âš ï¸ Warning: Failed to import dependency: {e}")
        # ×™×¦×™×¨×ª dummy modules ×›×“×™ ×©×”×§×•×“ ×œ× ×™×§×¨×•×¡
        class DummyModule:
            def __getattr__(self, name):
                return lambda *args, **kwargs: None
        
        # ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
        # gspread = DummyModule()
        # ServiceAccountCredentials = DummyModule()
        completion = DummyModule()
        from fields_dict import FIELDS_DICT
        try:
            from prompts import SYSTEM_PROMPT
        except ImportError:
            SYSTEM_PROMPT = "dummy system prompt"
else:
    # ×¡×‘×™×‘×ª CI - dummy imports
    print("[CI] CI environment detected - using dummy modules")
    class DummyModule:
        def __getattr__(self, name):
            return lambda *args, **kwargs: None
    
    # ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
    # gspread = DummyModule()
    # ServiceAccountCredentials = DummyModule()
    completion = DummyModule()
    import sys as _sys, types as _types
    _lazy = _types.ModuleType("lazy_litellm")
    _lazy.completion = lambda *args, **kwargs: None  # type: ignore[attr-defined]
    _lazy.embedding = lambda *args, **kwargs: None  # type: ignore[attr-defined]
    _sys.modules.setdefault("lazy_litellm", _lazy)
    # ×”×’×“×¨×•×ª dummy ×œ×¡×‘×™×‘×ª CI
    from fields_dict import FIELDS_DICT
    try:
        from prompts import SYSTEM_PROMPT
    except ImportError:
        SYSTEM_PROMPT = "dummy system prompt"


# ×˜×¢×™× ×ª ×§×•× ×¤×™×’×•×¨×¦×™×”
def load_config():
    """
    ×˜×•×¢×Ÿ ××ª ×§×•×‘×¥ ×”×§×•× ×¤×™×’×•×¨×¦×™×” (config.json) ××”× ×ª×™×‘ ×”××ª××™×.
    ×‘×¡×‘×™×‘×ª CI/CD ××—×–×™×¨ ×”×’×“×¨×•×ª dummy.
    ×¤×œ×˜: dict
    """
    # ×–×™×”×•×™ ×¡×‘×™×‘×ª CI/CD
    is_ci_environment = any([
        os.getenv("GITHUB_ACTIONS"),
        os.getenv("CI"),
        os.getenv("CONTINUOUS_INTEGRATION"),
        os.getenv("RUNNER_OS")  # GitHub Actions specific
    ])
    
    # ğŸŒ 1) Highest priority â€“ explicit JSON passed via CONFIG_GITHUB_JSON (secret)
    _env_json = os.getenv("CONFIG_GITHUB_JSON", "").strip()
    if _env_json:
        try:
            return json.loads(_env_json)
        except Exception as env_err:
            print(f"âš ï¸ CONFIG_GITHUB_JSON malformed: {env_err}. Falling back to defaults")

    # ğŸŒ 2) CI environment without explicit JSON â€“ use built-in dummy config
    if is_ci_environment:
        print("DEBUG: CI/CD environment detected - using dummy config")
        return {
            "TELEGRAM_BOT_TOKEN": "dummy_bot_token",
            "OPENAI_API_KEY": "dummy_openai_key", 
            "OPENAI_ADMIN_KEY": "dummy_admin_key",
            "GOOGLE_SHEET_ID": "dummy_sheet_id",
            "ADMIN_BOT_TELEGRAM_TOKEN": "dummy_admin_bot_token",
            "GEMINI_API_KEY": "dummy_gemini_key",
            "SERVICE_ACCOUNT_DICT": {
                "type": "service_account",
                "project_id": "dummy-project",
                "private_key_id": "dummy",
                "private_key": "-----BEGIN PRIVATE KEY-----\ndummy\n-----END PRIVATE KEY-----\n",
                "client_email": "dummy@dummy.iam.gserviceaccount.com",
                "client_id": "dummy",
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token"
            },
            # ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
            "SHEET_USER_TAB": "dummy_user_tab",
            "SHEET_LOG_TAB": "dummy_log_tab", 
            "SHEET_STATES_TAB": "dummy_states_tab"
        }
    
    path = get_config_file_path()
    print("DEBUG: using config path:", path)
    with open(path, encoding="utf-8") as f:
        return json.load(f)

# ×”×’×“×¨×ª × ×ª×™×‘ ×œ×•×’ ××—×™×“ ××ª×•×š ×ª×™×§×™×™×ª ×”×¤×¨×•×™×§×˜
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# âš ï¸ ×ª×™×§×•×Ÿ ×§×¨×™×˜×™: ×™×¦×™×¨×ª ×ª×™×§×™×™×ª data ×œ×¤× ×™ ×”×’×“×¨×ª ×”×œ×•×’×™×!
DATA_DIR = os.path.join(PROJECT_ROOT, "data")
os.makedirs(DATA_DIR, exist_ok=True)

def get_config_file_path():
    """
    ğŸ¯ ××¨×›×– × ×™×”×•×œ × ×ª×™×‘×™ ×§×‘×¦×™ ×§×•× ×¤×™×’
    ××—×–×™×¨ ××ª ×”× ×ª×™×‘ ×”× ×›×•×Ÿ ×œ×§×•×‘×¥ config.json
    """
    # 1. ×‘×“×™×§×ª ××©×ª× ×” ×¡×‘×™×‘×”
    env_path = os.getenv("CONFIG_PATH")
    if env_path and os.path.exists(env_path):
        return env_path
    
    # 2. ×‘×“×™×§×ª × ×ª×™×‘×™× ×™×“×•×¢×™×
    possible_paths = [
        os.path.join(PROJECT_ROOT, "etc", "secrets", "config.json"),  # × ×ª×™×‘ ×™×—×¡×™
        "/etc/secrets/config.json",  # × ×ª×™×‘ ××‘×¡×•×œ×•×˜×™ (Linux/Server)
        "etc/secrets/config.json",   # × ×ª×™×‘ ×™×—×¡×™ ×¤×©×•×˜
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # 3. ×× ×œ× × ××¦× - ×™×¦×™×¨×ª ×§×•×‘×¥ ×‘×¨×™×¨×ª ××—×“×œ
    default_path = os.path.join(PROJECT_ROOT, "etc", "secrets", "config.json")
    os.makedirs(os.path.dirname(default_path), exist_ok=True)
    
    default_config = {
        "TELEGRAM_BOT_TOKEN": "YOUR_BOT_TOKEN_HERE",
        "OPENAI_API_KEY": "YOUR_OPENAI_KEY_HERE",
        "GEMINI_API_KEY": "YOUR_GEMINI_KEY_HERE",
        "RENDER_API_KEY": "YOUR_RENDER_KEY_HERE",
        "RENDER_SERVICE_ID": "YOUR_SERVICE_ID_HERE"
    }
    
    try:
        with open(default_path, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=2, ensure_ascii=False)
        print(f"âš ï¸ [CONFIG] × ×•×¦×¨ ×§×•×‘×¥ ×§×•× ×¤×™×’ ×‘×¨×™×¨×ª ××—×“×œ: {default_path}")
        print("   ×× × ×¢×¨×•×š ××ª ×”×§×•×‘×¥ ×¢× ×”×˜×•×§× ×™× ×”×××™×ª×™×™× ×©×œ×š")
        return default_path
    except Exception as e:
        raise FileNotFoundError(f"×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨ ×§×•×‘×¥ ×§×•× ×¤×™×’: {e}")

def get_config():
    """
    ğŸ¯ ×¤×•× ×§×¦×™×” ××¨×›×–×™×ª ×œ×§×‘×œ×ª ×§×•× ×¤×™×’×•×¨×¦×™×”
    âš ï¸ ×›×œ ×§×•×‘×¥ ×©×¦×¨×™×š config ×¦×¨×™×š ×œ×§×¨×•× ×œ×¤×•× ×§×¦×™×” ×”×–×• ×‘××§×•× open ×™×©×™×¨
    âš ï¸ ××¡×•×¨ hardcode ×©×œ × ×ª×™×‘×™× ×›××• 'etc/secrets/config.json' ×‘×§×•×“!
    """
    path = get_config_file_path()
    with open(path, encoding="utf-8") as f:
        return json.load(f)

# ×”×’×“×¨×•×ª ×’×œ×•×‘×œ×™×•×ª
config = load_config()

# ğŸ›ï¸ ×”×’×“×¨×•×ª ×‘×§×¨×ª ×œ×•×’×™×
# ×¨××•×ª ×œ×•×’×™× ×–××™× ×•×ª: DEBUG, INFO, WARNING, ERROR, CRITICAL

# âš™ï¸ ×”×’×“×¨×•×ª ×‘×¨×™×¨×ª ××—×“×œ (× ×™×ª×Ÿ ×œ×©× ×•×ª ×›××Ÿ)
DEFAULT_LOG_LEVEL = "INFO"  # ×¨××ª ×œ×•×’×™× ×›×œ×œ×™×ª
ENABLE_DEBUG_PRINTS = False  # DEBUG prints ×›×œ×œ×™×™× (False = ×¨×–×” ×™×•×ª×¨)
ENABLE_GPT_COST_DEBUG = True  # ×“×™×‘××’ ×¢×œ×•×™×•×ª GPT ××¤×•×¨×˜ - ×—×©×•×‘ ×œ×ª×¤×¢×•×œ!
# ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×ª××™×“ False
ENABLE_SHEETS_DEBUG = False
ENABLE_PERFORMANCE_DEBUG = True  # ×“×™×‘××’ ×‘×™×¦×•×¢×™× ××¤×•×¨×˜ - ×—×©×•×‘ ×œ×–×× ×™ ×ª×’×•×‘×”!
ENABLE_MESSAGE_DEBUG = True  # ×”×•×“×¢×•×ª ×‘×¡×™×¡×™×•×ª (××•××œ×¥ True)
ENABLE_DATA_EXTRACTION_DEBUG = True  # ××™×“×¢ ×¢×œ ×—×™×œ×•×¥ × ×ª×•× ×™× ×-GPT C,D,E

# ğŸ”§ ××¤×©×¨×•×ª ×œ×¢×§×•×£ ×¢× ××©×ª× ×™ ×¡×‘×™×‘×” (××•×¤×¦×™×•× ×œ×™)
# ×“×•×’×××•×ª ×©×™××•×©:
# Windows: $env:ENABLE_GPT_COST_DEBUG="false"; python main.py
# Linux/Mac: ENABLE_GPT_COST_DEBUG=false python main.py
# ××• ×”×’×“×¨ ×‘××©×ª× ×™ ×”×¡×‘×™×‘×” ×©×œ ×”××¢×¨×›×ª
import os
DEFAULT_LOG_LEVEL = os.getenv("LOG_LEVEL", DEFAULT_LOG_LEVEL)
ENABLE_DEBUG_PRINTS = os.getenv("ENABLE_DEBUG_PRINTS", str(ENABLE_DEBUG_PRINTS)).lower() == "true"
ENABLE_GPT_COST_DEBUG = os.getenv("ENABLE_GPT_COST_DEBUG", str(ENABLE_GPT_COST_DEBUG)).lower() == "true"
# ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×ª××™×“ False
ENABLE_SHEETS_DEBUG = False
ENABLE_PERFORMANCE_DEBUG = os.getenv("ENABLE_PERFORMANCE_DEBUG", str(ENABLE_PERFORMANCE_DEBUG)).lower() == "true"
ENABLE_MESSAGE_DEBUG = os.getenv("ENABLE_MESSAGE_DEBUG", str(ENABLE_MESSAGE_DEBUG)).lower() == "true"
ENABLE_DATA_EXTRACTION_DEBUG = os.getenv("ENABLE_DATA_EXTRACTION_DEBUG", str(ENABLE_DATA_EXTRACTION_DEBUG)).lower() == "true"

# ×”×’×“×¨×ª ×¨××ª ×œ×•×’×™× ×’×œ×•×‘×œ×™×ª
logging.basicConfig(
    level=getattr(logging, DEFAULT_LOG_LEVEL.upper(), logging.INFO),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # ×¤×œ×˜ ×œ××¡×•×£
        logging.FileHandler(os.path.join(PROJECT_ROOT, 'data', 'bot.log'), encoding='utf-8')  # ×¤×œ×˜ ×œ×§×•×‘×¥
    ]
)

# ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ×œ×‘×§×¨×ª ×œ×•×’×™×
def should_log_debug_prints():
    """×‘×•×“×§ ×”×× ×œ×”×“×¤×™×¡ DEBUG prints ×‘×”×ª×× ×œ×”×’×“×¨×•×ª"""
    return ENABLE_DEBUG_PRINTS

def should_log_gpt_cost_debug():
    """×‘×•×“×§ ×”×× ×œ×”×“×¤×™×¡ ×“×™×‘××’ ×¢×œ×•×™×•×ª GPT"""
    return ENABLE_GPT_COST_DEBUG

def should_log_sheets_debug():
    """ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×ª××™×“ False"""
    return False

def should_log_performance_debug():
    """×‘×•×“×§ ×”×× ×œ×”×“×¤×™×¡ ×“×™×‘××’ ×‘×™×¦×•×¢×™×"""
    return ENABLE_PERFORMANCE_DEBUG

def should_log_message_debug():
    """×‘×•×“×§ ×”×× ×œ×”×“×¤×™×¡ ×”×•×“×¢×•×ª ×‘×¡×™×¡×™×•×ª"""
    return ENABLE_MESSAGE_DEBUG

def should_log_data_extraction_debug():
    """×‘×•×“×§ ×”×× ×œ×”×“×¤×™×¡ ××™×“×¢ ×¢×œ ×—×™×œ×•×¥ × ×ª×•× ×™× ×-GPT C,D,E"""
    return ENABLE_DATA_EXTRACTION_DEBUG

# Helper to mask sensitive strings (defined early to avoid NameError)
def _mask_sensitive(value: Optional[str], visible_chars: int = 4) -> str:
    if not value:
        return "[empty]"
    value = str(value)
    if len(value) <= visible_chars:
        return value
    return value[:visible_chars] + "..."

# ğŸš€ ×˜×•×§× ×™× ×•×–×™×”×•×™×™×
TELEGRAM_BOT_TOKEN = config["TELEGRAM_BOT_TOKEN"]
OPENAI_API_KEY = config["OPENAI_API_KEY"]
OPENAI_ADMIN_KEY = os.getenv("OPENAI_ADMIN_KEY", config.get("OPENAI_ADMIN_KEY", OPENAI_API_KEY))
print("××¤×ª×— Admin ×‘×©×™××•×© (×”Ö¾OPENAI_ADMIN_KEY):", _mask_sensitive(OPENAI_ADMIN_KEY, 5))

# ğŸ¯ ×”×’×“×¨×ª ××¡×“ × ×ª×•× ×™× - ×§×¨×™×˜×™ ×œ×¤×¢×•×œ×” ×ª×§×™× ×”
DB_URL = config.get("DATABASE_EXTERNAL_URL") or config.get("DATABASE_URL") or os.getenv("DATABASE_URL")
if not DB_URL:
    # ×™×¦×™×¨×ª DB_URL dummy ×œ×¡×‘×™×‘×ª CI/CD
    if IS_CI_ENVIRONMENT:
        DB_URL = "postgresql://dummy:dummy@localhost:5432/dummy"
        print("âš ï¸ [CONFIG] ×¡×‘×™×‘×ª CI - ××©×ª××© ×‘-dummy DB_URL")
    else:
        raise ValueError("âŒ [CONFIG] DB_URL ×—×¡×¨! ×”×’×“×¨ DATABASE_URL ××• DATABASE_EXTERNAL_URL ×‘×§×•× ×¤×™×’×•×¨×¦×™×”")
else:
    print(f"âœ… [CONFIG] ××¡×“ × ×ª×•× ×™× ××•×’×“×¨: {_mask_sensitive(DB_URL, 20)}")

# ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
GOOGLE_SHEET_ID = "dummy_sheet_id"

# ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
SERVICE_ACCOUNT_DICT = {}

# ×”×’×“×¨×•×ª ×”×ª×¨××•×ª ×©×’×™××•×ª (×œ×‘×•×˜ ×”× ×™×”×•×œ×™ ×”×—×“×©)
ADMIN_BOT_TELEGRAM_TOKEN = config.get("ADMIN_BOT_TELEGRAM_TOKEN", TELEGRAM_BOT_TOKEN)
ADMIN_NOTIFICATION_CHAT_ID = "111709341"  # ×”Ö¾chat_id ×©×œ×š ×‘×‘×•×˜ admin

# ××©×ª× ×™× × ×•×¡×¤×™× ×©× ×“×¨×©×™× ×œ-notifications.py ×•-message_handler.py
ADMIN_CHAT_ID = ADMIN_NOTIFICATION_CHAT_ID  # alias ×œ×¢×§×‘×™×•×ª
BOT_TOKEN = TELEGRAM_BOT_TOKEN  # alias ×œ×¢×§×‘×™×•×ª
MAX_MESSAGE_LENGTH = 4096  # ××’×‘×œ×ª ××•×¨×š ×”×•×“×¢×” ×‘×˜×œ×’×¨×
MAX_CODE_TRIES = 3  # ××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ × ×™×¡×™×•× ×•×ª ×§×•×“

# ×”×’×“×¨×ª LiteLLM
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ğŸš€ ×”×’×“×¨×ª Google AI Studio (Gemini)
# ×¤×©×•×˜ ×™×•×ª×¨ ×-Vertex AI - ×¨×§ API key ××—×“ ×œ×œ× service accounts ××¡×•×‘×›×™×
GEMINI_API_KEY = config.get("GEMINI_API_KEY", "")
if GEMINI_API_KEY:
    os.environ["GEMINI_API_KEY"] = GEMINI_API_KEY
    safe_print(f"âœ… [CONFIG] Google AI Studio (Gemini) API Key configured")
    print(f"   Key prefix: {_mask_sensitive(GEMINI_API_KEY, 5)}")  # ğŸ”’ ×”×¤×—×ª×” ×œ-5 ×ª×•×•×™× ×œ×‘×˜×™×—×•×ª
else:
    safe_print("âš ï¸ [CONFIG] ××–×”×¨×”: GEMINI_API_KEY ×œ× × ××¦× ×‘×§×•× ×¤×™×’×•×¨×¦×™×”.")

# ğŸš€ ×”×’×“×¨×•×ª Render ×œ×©×—×–×•×¨ ×œ×•×’×™×
RENDER_CONFIG = {
    "API_KEY": config.get("RENDER_API_KEY", ""),
    "SERVICE_ID": config.get("RENDER_SERVICE_ID", ""),
    "BASE_URL": "https://api.render.com/v1"
}

# ×‘×“×™×§×ª ×ª×§×™× ×•×ª ×¤×¨×˜×™ Render
if RENDER_CONFIG["API_KEY"]:
    safe_print(f"âœ… [CONFIG] Render API Key configured")
    print(f"   Key prefix: {_mask_sensitive(RENDER_CONFIG['API_KEY'], 5)}")
else:
    safe_print("âš ï¸ [CONFIG] ××–×”×¨×”: RENDER_API_KEY ×œ× × ××¦× ×‘×§×•× ×¤×™×’×•×¨×¦×™×”.")

if RENDER_CONFIG["SERVICE_ID"]:
    safe_print(f"âœ… [CONFIG] Render Service ID configured")
    print(f"   Service ID: {_mask_sensitive(RENDER_CONFIG['SERVICE_ID'], 8)}")
else:
    safe_print("âš ï¸ [CONFIG] ××–×”×¨×”: RENDER_SERVICE_ID ×œ× × ××¦× ×‘×§×•× ×¤×™×’×•×¨×¦×™×”.")

# ğŸ¯ ×”×’×“×¨×•×ª ××•×“×œ×™×
FREE_MODELS = ["gemini/gemini-1.5-flash", "gemini/gemini-2.0-flash-exp"]
PAID_MODELS = ["gpt-4o-mini", "gpt-4o", "gemini/gemini-2.5-flash"]
FREE_MODEL_DAILY_LIMIT = 100

# ğŸ”‘ ×”×’×“×¨×ª ××™××•×ª ×’×œ×•×‘×œ×™×ª ×¢×‘×•×¨ Google Vertex AI (×œ× ×‘×©×™××•×©)
# ×”×©××¨× ×• ××ª ×”×§×•×“ ×”×–×” ×›×’×™×‘×•×™ ×œ××§×¨×” ×©×œ ××¢×‘×¨ ×¢×ª×™×“×™ ×œ-Vertex AI
# ×›×¨×’×¢ ×× ×—× ×• ××©×ª××©×™× ×‘-Google AI Studio ×©×¤×©×•×˜ ×™×•×ª×¨ ×•×¢× GEMINI_API_KEY ×œ××¢×œ×”

# try:
#     # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×¢× credentials
#     import tempfile
#     import json as json_module
#     
#     service_account_dict = config["SERVICE_ACCOUNT_DICT"]
#     
#     # ×™×¦×™×¨×ª ×§×•×‘×¥ ×–×× ×™ ×¢× ×”-service account credentials
#     with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as temp_file:
#         json_module.dump(service_account_dict, temp_file, indent=2)
#         temp_credentials_path = temp_file.name
#     
#     # ×”×’×“×¨×ª ××©×ª× ×™ ×”×¡×‘×™×‘×” ×›×¤×™ ×©-LiteLLM ××¦×¤×”
#     os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = temp_credentials_path
#     os.environ["VERTEXAI_PROJECT"] = service_account_dict["project_id"]
#     os.environ["VERTEXAI_LOCATION"] = "us-central1"  # ×‘×¨×™×¨×ª ××—×“×œ
#     
#     print(f"âœ… [CONFIG] ××™××•×ª Google Vertex AI ×”×•×’×“×¨ ×‘×”×¦×œ×—×”")
#     print(f"   Project: {service_account_dict['project_id']}")
#     print(f"   Credentials file: {temp_credentials_path}")
#     
# except KeyError as e:
#     print(f"âš ï¸ [CONFIG] ××–×”×¨×”: ×œ× × ××¦× ××¤×ª×— '{e}' ×‘×§×•× ×¤×™×’×•×¨×¦×™×” ×¢×‘×•×¨ Vertex AI.")
# except Exception as e:
#     print(f"âŒ [CONFIG] ×©×’×™××” ×‘×”×’×“×¨×ª ××™××•×ª ×¢×‘×•×¨ Google Vertex AI: {e}")

# ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×
def reset_sheets_cache():
    """ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¤×•× ×§×¦×™×” ×¨×™×§×”"""
    pass

def get_sheets_cache_info():
    """ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ××—×–×™×¨ ××™×“×¢ ×¢×œ ××¡×“ × ×ª×•× ×™×"""
    return {
        "status": "database_mode", 
        "note": "Google Sheets ×”×•×¡×¨ - ×¢×‘×¨× ×• ×œ××¡×“ × ×ª×•× ×™×"
    }

def setup_google_sheets():
    """ğŸ—‘ï¸ Google Sheets ×”×•×¡×¨ - ×¤×•× ×§×¦×™×” ×¨×™×§×”"""
    return None, None, None, None


# âš ï¸ ×™×© ×œ×”×©×ª××© ××š ×•×¨×§ ×‘××¤×ª×—×•×ª ××ª×•×š FIELDS_DICT! ××™×Ÿ ×œ×”×›× ×™×¡ ×©××•×ª ×©×“×” ×§×©×™×—×™× ×—×“×©×™× ×›××Ÿ ××• ×‘×§×•×“ ××—×¨.
# ×©×“×•×ª ×¤×¨×•×¤×™×œ ××©×ª××© - ×©×™××•×© ×‘×¤×•× ×§×¦×™×” ××”-fields_dict
def get_profile_fields():
    try:
        from fields_dict import FIELDS_DICT
        core_fields = ["age", "closet_status", "relationship_type", "self_religiosity_level", "occupation_or_role", "attracted_to"]
        return [key for key in core_fields if key in FIELDS_DICT]
    except ImportError:
        # fallback ×× fields_dict ×œ× ×–××™×Ÿ
        return ["age", "closet_status", "relationship_type", "self_religiosity_level", "occupation_or_role", "attracted_to"]

def get_summary_field():
    try:
        from fields_dict import FIELDS_DICT
        return "summary" if "summary" in FIELDS_DICT else list(FIELDS_DICT.keys())[-1]
    except ImportError:
        return "summary"

PROFILE_FIELDS = get_profile_fields()
SUMMARY_FIELD = get_summary_field()

# ×”×’×“×¨×•×ª ×œ×•×’×™×
BOT_TRACE_LOG_FILENAME = "bot_trace_log.jsonl"
GPT_USAGE_LOG_FILENAME = "gpt_usage_log.jsonl"
CHAT_HISTORY_FILENAME = "chat_history.json"
BOT_ERRORS_FILENAME = "bot_errors.jsonl"
CRITICAL_ERRORS_FILENAME = "critical_errors.jsonl"
LOG_LIMIT = 100



# × ×ª×™×‘×™ ×§×‘×¦×™× ×¢×™×§×¨×™×™×
gpt_log_path = os.path.join(DATA_DIR, GPT_USAGE_LOG_FILENAME)
BOT_TRACE_LOG_PATH = os.path.join(DATA_DIR, BOT_TRACE_LOG_FILENAME)
CHAT_HISTORY_PATH = os.path.join(DATA_DIR, CHAT_HISTORY_FILENAME)
BOT_ERRORS_PATH = os.path.join(DATA_DIR, BOT_ERRORS_FILENAME)
CRITICAL_ERRORS_PATH = os.path.join(DATA_DIR, CRITICAL_ERRORS_FILENAME)

# ğŸš€ × ×ª×™×‘×™ ×§×‘×¦×™× ×œ××¢×¨×›×ª × ×™×”×•×œ × ×ª×•× ×™× ××§×‘×™×œ×”
USER_PROFILES_PATH = os.path.join(DATA_DIR, "user_profiles.json")
SYNC_QUEUE_PATH = os.path.join(DATA_DIR, "sync_queue.json")

# ğŸ”„ ×”×’×“×¨×•×ª ×¡× ×›×¨×•×Ÿ
SYNC_BATCH_SIZE = 10  # ×›××•×ª ×¢×“×›×•× ×™× ×œ×¡× ×›×¨×•×Ÿ ×‘××§×‘×™×œ
SYNC_INTERVAL_SECONDS = 30  # ×–××Ÿ ×‘×™×Ÿ ×¡× ×›×¨×•× ×™×
MAX_SYNC_RETRIES = 3  # ××¡×¤×¨ × ×™×¡×™×•× ×•×ª ×¡× ×›×¨×•×Ÿ

def check_config_sanity():
    """
    ×‘×•×“×§ ×©×›×œ ××©×ª× ×™ ×”×§×•× ×¤×™×’×•×¨×¦×™×” ×”×§×¨×™×˜×™×™× ×§×™×™××™×.
    ×¤×œ×˜: ××™×Ÿ (××“×¤×™×¡/××ª×¨×™×¢)
    """
    missing = []
    sensitive_keys = [
        "TELEGRAM_BOT_TOKEN", "OPENAI_API_KEY", "OPENAI_ADMIN_KEY", "ADMIN_BOT_TELEGRAM_TOKEN"
    ]
    for key in sensitive_keys:
        val = globals().get(key, None)
        if not val or (isinstance(val, str) and not val.strip()):
            missing.append(key)
    if missing:
        safe_print(f"âŒ [CONFIG] ×—×¡×¨×™× ××©×ª× ×™ ×§×•× ×¤×™×’×•×¨×¦×™×” ×§×¨×™×˜×™×™×: {missing}")
    else:
        safe_print("âœ… [CONFIG] ×›×œ ××©×ª× ×™ ×”×§×•× ×¤×™×’×•×¨×¦×™×” ×”×§×¨×™×˜×™×™× ×§×™×™××™×.")

def get_config_snapshot():
    """
    ××—×–×™×¨ snapshot ×©×œ ×§×•× ×¤×™×’×•×¨×¦×™×” ×œ×œ× ×¢×¨×›×™× ×¨×’×™×©×™×.
    ×¤×œ×˜: dict
    """
    # ××—×–×™×¨ snapshot ×©×œ ×§×•× ×¤×™×’×•×¨×¦×™×” ×œ×œ× ×¢×¨×›×™× ×¨×’×™×©×™×
    return {
        "DATA_DIR": DATA_DIR,
        "PROJECT_ROOT": PROJECT_ROOT,
        "LOG_FILE_PATH": BOT_TRACE_LOG_FILENAME,
        "gpt_log_path": gpt_log_path,
        "BOT_TRACE_LOG_PATH": BOT_TRACE_LOG_PATH,
        "CHAT_HISTORY_PATH": CHAT_HISTORY_PATH,
        "BOT_ERRORS_PATH": BOT_ERRORS_PATH,
        "CRITICAL_ERRORS_PATH": CRITICAL_ERRORS_PATH,
        "USER_PROFILES_PATH": USER_PROFILES_PATH,
        "SYNC_QUEUE_PATH": SYNC_QUEUE_PATH
    }

# ================================
# ğŸ¯ ×”×’×“×¨×ª ××•×“×œ×™× ×•×¤×¨××˜×¨×™× ××¨×›×–×™×ª
# ================================
# ×›×œ ×©×™× ×•×™ ×›××Ÿ ××©×¤×™×¢ ×¢×œ ×›×œ ×× ×•×¢×™ ×”-GPT

# ================================
# ğŸ”§ ×”×’×“×¨×•×ª Concurrent Handling
# ================================
# ×”×’×“×¨×•×ª ×œ× ×™×”×•×œ ×¢×•××¡×™ ××©×ª××©×™× ××¨×•×‘×™×
MAX_CONCURRENT_USERS = 50  # ××¡×¤×¨ ××©×ª××©×™× ××§×¡×™××œ×™ ×‘××§×‘×™×œ (×”×•×’×“×œ ×œ-50 - ×”×¨×‘×” ××§×•×)
MAX_SHEETS_OPERATIONS_PER_MINUTE = 60  # ××’×‘×œ×ª Google Sheets (60% ×-100)
SHEETS_QUEUE_SIZE = 100  # ×’×•×“×œ ×ª×•×¨ ×œ×¤×¢×•×œ×•×ª Sheets
SHEETS_BATCH_SIZE = 10  # ×›××•×ª ×¤×¢×•×œ×•×ª ×œ×¢×™×‘×•×“ ×‘××§×‘×™×œ (×”×•×’×“×œ ×-5 ×œ-10 ×œ×˜×™×¤×•×œ ×‘×©×™××•×© ××•×’×–×)

# ×¡×•×’×™ ×¢×“×›×•× ×™× ×œ×¤×™ ×¢×“×™×¤×•×ª
UPDATE_PRIORITY = {
    "critical": 1,    # ×”×™×¡×˜×•×¨×™×” + ×¤×¨×•×¤×™×œ - ××™×™×“×™
    "normal": 2,      # ×œ×•×’×™× ×¨×’×™×œ×™× - ×™×›×•×œ ×œ×—×›×•×ª
    "low": 3          # × ×ª×•× ×™× ×¡×˜×˜×™×¡×˜×™×™× - ×œ× ×“×—×•×£
}

GPT_PARAMS = {
    "gpt_a": {
        "temperature": 1,
        "max_tokens": None,  # ×œ×œ× ×”×’×‘×œ×”
    },
    "gpt_b": {
        "temperature": 0.5,
        "max_tokens": None,  # ×œ×œ× ×”×’×‘×œ×”
    },
    "gpt_c": {
        "temperature": 0.3,
        "max_tokens": 500,
    },
    "gpt_d": {
        "temperature": 0.1,
        "max_tokens": 300,
    },
    "gpt_e": {
        "temperature": 0.8,
        "max_tokens": 2000,
    },
}

# ×§×‘×•×¢×™× ××¡×¤×¨×™×™× - Single Source of Truth
MAX_LOG_LINES_TO_KEEP = 500  # ×œ××’×‘×œ×ª ×œ×•×’×™× ×™×©× ×™×
MAX_OLD_LOG_LINES = 1000     # ×œ× ×™×§×•×™ ×œ×•×’×™× ×™×©× ×™×  
MAX_CHAT_HISTORY_MESSAGES = 30000  # ××’×‘×œ×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”
MAX_TRACEBACK_LENGTH = 500   # ××•×¨×š ××§×¡×™××œ×™ ×©×œ traceback ×‘×”×•×“×¢×•×ª ×©×’×™××”

# ğŸš€ ×”×’×“×¨×ª ×¤×•×¨×˜ ×“×™× ××™×ª - ×ª×•×××ª ×œ×¤×œ×˜×¤×•×¨××•×ª cloud
# ×‘×¤×œ×˜×¤×•×¨××•×ª ×›××• Render, Heroku, Railway - ×”×¤×œ×˜×¤×•×¨××” ××’×“×™×¨×” ××ª ×”×¤×•×¨×˜ ×“×™× ××™×ª
PRODUCTION_PORT = int(os.getenv("PORT", 8000))     # ×¤×•×¨×˜ ×“×™× ××™ ××”×¤×œ×˜×¤×•×¨××” ××• 8000
DEVELOPMENT_PORT = 10000     # ×¤×•×¨×˜ ×œ×¡×‘×™×‘×ª ×¤×™×ª×•×—

safe_print(f"ğŸ”§ [CONFIG] ×¤×•×¨×˜ ×©×¨×ª: {PRODUCTION_PORT} (××§×•×¨: {'××©×ª× ×” ×¡×‘×™×‘×” PORT' if os.getenv('PORT') else '×‘×¨×™×¨×ª ××—×“×œ 8000'})")

MODEL_ROUTES = {
    # ========= ××§×¨× =========
    # default       â€“ ×”××•×“×œ ×”×¨××©×™ (Fast ×¨×’×™×œ)
    # extra_emotion â€“ ××•×“×œ ×¨×’×©×™ ××ª×§×“× (×©×™×™×š ×¨×§ ×œ-gpt_a)
    # fallback1     â€“ fallback ××”×™×¨/×–×•×œ (×× default × ×›×©×œ)
    # fallback2     â€“ fallback ×—×™×¨×•× GPT-4o (×× ×”×›×œ × ×›×©×œ)
    # ========================
    "gpt_a": {
        "default": "gemini/gemini-1.5-pro",   # Fast (filter FALSE)
        "extra_emotion": "gemini/gemini-2.5-flash", # Smart (filter TRUE)
        "fallback1": "gemini/gemini-2.0-flash-exp", # rate-limit fallback
        "fallback2": "openai/gpt-4o"              # Emergency paid
    },
    "gpt_b": {
        "default": "gemini/gemini-2.0-flash-exp",
        "fallback1": "gemini/gemini-1.5-pro",
        "fallback2": "openai/gpt-4o"
    },
    "gpt_c": {
        "default": "gemini/gemini-1.5-pro",
        "fallback1": "gemini/gemini-2.0-flash-exp",
        "fallback2": "openai/gpt-4o"
    },
    "gpt_d": {
        "default": "gemini/gemini-1.5-pro",
        "fallback1": "gemini/gemini-2.0-flash-exp",
        "fallback2": "openai/gpt-4o"
    },
    "gpt_e": {
        "default": "gemini/gemini-2.5-pro",
        "fallback1": "gemini/gemini-2.5-flash",
        "fallback2": "openai/gpt-4o"
    },
}

# --------------------------
# â¬‡ï¸ Generating legacy maps so ×©××¨ ×”×§×•×“ ×™××©×™×š ×œ×¢×‘×•×“ ×‘×œ×™ ×©×™× ×•×™
# --------------------------
GPT_MODELS = {}
GPT_FALLBACK_MODELS = {}
GPT_PREMIUM_FALLBACK = {}

for engine, routes in MODEL_ROUTES.items():
    if engine == "gpt_a":
        # Smart (extra_emotion) ××©××© ×›-GPT_MODELS
        GPT_MODELS[engine] = routes.get("extra_emotion", routes["default"])
        # default ××©××© ×›-fallback ×¨××©×•×Ÿ
        if routes.get("default"):
            GPT_FALLBACK_MODELS[engine] = routes["default"]
    else:
        GPT_MODELS[engine] = routes["default"]
        if routes.get("fallback1"):
            GPT_FALLBACK_MODELS[engine] = routes["fallback1"]
    if routes.get("fallback2"):
        GPT_PREMIUM_FALLBACK[engine] = routes["fallback2"]

# --------------------------------------------------------------------------
# ×¡×•×£ SECTION â€“ From here downwards ××™×Ÿ ×©×™× ×•×™×™ ××•×“×œ×™× × ×•×¡×¤×™×.
# --------------------------------------------------------------------------

# === Database URL from config ===
DATABASE_URL = config.get("DATABASE_INTERNAL_URL") or config.get("DATABASE_URL")
